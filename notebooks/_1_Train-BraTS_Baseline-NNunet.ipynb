{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13844758,"sourceType":"datasetVersion","datasetId":8803257}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. CÃ i Ä‘áº·t thÆ° viá»‡n (Setup)","metadata":{}},{"cell_type":"code","source":"# ------------------------------------------------------------------\n# CELL 1: SETUP & INSTALLATION\n# ------------------------------------------------------------------\nimport os\nimport sys\nimport site\nimport shutil\n\nprint(\"âš™ï¸ Äang cÃ i Ä‘áº·t nnU-Net vÃ  cÃ¡c thÆ° viá»‡n phá»¥ trá»£...\")\n!pip install nnunetv2 hiddenlayer graphviz --quiet\nprint(\"âœ… CÃ i Ä‘áº·t hoÃ n táº¥t.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T08:37:43.969619Z","iopub.execute_input":"2025-11-25T08:37:43.969855Z","iopub.status.idle":"2025-11-25T08:39:16.926762Z","shell.execute_reply.started":"2025-11-25T08:37:43.969837Z","shell.execute_reply":"2025-11-25T08:39:16.925954Z"}},"outputs":[{"name":"stdout","text":"âš™ï¸ Äang cÃ i Ä‘áº·t nnU-Net vÃ  cÃ¡c thÆ° viá»‡n phá»¥ trá»£...\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mâœ… CÃ i Ä‘áº·t hoÃ n táº¥t.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Cell 2: Cáº¥u hÃ¬nh MÃ´i trÆ°á»ng & Symlink Data (Configuration)","metadata":{}},{"cell_type":"code","source":"# ------------------------------------------------------------------\n# CELL 2: CONFIGURATION & DATA PREPARATION\n# ------------------------------------------------------------------\n# 1. Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng\nos.environ['nnUNet_raw'] = \"/kaggle/temp/nnUNet_raw\"\nos.environ['nnUNet_preprocessed'] = \"/kaggle/temp/nnUNet_preprocessed\"\nos.environ['nnUNet_results'] = \"/kaggle/working/nnUNet_results\" \nos.environ['nnUNet_compile'] = 'F' # FIX Lá»–I P100: Táº¯t torch.compile\n\n# Táº¡o folder gá»‘c\nfor path in [os.environ['nnUNet_raw'], os.environ['nnUNet_preprocessed'], os.environ['nnUNet_results']]:\n    os.makedirs(path, exist_ok=True)\n\n# 2. Xá»­ lÃ½ Symlink cho Data (Ká»¹ thuáº­t tiáº¿t kiá»‡m bá»™ nhá»› Kaggle)\nprint(\"ğŸ”— Äang táº¡o Symlink cho dá»¯ liá»‡u...\")\n\n# --- Preprocessed Data ---\ninput_preprocessed_plans = \"/kaggle/input/ds312-nnunet-edl/nnUNET_preprocessed/nnUNET_preprocessed/Dataset101_BraTS2020/nnUNetPlans_3d_fullres\"\ninput_preprocessed_root = os.path.dirname(input_preprocessed_plans)\ntarget_preprocessed_dataset = os.path.join(os.environ['nnUNet_preprocessed'], \"Dataset101_BraTS2020\")\nos.makedirs(target_preprocessed_dataset, exist_ok=True)\n\n# Link folder náº·ng\ntarget_plans_dir = os.path.join(target_preprocessed_dataset, \"nnUNetPlans_3d_fullres\")\nif not os.path.exists(target_plans_dir):\n    os.symlink(input_preprocessed_plans, target_plans_dir)\n\n# --- THÃŠM ÄOáº N NÃ€Y VÃ€O CELL 2 ---\n# 1.1 Link folder 'gt_segmentations' (Äá»ƒ cháº¡y bÆ°á»›c cháº¥m Ä‘iá»ƒm cuá»‘i cÃ¹ng)\ninput_gt_dir = \"/kaggle/input/ds312-nnunet-edl/nnUNET_preprocessed/nnUNET_preprocessed/Dataset101_BraTS2020/gt_segmentations\"\ntarget_gt_dir = os.path.join(target_preprocessed_dataset, \"gt_segmentations\")\nif not os.path.exists(target_gt_dir):\n    os.symlink(input_gt_dir, target_gt_dir)\n    \n# Copy file nháº¹ (json/pkl)\nfor item in os.listdir(input_preprocessed_root):\n    s = os.path.join(input_preprocessed_root, item)\n    d = os.path.join(target_preprocessed_dataset, item)\n    if os.path.isfile(s) and (item.endswith(\".json\") or item.endswith(\".pkl\")):\n        shutil.copy(s, d)\n\n# --- Raw Data (Optional nhÆ°ng tá»‘t Ä‘á»ƒ verify) ---\ninput_raw_images = \"/kaggle/input/ds312-nnunet-edl/nnUNET_raw/nnUNET_raw/Dataset101_BraTS2020/imagesTr\"\ninput_raw_root = os.path.dirname(input_raw_images)\ntarget_raw_dataset = os.path.join(os.environ['nnUNet_raw'], \"Dataset101_BraTS2020\")\nos.makedirs(target_raw_dataset, exist_ok=True)\n\ntarget_imagesTr = os.path.join(target_raw_dataset, \"imagesTr\")\nif not os.path.exists(target_imagesTr):\n    os.symlink(input_raw_images, target_imagesTr)\n\nraw_json_path = os.path.join(input_raw_root, \"dataset.json\")\nif os.path.exists(raw_json_path):\n    shutil.copy(raw_json_path, os.path.join(target_raw_dataset, \"dataset.json\"))\n\nprint(\"âœ… Cáº¥u hÃ¬nh Data & MÃ´i trÆ°á»ng hoÃ n táº¥t.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T08:39:16.930739Z","iopub.execute_input":"2025-11-25T08:39:16.930980Z","iopub.status.idle":"2025-11-25T08:39:16.969718Z","shell.execute_reply.started":"2025-11-25T08:39:16.930945Z","shell.execute_reply":"2025-11-25T08:39:16.969164Z"}},"outputs":[{"name":"stdout","text":"ğŸ”— Äang táº¡o Symlink cho dá»¯ liá»‡u...\nâœ… Cáº¥u hÃ¬nh Data & MÃ´i trÆ°á»ng hoÃ n táº¥t.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Cell 4: Thá»±c thi Training (Execution)","metadata":{}},{"cell_type":"code","source":"# ------------------------------------------------------------------\n# CELL 4: START TRAINING\n# ------------------------------------------------------------------\nprint(\"ğŸš€ Báº®T Äáº¦U TRAINING (Fold 0 - 30 Epochs)...\")\n# LÆ°u Ã½: Cá» --npz sáº½ lÆ°u file .npz ráº¥t náº·ng. Náº¿u sá»£ trÃ n á»• cá»©ng Kaggle thÃ¬ xÃ³a cá» nÃ y Ä‘i.\n!nnUNetv2_train Dataset101_BraTS2020 3d_fullres 0 --npz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T08:39:37.562963Z","iopub.execute_input":"2025-11-25T08:39:37.563237Z","iopub.status.idle":"2025-11-25T13:36:18.648305Z","shell.execute_reply.started":"2025-11-25T08:39:37.563218Z","shell.execute_reply":"2025-11-25T13:36:18.647203Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Báº®T Äáº¦U TRAINING (Fold 0 - 30 Epochs)...\n\n############################\nINFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n############################\n\nUsing device: cuda:0\n\n#######################################################################\nPlease cite the following paper when using nnU-Net:\nIsensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n#######################################################################\n\n2025-11-25 08:39:50.225366: do_dummy_2d_data_aug: False\n2025-11-25 08:39:50.226885: Using splits from existing split file: /kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\n2025-11-25 08:39:50.227391: The split file contains 5 splits.\n2025-11-25 08:39:50.227484: Desired fold for training: 0\n2025-11-25 08:39:50.227569: This split has 294 training and 74 validation cases.\nusing pin_memory on device 0\nusing pin_memory on device 0\n\nThis is the configuration used by this training:\nConfiguration name: 3d_fullres\n {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [139.0, 170.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n\nThese are the global plan.json settings:\n {'dataset_name': 'Dataset101_BraTS2020', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [139, 170, 138], 'image_reader_writer': 'NibabelIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 29422.0, 'mean': 724.156982421875, 'median': 428.0, 'min': 0.0, 'percentile_00_5': 73.0, 'percentile_99_5': 16634.0, 'std': 1905.18603515625}, '1': {'max': 20094.0, 'mean': 644.5623779296875, 'median': 356.0, 'min': 0.0, 'percentile_00_5': 37.0, 'percentile_99_5': 8509.0, 'std': 1026.4256591796875}, '2': {'max': 18011.0, 'mean': 793.357421875, 'median': 415.0, 'min': 0.0, 'percentile_00_5': 36.0, 'percentile_99_5': 8117.0, 'std': 1158.4361572265625}, '3': {'max': 31404.0, 'mean': 1070.999267578125, 'median': 665.0, 'min': 0.0, 'percentile_00_5': 96.0, 'percentile_99_5': 16393.0, 'std': 1994.0704345703125}}} \n\n2025-11-25 08:40:24.189965: Unable to plot network architecture:\n2025-11-25 08:40:24.190289: module 'torch.onnx' has no attribute '_optimize_trace'\n2025-11-25 08:40:24.278796: \n2025-11-25 08:40:24.279072: Epoch 0\n2025-11-25 08:40:24.279271: Current learning rate: 0.01\n2025-11-25 08:48:22.473887: train_loss -0.224\n2025-11-25 08:48:22.474615: val_loss -0.4465\n2025-11-25 08:48:22.475452: Pseudo dice [0.4318, 0.717, 0.7891]\n2025-11-25 08:48:22.475567: Epoch time: 478.2 s\n2025-11-25 08:48:22.475667: Yayy! New best EMA pseudo Dice: 0.646\n2025-11-25 08:48:24.386564: \n2025-11-25 08:48:24.386791: Epoch 1\n2025-11-25 08:48:24.386977: Current learning rate: 0.00999\n2025-11-25 08:54:13.359186: train_loss -0.426\n2025-11-25 08:54:13.359797: val_loss -0.5067\n2025-11-25 08:54:13.359990: Pseudo dice [0.4487, 0.7572, 0.7794]\n2025-11-25 08:54:13.360130: Epoch time: 348.97 s\n2025-11-25 08:54:13.360270: Yayy! New best EMA pseudo Dice: 0.6475\n2025-11-25 08:54:15.716068: \n2025-11-25 08:54:15.716390: Epoch 2\n2025-11-25 08:54:15.716570: Current learning rate: 0.00998\n2025-11-25 09:00:04.588481: train_loss -0.4886\n2025-11-25 09:00:04.588829: val_loss -0.5368\n2025-11-25 09:00:04.589029: Pseudo dice [0.5661, 0.7534, 0.7915]\n2025-11-25 09:00:04.589155: Epoch time: 348.87 s\n2025-11-25 09:00:04.589265: Yayy! New best EMA pseudo Dice: 0.6532\n2025-11-25 09:00:07.235526: \n2025-11-25 09:00:07.235886: Epoch 3\n2025-11-25 09:00:07.236061: Current learning rate: 0.00997\n2025-11-25 09:05:56.275898: train_loss -0.534\n2025-11-25 09:05:56.276164: val_loss -0.6079\n2025-11-25 09:05:56.276268: Pseudo dice [0.6298, 0.7725, 0.8168]\n2025-11-25 09:05:56.276386: Epoch time: 349.04 s\n2025-11-25 09:05:56.276465: Yayy! New best EMA pseudo Dice: 0.6618\n2025-11-25 09:05:58.558698: \n2025-11-25 09:05:58.558990: Epoch 4\n2025-11-25 09:05:58.559173: Current learning rate: 0.00996\n2025-11-25 09:11:47.493251: train_loss -0.5444\n2025-11-25 09:11:47.493535: val_loss -0.5933\n2025-11-25 09:11:47.493713: Pseudo dice [0.6191, 0.8095, 0.7974]\n2025-11-25 09:11:47.493925: Epoch time: 348.94 s\n2025-11-25 09:11:47.494123: Yayy! New best EMA pseudo Dice: 0.6698\n2025-11-25 09:11:49.730180: \n2025-11-25 09:11:49.730505: Epoch 5\n2025-11-25 09:11:49.730699: Current learning rate: 0.00995\n2025-11-25 09:17:38.663253: train_loss -0.5748\n2025-11-25 09:17:38.663691: val_loss -0.5889\n2025-11-25 09:17:38.663872: Pseudo dice [0.6575, 0.8095, 0.8208]\n2025-11-25 09:17:38.664034: Epoch time: 348.93 s\n2025-11-25 09:17:38.664172: Yayy! New best EMA pseudo Dice: 0.6791\n2025-11-25 09:17:40.941772: \n2025-11-25 09:17:40.942088: Epoch 6\n2025-11-25 09:17:40.942268: Current learning rate: 0.00995\n2025-11-25 09:23:29.745067: train_loss -0.5768\n2025-11-25 09:23:29.745367: val_loss -0.5948\n2025-11-25 09:23:29.745538: Pseudo dice [0.6509, 0.7872, 0.8452]\n2025-11-25 09:23:29.745732: Epoch time: 348.8 s\n2025-11-25 09:23:29.745903: Yayy! New best EMA pseudo Dice: 0.6873\n2025-11-25 09:23:31.988459: \n2025-11-25 09:23:31.988679: Epoch 7\n2025-11-25 09:23:31.988909: Current learning rate: 0.00994\n2025-11-25 09:29:20.867790: train_loss -0.5757\n2025-11-25 09:29:20.868077: val_loss -0.6401\n2025-11-25 09:29:20.868223: Pseudo dice [0.6624, 0.8184, 0.8399]\n2025-11-25 09:29:20.868372: Epoch time: 348.88 s\n2025-11-25 09:29:20.868512: Yayy! New best EMA pseudo Dice: 0.6959\n2025-11-25 09:29:23.132535: \n2025-11-25 09:29:23.132916: Epoch 8\n2025-11-25 09:29:23.133066: Current learning rate: 0.00993\n2025-11-25 09:35:11.921926: train_loss -0.6085\n2025-11-25 09:35:11.922198: val_loss -0.6591\n2025-11-25 09:35:11.922309: Pseudo dice [0.7132, 0.8122, 0.862]\n2025-11-25 09:35:11.922391: Epoch time: 348.79 s\n2025-11-25 09:35:11.922459: Yayy! New best EMA pseudo Dice: 0.7059\n2025-11-25 09:35:14.087066: \n2025-11-25 09:35:14.087355: Epoch 9\n2025-11-25 09:35:14.087525: Current learning rate: 0.00992\n2025-11-25 09:41:02.858307: train_loss -0.612\n2025-11-25 09:41:02.858570: val_loss -0.6588\n2025-11-25 09:41:02.858731: Pseudo dice [0.7306, 0.8252, 0.8475]\n2025-11-25 09:41:02.858906: Epoch time: 348.77 s\n2025-11-25 09:41:02.859004: Yayy! New best EMA pseudo Dice: 0.7154\n2025-11-25 09:41:05.064085: \n2025-11-25 09:41:05.064235: Epoch 10\n2025-11-25 09:41:05.064392: Current learning rate: 0.00991\n2025-11-25 09:46:53.865852: train_loss -0.6202\n2025-11-25 09:46:53.866144: val_loss -0.6631\n2025-11-25 09:46:53.866255: Pseudo dice [0.7009, 0.8224, 0.8596]\n2025-11-25 09:46:53.866352: Epoch time: 348.8 s\n2025-11-25 09:46:53.866428: Yayy! New best EMA pseudo Dice: 0.7233\n2025-11-25 09:46:56.043412: \n2025-11-25 09:46:56.043594: Epoch 11\n2025-11-25 09:46:56.043784: Current learning rate: 0.0099\n2025-11-25 09:52:44.962865: train_loss -0.6113\n2025-11-25 09:52:44.963150: val_loss -0.6413\n2025-11-25 09:52:44.963280: Pseudo dice [0.6792, 0.8073, 0.8567]\n2025-11-25 09:52:44.963453: Epoch time: 348.92 s\n2025-11-25 09:52:44.963534: Yayy! New best EMA pseudo Dice: 0.7291\n2025-11-25 09:52:47.453086: \n2025-11-25 09:52:47.453401: Epoch 12\n2025-11-25 09:52:47.453569: Current learning rate: 0.00989\n2025-11-25 09:58:36.276474: train_loss -0.6244\n2025-11-25 09:58:36.276814: val_loss -0.6543\n2025-11-25 09:58:36.276968: Pseudo dice [0.7206, 0.8133, 0.8453]\n2025-11-25 09:58:36.277137: Epoch time: 348.82 s\n2025-11-25 09:58:36.277235: Yayy! New best EMA pseudo Dice: 0.7355\n2025-11-25 09:58:38.394160: \n2025-11-25 09:58:38.394421: Epoch 13\n2025-11-25 09:58:38.394586: Current learning rate: 0.00988\n2025-11-25 10:04:27.080643: train_loss -0.6356\n2025-11-25 10:04:27.080999: val_loss -0.6586\n2025-11-25 10:04:27.081154: Pseudo dice [0.6994, 0.8334, 0.853]\n2025-11-25 10:04:27.081302: Epoch time: 348.69 s\n2025-11-25 10:04:27.081409: Yayy! New best EMA pseudo Dice: 0.7415\n2025-11-25 10:04:29.279988: \n2025-11-25 10:04:29.280176: Epoch 14\n2025-11-25 10:04:29.280326: Current learning rate: 0.00987\n2025-11-25 10:10:17.966416: train_loss -0.6254\n2025-11-25 10:10:17.966676: val_loss -0.6854\n2025-11-25 10:10:17.966828: Pseudo dice [0.7766, 0.8571, 0.8502]\n2025-11-25 10:10:17.966948: Epoch time: 348.69 s\n2025-11-25 10:10:17.967046: Yayy! New best EMA pseudo Dice: 0.7501\n2025-11-25 10:10:20.179856: \n2025-11-25 10:10:20.180147: Epoch 15\n2025-11-25 10:10:20.180317: Current learning rate: 0.00986\n2025-11-25 10:16:09.121315: train_loss -0.6528\n2025-11-25 10:16:09.121603: val_loss -0.6666\n2025-11-25 10:16:09.121708: Pseudo dice [0.6524, 0.8344, 0.8812]\n2025-11-25 10:16:09.121854: Epoch time: 348.94 s\n2025-11-25 10:16:09.121928: Yayy! New best EMA pseudo Dice: 0.754\n2025-11-25 10:16:11.355451: \n2025-11-25 10:16:11.355741: Epoch 16\n2025-11-25 10:16:11.355922: Current learning rate: 0.00986\n2025-11-25 10:22:00.156622: train_loss -0.6463\n2025-11-25 10:22:00.156900: val_loss -0.7006\n2025-11-25 10:22:00.157059: Pseudo dice [0.7955, 0.8619, 0.8877]\n2025-11-25 10:22:00.157176: Epoch time: 348.8 s\n2025-11-25 10:22:00.157316: Yayy! New best EMA pseudo Dice: 0.7635\n2025-11-25 10:22:02.519730: \n2025-11-25 10:22:02.520063: Epoch 17\n2025-11-25 10:22:02.520230: Current learning rate: 0.00985\n2025-11-25 10:27:51.268784: train_loss -0.6327\n2025-11-25 10:27:51.269084: val_loss -0.6252\n2025-11-25 10:27:51.269208: Pseudo dice [0.7292, 0.7943, 0.8339]\n2025-11-25 10:27:51.269299: Epoch time: 348.75 s\n2025-11-25 10:27:51.269406: Yayy! New best EMA pseudo Dice: 0.7657\n2025-11-25 10:27:53.569594: \n2025-11-25 10:27:53.569814: Epoch 18\n2025-11-25 10:27:53.570011: Current learning rate: 0.00984\n2025-11-25 10:33:42.464117: train_loss -0.6388\n2025-11-25 10:33:42.464374: val_loss -0.6862\n2025-11-25 10:33:42.464537: Pseudo dice [0.7625, 0.8504, 0.8767]\n2025-11-25 10:33:42.464689: Epoch time: 348.9 s\n2025-11-25 10:33:42.464858: Yayy! New best EMA pseudo Dice: 0.7721\n2025-11-25 10:33:44.754816: \n2025-11-25 10:33:44.755129: Epoch 19\n2025-11-25 10:33:44.755298: Current learning rate: 0.00983\n2025-11-25 10:39:33.526048: train_loss -0.6656\n2025-11-25 10:39:33.526308: val_loss -0.6753\n2025-11-25 10:39:33.526440: Pseudo dice [0.7634, 0.8281, 0.8548]\n2025-11-25 10:39:33.526555: Epoch time: 348.77 s\n2025-11-25 10:39:33.526655: Yayy! New best EMA pseudo Dice: 0.7765\n2025-11-25 10:39:36.088622: \n2025-11-25 10:39:36.088964: Epoch 20\n2025-11-25 10:39:36.089129: Current learning rate: 0.00982\n2025-11-25 10:45:24.866669: train_loss -0.6477\n2025-11-25 10:45:24.867264: val_loss -0.6695\n2025-11-25 10:45:24.867418: Pseudo dice [0.7257, 0.8361, 0.8678]\n2025-11-25 10:45:24.867563: Epoch time: 348.78 s\n2025-11-25 10:45:24.867670: Yayy! New best EMA pseudo Dice: 0.7798\n2025-11-25 10:45:27.136635: \n2025-11-25 10:45:27.136921: Epoch 21\n2025-11-25 10:45:27.137071: Current learning rate: 0.00981\n2025-11-25 10:51:15.972257: train_loss -0.6446\n2025-11-25 10:51:15.972519: val_loss -0.6854\n2025-11-25 10:51:15.972667: Pseudo dice [0.7708, 0.8413, 0.8581]\n2025-11-25 10:51:15.972879: Epoch time: 348.84 s\n2025-11-25 10:51:15.972991: Yayy! New best EMA pseudo Dice: 0.7842\n2025-11-25 10:51:18.127713: \n2025-11-25 10:51:18.127908: Epoch 22\n2025-11-25 10:51:18.128177: Current learning rate: 0.0098\n2025-11-25 10:57:06.910726: train_loss -0.6521\n2025-11-25 10:57:06.911041: val_loss -0.6803\n2025-11-25 10:57:06.911260: Pseudo dice [0.767, 0.8424, 0.8545]\n2025-11-25 10:57:06.911360: Epoch time: 348.78 s\n2025-11-25 10:57:06.911434: Yayy! New best EMA pseudo Dice: 0.7879\n2025-11-25 10:57:09.063608: \n2025-11-25 10:57:09.063869: Epoch 23\n2025-11-25 10:57:09.064032: Current learning rate: 0.00979\n2025-11-25 11:02:57.865565: train_loss -0.6649\n2025-11-25 11:02:57.865952: val_loss -0.7208\n2025-11-25 11:02:57.866092: Pseudo dice [0.799, 0.8641, 0.8528]\n2025-11-25 11:02:57.866212: Epoch time: 348.8 s\n2025-11-25 11:02:57.866306: Yayy! New best EMA pseudo Dice: 0.7929\n2025-11-25 11:03:00.022915: \n2025-11-25 11:03:00.023161: Epoch 24\n2025-11-25 11:03:00.023325: Current learning rate: 0.00978\n2025-11-25 11:08:48.792432: train_loss -0.6552\n2025-11-25 11:08:48.792800: val_loss -0.6971\n2025-11-25 11:08:48.793008: Pseudo dice [0.7737, 0.8508, 0.8728]\n2025-11-25 11:08:48.793226: Epoch time: 348.77 s\n2025-11-25 11:08:48.793322: Yayy! New best EMA pseudo Dice: 0.7969\n2025-11-25 11:08:51.012970: \n2025-11-25 11:08:51.013324: Epoch 25\n2025-11-25 11:08:51.013498: Current learning rate: 0.00977\n2025-11-25 11:14:39.813447: train_loss -0.6617\n2025-11-25 11:14:39.813848: val_loss -0.6523\n2025-11-25 11:14:39.813982: Pseudo dice [0.7655, 0.8188, 0.8515]\n2025-11-25 11:14:39.814088: Epoch time: 348.8 s\n2025-11-25 11:14:39.814176: Yayy! New best EMA pseudo Dice: 0.7984\n2025-11-25 11:14:42.055877: \n2025-11-25 11:14:42.056180: Epoch 26\n2025-11-25 11:14:42.056343: Current learning rate: 0.00977\n2025-11-25 11:20:30.846234: train_loss -0.672\n2025-11-25 11:20:30.846495: val_loss -0.7298\n2025-11-25 11:20:30.846647: Pseudo dice [0.8033, 0.8572, 0.8814]\n2025-11-25 11:20:30.846807: Epoch time: 348.79 s\n2025-11-25 11:20:30.846958: Yayy! New best EMA pseudo Dice: 0.8033\n2025-11-25 11:20:33.007301: \n2025-11-25 11:20:33.007598: Epoch 27\n2025-11-25 11:20:33.007787: Current learning rate: 0.00976\n2025-11-25 11:26:21.982853: train_loss -0.6716\n2025-11-25 11:26:21.983221: val_loss -0.6499\n2025-11-25 11:26:21.983368: Pseudo dice [0.7634, 0.8444, 0.8606]\n2025-11-25 11:26:21.983489: Epoch time: 348.98 s\n2025-11-25 11:26:21.983592: Yayy! New best EMA pseudo Dice: 0.8052\n2025-11-25 11:26:24.732514: \n2025-11-25 11:26:24.732711: Epoch 28\n2025-11-25 11:26:24.732875: Current learning rate: 0.00975\n2025-11-25 11:32:13.827411: train_loss -0.6769\n2025-11-25 11:32:13.827734: val_loss -0.7154\n2025-11-25 11:32:13.827960: Pseudo dice [0.8121, 0.8658, 0.8894]\n2025-11-25 11:32:13.828117: Epoch time: 349.1 s\n2025-11-25 11:32:13.828228: Yayy! New best EMA pseudo Dice: 0.8103\n2025-11-25 11:32:16.204599: \n2025-11-25 11:32:16.204960: Epoch 29\n2025-11-25 11:32:16.205100: Current learning rate: 0.00974\n2025-11-25 11:38:05.549189: train_loss -0.6783\n2025-11-25 11:38:05.549495: val_loss -0.6968\n2025-11-25 11:38:05.549653: Pseudo dice [0.7882, 0.8607, 0.868]\n2025-11-25 11:38:05.549803: Epoch time: 349.35 s\n2025-11-25 11:38:05.549925: Yayy! New best EMA pseudo Dice: 0.8132\n2025-11-25 11:38:07.924171: \n2025-11-25 11:38:07.924475: Epoch 30\n2025-11-25 11:38:07.924666: Current learning rate: 0.00973\n2025-11-25 11:43:56.994990: train_loss -0.6662\n2025-11-25 11:43:56.995297: val_loss -0.67\n2025-11-25 11:43:56.995564: Pseudo dice [0.7401, 0.8547, 0.848]\n2025-11-25 11:43:56.995781: Epoch time: 349.07 s\n2025-11-25 11:43:56.995910: Yayy! New best EMA pseudo Dice: 0.8133\n2025-11-25 11:43:59.365237: \n2025-11-25 11:43:59.365532: Epoch 31\n2025-11-25 11:43:59.365731: Current learning rate: 0.00972\n2025-11-25 11:49:48.703657: train_loss -0.6576\n2025-11-25 11:49:48.704041: val_loss -0.6474\n2025-11-25 11:49:48.704159: Pseudo dice [0.6872, 0.8213, 0.8697]\n2025-11-25 11:49:48.704254: Epoch time: 349.34 s\n2025-11-25 11:49:50.584568: \n2025-11-25 11:49:50.584949: Epoch 32\n2025-11-25 11:49:50.585112: Current learning rate: 0.00971\n2025-11-25 11:55:39.621071: train_loss -0.6768\n2025-11-25 11:55:39.621422: val_loss -0.6708\n2025-11-25 11:55:39.621587: Pseudo dice [0.7044, 0.8273, 0.878]\n2025-11-25 11:55:39.621724: Epoch time: 349.04 s\n2025-11-25 11:55:41.471013: \n2025-11-25 11:55:41.471351: Epoch 33\n2025-11-25 11:55:41.471494: Current learning rate: 0.0097\n2025-11-25 12:01:30.725270: train_loss -0.6812\n2025-11-25 12:01:30.725775: val_loss -0.719\n2025-11-25 12:01:30.725990: Pseudo dice [0.7657, 0.8561, 0.883]\n2025-11-25 12:01:30.726155: Epoch time: 349.26 s\n2025-11-25 12:01:32.531204: \n2025-11-25 12:01:32.531510: Epoch 34\n2025-11-25 12:01:32.531657: Current learning rate: 0.00969\n2025-11-25 12:07:21.608539: train_loss -0.6605\n2025-11-25 12:07:21.608905: val_loss -0.6654\n2025-11-25 12:07:21.609025: Pseudo dice [0.8023, 0.7865, 0.8698]\n2025-11-25 12:07:21.609126: Epoch time: 349.08 s\n2025-11-25 12:07:21.609209: Yayy! New best EMA pseudo Dice: 0.8135\n2025-11-25 12:07:23.984432: \n2025-11-25 12:07:23.984823: Epoch 35\n2025-11-25 12:07:23.984987: Current learning rate: 0.00968\n2025-11-25 12:13:12.807181: train_loss -0.6684\n2025-11-25 12:13:12.807487: val_loss -0.7372\n2025-11-25 12:13:12.807643: Pseudo dice [0.767, 0.8707, 0.8856]\n2025-11-25 12:13:12.807796: Epoch time: 348.82 s\n2025-11-25 12:13:12.807914: Yayy! New best EMA pseudo Dice: 0.8163\n2025-11-25 12:13:15.082685: \n2025-11-25 12:13:15.082926: Epoch 36\n2025-11-25 12:13:15.083076: Current learning rate: 0.00968\n2025-11-25 12:19:03.899681: train_loss -0.6858\n2025-11-25 12:19:03.900062: val_loss -0.7201\n2025-11-25 12:19:03.900217: Pseudo dice [0.7902, 0.8537, 0.8894]\n2025-11-25 12:19:03.900349: Epoch time: 348.82 s\n2025-11-25 12:19:03.900432: Yayy! New best EMA pseudo Dice: 0.8191\n2025-11-25 12:19:06.185001: \n2025-11-25 12:19:06.185254: Epoch 37\n2025-11-25 12:19:06.185414: Current learning rate: 0.00967\n2025-11-25 12:24:55.206361: train_loss -0.6886\n2025-11-25 12:24:55.206675: val_loss -0.7267\n2025-11-25 12:24:55.206924: Pseudo dice [0.7682, 0.8601, 0.882]\n2025-11-25 12:24:55.207052: Epoch time: 349.02 s\n2025-11-25 12:24:55.207136: Yayy! New best EMA pseudo Dice: 0.8209\n2025-11-25 12:24:57.521056: \n2025-11-25 12:24:57.521235: Epoch 38\n2025-11-25 12:24:57.521397: Current learning rate: 0.00966\n2025-11-25 12:30:46.273190: train_loss -0.6819\n2025-11-25 12:30:46.273453: val_loss -0.7022\n2025-11-25 12:30:46.273609: Pseudo dice [0.6691, 0.839, 0.89]\n2025-11-25 12:30:46.273760: Epoch time: 348.75 s\n2025-11-25 12:30:48.013290: \n2025-11-25 12:30:48.013568: Epoch 39\n2025-11-25 12:30:48.013727: Current learning rate: 0.00965\n2025-11-25 12:36:36.752877: train_loss -0.6792\n2025-11-25 12:36:36.753179: val_loss -0.7077\n2025-11-25 12:36:36.753295: Pseudo dice [0.7953, 0.8487, 0.8872]\n2025-11-25 12:36:36.753396: Epoch time: 348.74 s\n2025-11-25 12:36:36.753510: Yayy! New best EMA pseudo Dice: 0.8212\n2025-11-25 12:36:39.035339: \n2025-11-25 12:36:39.035635: Epoch 40\n2025-11-25 12:36:39.035822: Current learning rate: 0.00964\n2025-11-25 12:42:27.960983: train_loss -0.6884\n2025-11-25 12:42:27.961358: val_loss -0.6969\n2025-11-25 12:42:27.961572: Pseudo dice [0.7176, 0.8418, 0.8736]\n2025-11-25 12:42:27.961738: Epoch time: 348.93 s\n2025-11-25 12:42:29.869412: \n2025-11-25 12:42:29.869725: Epoch 41\n2025-11-25 12:42:29.869927: Current learning rate: 0.00963\n2025-11-25 12:48:19.098834: train_loss -0.6871\n2025-11-25 12:48:19.099160: val_loss -0.6999\n2025-11-25 12:48:19.099356: Pseudo dice [0.7432, 0.8481, 0.8723]\n2025-11-25 12:48:19.099639: Epoch time: 349.23 s\n2025-11-25 12:48:20.998209: \n2025-11-25 12:48:20.998451: Epoch 42\n2025-11-25 12:48:20.998584: Current learning rate: 0.00962\n2025-11-25 12:54:10.275101: train_loss -0.6706\n2025-11-25 12:54:10.275473: val_loss -0.6784\n2025-11-25 12:54:10.275634: Pseudo dice [0.7313, 0.8287, 0.8647]\n2025-11-25 12:54:10.275784: Epoch time: 349.28 s\n2025-11-25 12:54:12.113038: \n2025-11-25 12:54:12.113342: Epoch 43\n2025-11-25 12:54:12.113497: Current learning rate: 0.00961\n2025-11-25 13:00:01.388170: train_loss -0.6713\n2025-11-25 13:00:01.388486: val_loss -0.6914\n2025-11-25 13:00:01.388663: Pseudo dice [0.7456, 0.8458, 0.8636]\n2025-11-25 13:00:01.389003: Epoch time: 349.28 s\n2025-11-25 13:00:03.190361: \n2025-11-25 13:00:03.190526: Epoch 44\n2025-11-25 13:00:03.190690: Current learning rate: 0.0096\n2025-11-25 13:05:52.429910: train_loss -0.6638\n2025-11-25 13:05:52.430228: val_loss -0.7201\n2025-11-25 13:05:52.430452: Pseudo dice [0.7729, 0.8453, 0.8852]\n2025-11-25 13:05:52.430735: Epoch time: 349.24 s\n2025-11-25 13:05:54.686862: \n2025-11-25 13:05:54.687177: Epoch 45\n2025-11-25 13:05:54.687337: Current learning rate: 0.00959\n2025-11-25 13:11:44.198407: train_loss -0.6898\n2025-11-25 13:11:44.198729: val_loss -0.6834\n2025-11-25 13:11:44.198947: Pseudo dice [0.7648, 0.8507, 0.8674]\n2025-11-25 13:11:44.199131: Epoch time: 349.51 s\n2025-11-25 13:11:44.199250: Yayy! New best EMA pseudo Dice: 0.8213\n2025-11-25 13:11:46.628606: \n2025-11-25 13:11:46.628952: Epoch 46\n2025-11-25 13:11:46.629127: Current learning rate: 0.00959\n2025-11-25 13:17:36.125564: train_loss -0.6728\n2025-11-25 13:17:36.126050: val_loss -0.7238\n2025-11-25 13:17:36.126277: Pseudo dice [0.7983, 0.8495, 0.8885]\n2025-11-25 13:17:36.126462: Epoch time: 349.5 s\n2025-11-25 13:17:36.126611: Yayy! New best EMA pseudo Dice: 0.8237\n2025-11-25 13:17:38.593726: \n2025-11-25 13:17:38.594061: Epoch 47\n2025-11-25 13:17:38.594233: Current learning rate: 0.00958\n2025-11-25 13:23:27.878403: train_loss -0.7075\n2025-11-25 13:23:27.878740: val_loss -0.7441\n2025-11-25 13:23:27.878927: Pseudo dice [0.8315, 0.8772, 0.8923]\n2025-11-25 13:23:27.879063: Epoch time: 349.29 s\n2025-11-25 13:23:27.879182: Yayy! New best EMA pseudo Dice: 0.828\n2025-11-25 13:23:30.214315: \n2025-11-25 13:23:30.214534: Epoch 48\n2025-11-25 13:23:30.214712: Current learning rate: 0.00957\n2025-11-25 13:29:19.459355: train_loss -0.6829\n2025-11-25 13:29:19.459677: val_loss -0.7121\n2025-11-25 13:29:19.459955: Pseudo dice [0.7983, 0.8647, 0.8835]\n2025-11-25 13:29:19.460144: Epoch time: 349.25 s\n2025-11-25 13:29:19.460290: Yayy! New best EMA pseudo Dice: 0.8301\n2025-11-25 13:29:21.949071: \n2025-11-25 13:29:21.949522: Epoch 49\n2025-11-25 13:29:21.949688: Current learning rate: 0.00956\n2025-11-25 13:35:11.456141: train_loss -0.685\n2025-11-25 13:35:11.456487: val_loss -0.7082\n2025-11-25 13:35:11.456645: Pseudo dice [0.8033, 0.8349, 0.8633]\n2025-11-25 13:35:11.456798: Epoch time: 349.51 s\n2025-11-25 13:35:11.801347: Yayy! New best EMA pseudo Dice: 0.8305\n2025-11-25 13:35:14.266264: \n2025-11-25 13:35:14.266562: Epoch 50\n2025-11-25 13:35:14.266773: Current learning rate: 0.00955\n^C\nTraceback (most recent call last):\n  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n    sys.exit(run_training_entry())\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 266, in run_training_entry\n    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 207, in run_training\n    nnunet_trainer.run_training()\n  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1371, in run_training\n    train_outputs.append(self.train_step(next(self.dataloader_train)))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 989, in train_step\n    output = self.network(data)\n             ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/dynamic_network_architectures/architectures/unet.py\", line 93, in forward\n    skips = self.encoder(x)\n            ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/dynamic_network_architectures/building_blocks/plain_conv_encoder.py\", line 86, in forward\n    x = s(x)\n        ^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n    input = module(input)\n            ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py\", line 137, in forward\n    return self.convs(x)\n           ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n    input = module(input)\n            ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py\", line 71, in forward\n    return self.all_modules(x)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n    input = module(input)\n            ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/instancenorm.py\", line 124, in forward\n    return self._apply_instance_norm(input)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/instancenorm.py\", line 47, in _apply_instance_norm\n    return F.instance_norm(\n           ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 2876, in instance_norm\n    return torch.instance_norm(\n           ^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\nException in thread Thread-1 (results_loop):\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n    self.run()\n  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 125, in results_loop\n    raise e\n  File \"/usr/local/lib/python3.11/dist-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 108, in results_loop\n    item = in_queue.get()\n           ^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n    fd = df.detach()\n         ^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n    with _resource_sharer.get_connection(self._id) as conn:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n    c = Client(address, authkey=process.current_process().authkey)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 519, in Client\n    c = SocketClient(address)\n        ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 647, in SocketClient\n    s.connect(address)\nFileNotFoundError: [Errno 2] No such file or directory\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Cell 4b","metadata":{}},{"cell_type":"code","source":"# # ------------------------------------------------------------------\n# # CELL 4b: CHáº¤M ÄIá»‚M THá»¦ CÃ”NG (FIX Lá»–I Lá»†CH Sá» LÆ¯á»¢NG FILE)\n# # ------------------------------------------------------------------\n# import os\n# import shutil\n\n# # 1. Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n\n# gt_folder_full = \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/gt_segmentations\"\n# pred_folder = \"/kaggle/working/nnUNet_results/Dataset101_BraTS2020/EDLTrainer__nnUNetPlans__3d_fullres/fold_0/validation\"\n# dataset_json = \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/dataset.json\"\n# plans_json = \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/nnUNetPlans.json\"\n\n# # Folder táº¡m Ä‘á»ƒ chá»©a GT khá»›p\n# gt_folder_matched = \"/kaggle/temp/matched_gt_validation\"\n\n# print(\"ğŸ” Äang chuáº©n bá»‹ dá»¯ liá»‡u cháº¥m Ä‘iá»ƒm...\")\n\n# if os.path.exists(pred_folder) and os.path.exists(gt_folder_full):\n#     # BÆ°á»›c 1: Táº¡o folder GT táº¡m\n#     if os.path.exists(gt_folder_matched):\n#         shutil.rmtree(gt_folder_matched)\n#     os.makedirs(gt_folder_matched)\n    \n#     # BÆ°á»›c 2: Lá»c danh sÃ¡ch file trong folder dá»± Ä‘oÃ¡n\n#     # Chá»‰ láº¥y file .nii.gz (bá» qua json, pkl náº¿u cÃ³)\n#     pred_files = [f for f in os.listdir(pred_folder) if f.endswith('.nii.gz')]\n#     print(f\"ğŸ“‚ TÃ¬m tháº¥y {len(pred_files)} file dá»± Ä‘oÃ¡n (Validation Set).\")\n    \n#     # BÆ°á»›c 3: Copy/Link cÃ¡c file GT tÆ°Æ¡ng á»©ng sang folder táº¡m\n#     count = 0\n#     for fname in pred_files:\n#         src = os.path.join(gt_folder_full, fname)\n#         dst = os.path.join(gt_folder_matched, fname)\n        \n#         if os.path.exists(src):\n#             os.symlink(src, dst) # Táº¡o shortcut cho nhanh, ko cáº§n copy\n#             count += 1\n#         else:\n#             print(f\"âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y GT cho file {fname}\")\n            \n#     print(f\"âœ… ÄÃ£ táº¡o folder GT khá»›p ({count} files) táº¡i: {gt_folder_matched}\")\n    \n#     # BÆ°á»›c 4: Cháº¡y cháº¥m Ä‘iá»ƒm trÃªn folder GT táº¡m nÃ y\n#     print(\"ğŸš€ Báº¯t Ä‘áº§u cháº¥m Ä‘iá»ƒm...\")\n#     !nnUNetv2_evaluate_folder \"$gt_folder_matched\" \"$pred_folder\" -djfile \"$dataset_json\" -pfile \"$plans_json\"\n    \n#     print(\"\\nğŸ‰ HOÃ€N Táº¤T! File summary.json Ä‘Ã£ Ä‘Æ°á»£c táº¡o trong folder validation.\")\n# else:\n#     print(\"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y folder dá»± Ä‘oÃ¡n hoáº·c folder GT gá»‘c.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T15:03:02.458773Z","iopub.execute_input":"2025-11-23T15:03:02.459628Z","iopub.status.idle":"2025-11-23T15:03:05.274953Z","shell.execute_reply.started":"2025-11-23T15:03:02.459604Z","shell.execute_reply":"2025-11-23T15:03:05.274087Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cell 5: ÄÃ³ng gÃ³i & Xuáº¥t káº¿t quáº£ (Export)","metadata":{}},{"cell_type":"code","source":"# # ------------------------------------------------------------------\n# # CELL 5: EXPORT RESULTS\n# # ------------------------------------------------------------------\n# print(\"ğŸ“¦ Äang Ä‘Ã³ng gÃ³i káº¿t quáº£...\")\n\n# # 1. NÃ©n Model Results\n# output_folder = \"/kaggle/working/nnUNet_results/Dataset101_BraTS2020/EDLTrainer__nnUNetPlans__3d_fullres\"\n# zip_name = \"/kaggle/working/BraTS2020_EDL_Fold0_Results\"\n\n# if os.path.exists(output_folder):\n#     shutil.make_archive(zip_name, 'zip', output_folder)\n#     print(f\"âœ… ÄÃ£ nÃ©n model: {zip_name}.zip\")\n# else:\n#     print(\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y folder káº¿t quáº£ Ä‘á»ƒ nÃ©n (CÃ³ thá»ƒ training bá»‹ lá»—i).\")\n\n# # 2. Copy file splits_final.json\n# src_split = \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\"\n# dst_split = \"/kaggle/working/splits_final.json\"\n\n# if os.path.exists(src_split):\n#     shutil.copy(src_split, dst_split)\n#     print(f\"âœ… ÄÃ£ lÆ°u splits_final.json táº¡i: {dst_split}\")\n# else:\n#     print(\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file splits_final.json.\")\n\n# print(\"ğŸ‰ HOÃ€N Táº¤T! Báº N CÃ“ THá»‚ Táº¢I FILE Vá»€ Tá»ª TAB OUTPUT.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T13:36:55.717000Z","iopub.execute_input":"2025-11-25T13:36:55.717305Z","iopub.status.idle":"2025-11-25T13:36:55.725401Z","shell.execute_reply.started":"2025-11-25T13:36:55.717274Z","shell.execute_reply":"2025-11-25T13:36:55.724647Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¦ Äang Ä‘Ã³ng gÃ³i káº¿t quáº£...\nâš ï¸ KhÃ´ng tÃ¬m tháº¥y folder káº¿t quáº£ Ä‘á»ƒ nÃ©n (CÃ³ thá»ƒ training bá»‹ lá»—i).\nâœ… ÄÃ£ lÆ°u splits_final.json táº¡i: /kaggle/working/splits_final.json\nğŸ‰ HOÃ€N Táº¤T! Báº N CÃ“ THá»‚ Táº¢I FILE Vá»€ Tá»ª TAB OUTPUT.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ------------------------------------------------------------------\n# CELL 5: EXPORT RESULTS (CODE NÃ‰N GIá»® NGUYÃŠN Cáº¤U TRÃšC FOLDER)\n# ------------------------------------------------------------------\nimport shutil\nimport os\n\nprint(\"ğŸ“¦ Äang Ä‘Ã³ng gÃ³i káº¿t quáº£...\")\n\n# 1. NÃ©n Model (Giá»¯ nguyÃªn cáº¥u trÃºc nnUNet_results/...)\n# ChÃºng ta sáº½ nÃ©n tá»« thÆ° má»¥c gá»‘c /kaggle/working\noutput_zip_name = \"/kaggle/working/BraTS2020_EDL_Fold0_Results\"\nroot_dir = \"/kaggle/working\"\nbase_dir = \"nnUNet_results\" # Chá»‰ nÃ©n folder nÃ y vÃ  cÃ¡c con cá»§a nÃ³\n\ntry:\n    shutil.make_archive(output_zip_name, 'zip', root_dir, base_dir)\n    print(f\"âœ… ÄÃ£ nÃ©n thÃ nh cÃ´ng: {output_zip_name}.zip\")\n    print(\"   (Giáº£i nÃ©n ra sáº½ cÃ³ sáºµn folder nnUNet_results/Dataset101...)\")\nexcept Exception as e:\n    print(f\"âŒ Lá»—i khi nÃ©n: {e}\")\n\n# 2. Copy file splits_final.json (Váº«n giá»¯ nguyÃªn bÆ°á»›c nÃ y Ä‘á»ƒ backup)\nsrc_split = \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\"\ndst_split = \"/kaggle/working/splits_final.json\"\n\nif os.path.exists(src_split):\n    shutil.copy(src_split, dst_split)\n    print(f\"âœ… ÄÃ£ lÆ°u riÃªng splits_final.json táº¡i: {dst_split}\")\nelse:\n    print(\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file splits_final.json.\")\n\nprint(\"ğŸ‰ HOÃ€N Táº¤T! Báº N CÃ“ THá»‚ Táº¢I FILE Vá»€ Tá»ª TAB OUTPUT.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T13:38:16.206177Z","iopub.execute_input":"2025-11-25T13:38:16.206757Z","iopub.status.idle":"2025-11-25T13:38:43.995331Z","shell.execute_reply.started":"2025-11-25T13:38:16.206716Z","shell.execute_reply":"2025-11-25T13:38:43.994525Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¦ Äang Ä‘Ã³ng gÃ³i káº¿t quáº£...\nâœ… ÄÃ£ nÃ©n thÃ nh cÃ´ng: /kaggle/working/BraTS2020_EDL_Fold0_Results.zip\n   (Giáº£i nÃ©n ra sáº½ cÃ³ sáºµn folder nnUNet_results/Dataset101...)\nâœ… ÄÃ£ lÆ°u riÃªng splits_final.json táº¡i: /kaggle/working/splits_final.json\nğŸ‰ HOÃ€N Táº¤T! Báº N CÃ“ THá»‚ Táº¢I FILE Vá»€ Tá»ª TAB OUTPUT.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Cell 6: HÃ¬nh áº£nh so sÃ¡nh MRI vs AI Prediction vs Uncertainty Map","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\nimport json\nimport shutil\n\n# --- QUAN TRá»ŒNG: Táº®T COMPILE CHO P100 ---\nos.environ['nnUNet_compile'] = 'F'\n\n# ==============================================================================\n# âš™ï¸ KAGGLE CONFIGURATION (ÄÃƒ Sá»¬A ÄÆ¯á»œNG DáºªN)\n# ==============================================================================\nCONFIG = {\n    # 1. ÄÆ°á»ng dáº«n Model (Láº¥y tá»« folder working)\n    \"checkpoint_path\": \"/kaggle/working/nnUNet_results/Dataset101_BraTS2020/EDLTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth\",\n    \n    # 2. ÄÆ°á»ng dáº«n Data (Láº¥y tá»« folder temp symlink)\n    \"image_folder\": \"/kaggle/temp/nnUNet_raw/Dataset101_BraTS2020/imagesTr\",\n    \"label_folder\": \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/gt_segmentations\", # DÃ¹ng GT Ä‘Ã£ preprocessed cho tiá»‡n\n    \"split_file\":   \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\",\n\n    # 3. ÄÆ°á»ng dáº«n lÆ°u káº¿t quáº£ (LÆ°u vÃ o working Ä‘á»ƒ táº£i vá»)\n    \"output_folder\": \"/kaggle/working/inference_results_batch\",\n    \n    # 4. Cáº¥u hÃ¬nh cháº¡y\n    \"run_mode\":         \"validation_split\",  # Cháº¡y Ä‘Ãºng táº­p Validation cá»§a Fold 0\n    \"test_range\":       [0, 10], \n    \"num_random\":       5,        \n    \n    # 5. TÃ¹y chá»n hiá»ƒn thá»‹\n    \"save_images\":      True,     \n    \"show_on_screen\":   True,    \n}\n# ==============================================================================\n\ndef get_case_list(folder):\n    if not os.path.exists(folder):\n        raise FileNotFoundError(f\"âŒ Folder {folder} khÃ´ng tá»“n táº¡i!\")\n    files = sorted([f for f in os.listdir(folder) if f.endswith(\"_0000.nii\") or f.endswith(\"_0000.nii.gz\")])\n    case_ids = []\n    for f in files:\n        if f.endswith(\".nii\"): cid = f.replace(\"_0000.nii\", \"\")\n        else: cid = f.replace(\"_0000.nii.gz\", \"\")\n        case_ids.append(cid)\n    return case_ids\n\ndef calculate_dice(pred_slice, gt_slice):\n    p = (pred_slice > 0).astype(np.float32)\n    g = (gt_slice > 0).astype(np.float32)\n    intersection = np.sum(p * g)\n    sum_areas = np.sum(p) + np.sum(g)\n    if sum_areas == 0: return 1.0\n    return (2.0 * intersection) / sum_areas\n\ndef visualize_comparison(case_id, mri_data, gt_data, pred_data, uncertainty, slice_idx=None):\n    # TÃ¬m slice cÃ³ khá»‘i u lá»›n nháº¥t Ä‘á»ƒ váº½ cho Ä‘áº¹p\n    if slice_idx is None:\n        sums_gt = np.sum(gt_data, axis=(0, 1, 2))\n        sums_pred = np.sum(pred_data, axis=(0, 1))\n        \n        if sums_gt.max() > 0: slice_idx = np.argmax(sums_gt)\n        elif sums_pred.max() > 0: slice_idx = np.argmax(sums_pred)\n        else: slice_idx = gt_data.shape[3] // 2\n\n    print(f\"    ğŸ“¸ Drawing Slice: {slice_idx}\")\n\n    # Xoay áº£nh cho Ä‘Ãºng chiá»u (.T)\n    img_slice = mri_data[0, :, :, slice_idx].T\n    \n    # GT data tá»« preprocessed folder thÆ°á»ng cÃ³ shape [C, X, Y, Z] hoáº·c [X, Y, Z]\n    # Náº¿u gt_data lÃ  [1, X, Y, Z]\n    if gt_data.ndim == 4:\n        gt_slice = gt_data[0, :, :, slice_idx].T\n    else:\n        gt_slice = gt_data[:, :, slice_idx].T\n        \n    pred_slice = pred_data[:, :, slice_idx].T\n    unc_slice = uncertainty[:, :, slice_idx].T\n\n    dice = calculate_dice(pred_slice, gt_slice)\n    ratio = (np.sum(pred_slice>0) / np.sum(gt_slice>0) * 100) if np.sum(gt_slice>0) > 0 else 0\n\n    fig, ax = plt.subplots(1, 4, figsize=(24, 6))\n    plt.suptitle(f\"Case: {case_id} | Slice: {slice_idx}\", fontsize=16, y=0.98)\n\n    # 1. MRI\n    ax[0].imshow(img_slice, cmap='gray', origin='lower')\n    ax[0].set_title(\"MRI Input\", fontsize=12)\n    ax[0].axis('off')\n\n    # 2. GT\n    ax[1].imshow(img_slice, cmap='gray', origin='lower', alpha=0.6)\n    if np.any(gt_slice): ax[1].imshow(gt_slice, cmap='Greens', origin='lower', alpha=0.6, interpolation='nearest')\n    ax[1].set_title(\"Ground Truth\", fontsize=12, color='green')\n    ax[1].axis('off')\n\n    # 3. Pred\n    ax[2].imshow(img_slice, cmap='gray', origin='lower', alpha=0.6)\n    if np.any(pred_slice): ax[2].imshow(pred_slice, cmap='jet', origin='lower', alpha=0.5, interpolation='nearest')\n    ax[2].set_title(f\"AI Prediction\\nDice: {dice:.1%} | Area: {ratio:.0f}%\", fontsize=12, color='blue')\n    ax[2].axis('off')\n\n    # 4. Uncertainty\n    im = ax[3].imshow(unc_slice, cmap='hot', origin='lower', vmin=0, vmax=1.0)\n    ax[3].set_title(\"Uncertainty Map\", fontsize=12, color='red')\n    ax[3].axis('off')\n    plt.colorbar(im, ax=ax[3], fraction=0.046, pad=0.04)\n\n    if CONFIG[\"save_images\"]:\n        os.makedirs(CONFIG[\"output_folder\"], exist_ok=True)\n        save_path = os.path.join(CONFIG[\"output_folder\"], f\"{case_id}_slice{slice_idx}.png\")\n        plt.savefig(save_path, bbox_inches='tight', dpi=100)\n        print(f\"    âœ… Saved: {save_path}\")\n    \n    if CONFIG[\"show_on_screen\"]:\n        plt.show()\n    plt.close()\n\ndef process_case(predictor, case_id):\n    print(f\"\\nğŸ” Processing: {case_id}...\")\n    \n    # TÃ¬m file áº£nh input\n    base_file = os.path.join(CONFIG[\"image_folder\"], f\"{case_id}_0000.nii\")\n    ext = \".nii\" if os.path.exists(base_file) else \".nii.gz\"\n    \n    image_files = [os.path.join(CONFIG[\"image_folder\"], f\"{case_id}_{i:04d}{ext}\") for i in range(4)]\n    \n    # TÃ¬m file nhÃ£n (GT)\n    gt_file = os.path.join(CONFIG[\"label_folder\"], f\"{case_id}{ext}\")\n    if not os.path.exists(gt_file):\n        # Thá»­ tÃ¬m trong preprocessed náº¿u raw khÃ´ng cÃ³\n        gt_file = os.path.join(CONFIG[\"label_folder\"], f\"{case_id}.nii.gz\")\n    \n    if not os.path.exists(gt_file):\n        print(f\"    âš ï¸ Skipping {case_id}: Label file missing.\")\n        return\n\n    # Preprocessing & Inference\n    preprocessor = predictor.configuration_manager.preprocessor_class(verbose=False)\n    # Load vÃ  crop dá»¯ liá»‡u\n    data, seg, _ = preprocessor.run_case(image_files, gt_file, predictor.plans_manager, predictor.configuration_manager, predictor.dataset_json)\n    \n    # Predict\n    data_tensor = torch.from_numpy(data).to(predictor.device)\n    pred_logits = predictor.predict_logits_from_preprocessed_data(data_tensor)\n    \n    # TÃ­nh EDL Uncertainty\n    evidence = F.softplus(pred_logits)\n    alpha = evidence + 1\n    S = torch.sum(alpha, dim=0)\n    K = alpha.shape[0]\n    uncertainty = (K / S).cpu().numpy()\n    segmentation = torch.argmax(pred_logits, dim=0).cpu().numpy()\n    \n    visualize_comparison(case_id, data, seg, segmentation, uncertainty)\n\ndef get_validation_cases(fold=0):\n    split_file = CONFIG[\"split_file\"]\n    if not os.path.exists(split_file):\n        raise FileNotFoundError(f\"âŒ KhÃ´ng tÃ¬m tháº¥y file split táº¡i: {split_file}\")\n        \n    with open(split_file, 'r') as f:\n        splits = json.load(f)\n    \n    if fold >= len(splits):\n        raise ValueError(f\"âŒ Fold {fold} khÃ´ng tá»“n táº¡i!\")\n        \n    val_keys = splits[fold]['val']\n    print(f\"ğŸ“‚ ÄÃ£ load danh sÃ¡ch Validation Fold {fold}: {len(val_keys)} ca.\")\n    return val_keys\n\ndef main():\n    print(\"ğŸš€ --- BATCH INFERENCE STARTED ---\")\n    \n    # Load Model\n    predictor = nnUNetPredictor(\n        tile_step_size=0.5, use_gaussian=True, use_mirroring=True,\n        device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'),\n        verbose=False\n    )\n    \n    checkpoint_folder = os.path.dirname(os.path.dirname(CONFIG[\"checkpoint_path\"]))\n    # nnUNetPredictor tá»± tÃ¬m fold_X trong folder nÃ y\n    predictor.initialize_from_trained_model_folder(checkpoint_folder, use_folds=(0,), checkpoint_name=\"checkpoint_best.pth\")\n    print(f\"ğŸ“‚ Model Loaded.\")\n\n    if CONFIG[\"run_mode\"] == \"validation_split\":\n        cases_to_run = get_validation_cases(fold=0)\n        # cases_to_run = cases_to_run[:5] # Bá» comment náº¿u muá»‘n test nhanh 5 ca Ä‘áº§u\n        print(f\"âš™ï¸ Mode: VALIDATION SPLIT (Fold 0) -> Running {len(cases_to_run)} cases.\")\n    else:\n        # Code cho mode random/range giá»¯ nguyÃªn\n        pass\n\n    for case_id in cases_to_run:\n        try:\n            process_case(predictor, case_id)\n        except Exception as e:\n            print(f\"    âŒ Error processing {case_id}: {e}\")\n\n    print(\"\\nâœ… --- BATCH INFERENCE FINISHED ---\")\n    \n    # NÃ©n áº£nh káº¿t quáº£ Ä‘á»ƒ táº£i vá»\n    shutil.make_archive(\"/kaggle/working/inference_images\", 'zip', CONFIG[\"output_folder\"])\n    print(\"ğŸ“¦ ÄÃ£ nÃ©n áº£nh káº¿t quáº£: /kaggle/working/inference_images.zip\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:44:37.673516Z","iopub.execute_input":"2025-11-23T14:44:37.673838Z","iopub.status.idle":"2025-11-23T15:02:19.06526Z","shell.execute_reply.started":"2025-11-23T14:44:37.673807Z","shell.execute_reply":"2025-11-23T15:02:19.064562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}