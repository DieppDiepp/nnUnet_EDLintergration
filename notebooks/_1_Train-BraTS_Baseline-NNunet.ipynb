{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CÃ i Ä‘áº·t thÆ° viá»‡n (Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T08:37:43.969855Z",
     "iopub.status.busy": "2025-11-25T08:37:43.969619Z",
     "iopub.status.idle": "2025-11-25T08:39:16.926762Z",
     "shell.execute_reply": "2025-11-25T08:39:16.925954Z",
     "shell.execute_reply.started": "2025-11-25T08:37:43.969837Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Äang cÃ i Ä‘áº·t nnU-Net vÃ  cÃ¡c thÆ° viá»‡n phá»¥ trá»£...\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mâœ… CÃ i Ä‘áº·t hoÃ n táº¥t.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# CELL 1: SETUP & INSTALLATION\n",
    "# ------------------------------------------------------------------\n",
    "import os\n",
    "import sys\n",
    "import site\n",
    "import shutil\n",
    "\n",
    "print(\"âš™ï¸ Äang cÃ i Ä‘áº·t nnU-Net vÃ  cÃ¡c thÆ° viá»‡n phá»¥ trá»£...\")\n",
    "!pip install nnunetv2 hiddenlayer graphviz --quiet\n",
    "print(\"âœ… CÃ i Ä‘áº·t hoÃ n táº¥t.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Cáº¥u hÃ¬nh MÃ´i trÆ°á»ng & Symlink Data (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T08:39:16.930980Z",
     "iopub.status.busy": "2025-11-25T08:39:16.930739Z",
     "iopub.status.idle": "2025-11-25T08:39:16.969718Z",
     "shell.execute_reply": "2025-11-25T08:39:16.969164Z",
     "shell.execute_reply.started": "2025-11-25T08:39:16.930945Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Äang táº¡o Symlink cho dá»¯ liá»‡u...\n",
      "âœ… Cáº¥u hÃ¬nh Data & MÃ´i trÆ°á»ng hoÃ n táº¥t.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# CELL 2: CONFIGURATION & DATA PREPARATION\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng\n",
    "os.environ['nnUNet_raw'] = \"/kaggle/temp/nnUNet_raw\"\n",
    "os.environ['nnUNet_preprocessed'] = \"/kaggle/temp/nnUNet_preprocessed\"\n",
    "os.environ['nnUNet_results'] = \"/kaggle/working/nnUNet_results\" \n",
    "os.environ['nnUNet_compile'] = 'F' # FIX Lá»–I P100: Táº¯t torch.compile\n",
    "\n",
    "# Táº¡o folder gá»‘c\n",
    "for path in [os.environ['nnUNet_raw'], os.environ['nnUNet_preprocessed'], os.environ['nnUNet_results']]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# 2. Xá»­ lÃ½ Symlink cho Data (Ká»¹ thuáº­t tiáº¿t kiá»‡m bá»™ nhá»› Kaggle)\n",
    "print(\"ğŸ”— Äang táº¡o Symlink cho dá»¯ liá»‡u...\")\n",
    "\n",
    "# --- Preprocessed Data ---\n",
    "input_preprocessed_plans = \"/kaggle/input/ds312-nnunet-edl/nnUNET_preprocessed/nnUNET_preprocessed/Dataset101_BraTS2020/nnUNetPlans_3d_fullres\"\n",
    "input_preprocessed_root = os.path.dirname(input_preprocessed_plans)\n",
    "target_preprocessed_dataset = os.path.join(os.environ['nnUNet_preprocessed'], \"Dataset101_BraTS2020\")\n",
    "os.makedirs(target_preprocessed_dataset, exist_ok=True)\n",
    "\n",
    "# Link folder náº·ng\n",
    "target_plans_dir = os.path.join(target_preprocessed_dataset, \"nnUNetPlans_3d_fullres\")\n",
    "if not os.path.exists(target_plans_dir):\n",
    "    os.symlink(input_preprocessed_plans, target_plans_dir)\n",
    "\n",
    "# --- THÃŠM ÄOáº N NÃ€Y VÃ€O CELL 2 ---\n",
    "# 1.1 Link folder 'gt_segmentations' (Äá»ƒ cháº¡y bÆ°á»›c cháº¥m Ä‘iá»ƒm cuá»‘i cÃ¹ng)\n",
    "input_gt_dir = \"/kaggle/input/ds312-nnunet-edl/nnUNET_preprocessed/nnUNET_preprocessed/Dataset101_BraTS2020/gt_segmentations\"\n",
    "target_gt_dir = os.path.join(target_preprocessed_dataset, \"gt_segmentations\")\n",
    "if not os.path.exists(target_gt_dir):\n",
    "    os.symlink(input_gt_dir, target_gt_dir)\n",
    "    \n",
    "# Copy file nháº¹ (json/pkl)\n",
    "for item in os.listdir(input_preprocessed_root):\n",
    "    s = os.path.join(input_preprocessed_root, item)\n",
    "    d = os.path.join(target_preprocessed_dataset, item)\n",
    "    if os.path.isfile(s) and (item.endswith(\".json\") or item.endswith(\".pkl\")):\n",
    "        shutil.copy(s, d)\n",
    "\n",
    "# --- Raw Data (Optional nhÆ°ng tá»‘t Ä‘á»ƒ verify) ---\n",
    "input_raw_images = \"/kaggle/input/ds312-nnunet-edl/nnUNET_raw/nnUNET_raw/Dataset101_BraTS2020/imagesTr\"\n",
    "input_raw_root = os.path.dirname(input_raw_images)\n",
    "target_raw_dataset = os.path.join(os.environ['nnUNet_raw'], \"Dataset101_BraTS2020\")\n",
    "os.makedirs(target_raw_dataset, exist_ok=True)\n",
    "\n",
    "target_imagesTr = os.path.join(target_raw_dataset, \"imagesTr\")\n",
    "if not os.path.exists(target_imagesTr):\n",
    "    os.symlink(input_raw_images, target_imagesTr)\n",
    "\n",
    "raw_json_path = os.path.join(input_raw_root, \"dataset.json\")\n",
    "if os.path.exists(raw_json_path):\n",
    "    shutil.copy(raw_json_path, os.path.join(target_raw_dataset, \"dataset.json\"))\n",
    "\n",
    "print(\"âœ… Cáº¥u hÃ¬nh Data & MÃ´i trÆ°á»ng hoÃ n táº¥t.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Thá»±c thi Training (Execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T08:39:37.563237Z",
     "iopub.status.busy": "2025-11-25T08:39:37.562963Z",
     "iopub.status.idle": "2025-11-25T13:36:18.648305Z",
     "shell.execute_reply": "2025-11-25T13:36:18.647203Z",
     "shell.execute_reply.started": "2025-11-25T08:39:37.563218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Báº®T Äáº¦U TRAINING (Fold 0 - 30 Epochs)...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-11-25 08:39:50.225366: do_dummy_2d_data_aug: False\n",
      "2025-11-25 08:39:50.226885: Using splits from existing split file: /kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\n",
      "2025-11-25 08:39:50.227391: The split file contains 5 splits.\n",
      "2025-11-25 08:39:50.227484: Desired fold for training: 0\n",
      "2025-11-25 08:39:50.227569: This split has 294 training and 74 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [139.0, 170.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset101_BraTS2020', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [139, 170, 138], 'image_reader_writer': 'NibabelIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 29422.0, 'mean': 724.156982421875, 'median': 428.0, 'min': 0.0, 'percentile_00_5': 73.0, 'percentile_99_5': 16634.0, 'std': 1905.18603515625}, '1': {'max': 20094.0, 'mean': 644.5623779296875, 'median': 356.0, 'min': 0.0, 'percentile_00_5': 37.0, 'percentile_99_5': 8509.0, 'std': 1026.4256591796875}, '2': {'max': 18011.0, 'mean': 793.357421875, 'median': 415.0, 'min': 0.0, 'percentile_00_5': 36.0, 'percentile_99_5': 8117.0, 'std': 1158.4361572265625}, '3': {'max': 31404.0, 'mean': 1070.999267578125, 'median': 665.0, 'min': 0.0, 'percentile_00_5': 96.0, 'percentile_99_5': 16393.0, 'std': 1994.0704345703125}}} \n",
      "\n",
      "2025-11-25 08:40:24.189965: Unable to plot network architecture:\n",
      "2025-11-25 08:40:24.190289: module 'torch.onnx' has no attribute '_optimize_trace'\n",
      "2025-11-25 08:40:24.278796: \n",
      "2025-11-25 08:40:24.279072: Epoch 0\n",
      "2025-11-25 08:40:24.279271: Current learning rate: 0.01\n",
      "2025-11-25 08:48:22.473887: train_loss -0.224\n",
      "2025-11-25 08:48:22.474615: val_loss -0.4465\n",
      "2025-11-25 08:48:22.475452: Pseudo dice [0.4318, 0.717, 0.7891]\n",
      "2025-11-25 08:48:22.475567: Epoch time: 478.2 s\n",
      "2025-11-25 08:48:22.475667: Yayy! New best EMA pseudo Dice: 0.646\n",
      "2025-11-25 08:48:24.386564: \n",
      "2025-11-25 08:48:24.386791: Epoch 1\n",
      "2025-11-25 08:48:24.386977: Current learning rate: 0.00999\n",
      "2025-11-25 08:54:13.359186: train_loss -0.426\n",
      "2025-11-25 08:54:13.359797: val_loss -0.5067\n",
      "2025-11-25 08:54:13.359990: Pseudo dice [0.4487, 0.7572, 0.7794]\n",
      "2025-11-25 08:54:13.360130: Epoch time: 348.97 s\n",
      "2025-11-25 08:54:13.360270: Yayy! New best EMA pseudo Dice: 0.6475\n",
      "2025-11-25 08:54:15.716068: \n",
      "2025-11-25 08:54:15.716390: Epoch 2\n",
      "2025-11-25 08:54:15.716570: Current learning rate: 0.00998\n",
      "2025-11-25 09:00:04.588481: train_loss -0.4886\n",
      "2025-11-25 09:00:04.588829: val_loss -0.5368\n",
      "2025-11-25 09:00:04.589029: Pseudo dice [0.5661, 0.7534, 0.7915]\n",
      "2025-11-25 09:00:04.589155: Epoch time: 348.87 s\n",
      "2025-11-25 09:00:04.589265: Yayy! New best EMA pseudo Dice: 0.6532\n",
      "2025-11-25 09:00:07.235526: \n",
      "2025-11-25 09:00:07.235886: Epoch 3\n",
      "2025-11-25 09:00:07.236061: Current learning rate: 0.00997\n",
      "2025-11-25 09:05:56.275898: train_loss -0.534\n",
      "2025-11-25 09:05:56.276164: val_loss -0.6079\n",
      "2025-11-25 09:05:56.276268: Pseudo dice [0.6298, 0.7725, 0.8168]\n",
      "2025-11-25 09:05:56.276386: Epoch time: 349.04 s\n",
      "2025-11-25 09:05:56.276465: Yayy! New best EMA pseudo Dice: 0.6618\n",
      "2025-11-25 09:05:58.558698: \n",
      "2025-11-25 09:05:58.558990: Epoch 4\n",
      "2025-11-25 09:05:58.559173: Current learning rate: 0.00996\n",
      "2025-11-25 09:11:47.493251: train_loss -0.5444\n",
      "2025-11-25 09:11:47.493535: val_loss -0.5933\n",
      "2025-11-25 09:11:47.493713: Pseudo dice [0.6191, 0.8095, 0.7974]\n",
      "2025-11-25 09:11:47.493925: Epoch time: 348.94 s\n",
      "2025-11-25 09:11:47.494123: Yayy! New best EMA pseudo Dice: 0.6698\n",
      "2025-11-25 09:11:49.730180: \n",
      "2025-11-25 09:11:49.730505: Epoch 5\n",
      "2025-11-25 09:11:49.730699: Current learning rate: 0.00995\n",
      "2025-11-25 09:17:38.663253: train_loss -0.5748\n",
      "2025-11-25 09:17:38.663691: val_loss -0.5889\n",
      "2025-11-25 09:17:38.663872: Pseudo dice [0.6575, 0.8095, 0.8208]\n",
      "2025-11-25 09:17:38.664034: Epoch time: 348.93 s\n",
      "2025-11-25 09:17:38.664172: Yayy! New best EMA pseudo Dice: 0.6791\n",
      "2025-11-25 09:17:40.941772: \n",
      "2025-11-25 09:17:40.942088: Epoch 6\n",
      "2025-11-25 09:17:40.942268: Current learning rate: 0.00995\n",
      "2025-11-25 09:23:29.745067: train_loss -0.5768\n",
      "2025-11-25 09:23:29.745367: val_loss -0.5948\n",
      "2025-11-25 09:23:29.745538: Pseudo dice [0.6509, 0.7872, 0.8452]\n",
      "2025-11-25 09:23:29.745732: Epoch time: 348.8 s\n",
      "2025-11-25 09:23:29.745903: Yayy! New best EMA pseudo Dice: 0.6873\n",
      "2025-11-25 09:23:31.988459: \n",
      "2025-11-25 09:23:31.988679: Epoch 7\n",
      "2025-11-25 09:23:31.988909: Current learning rate: 0.00994\n",
      "2025-11-25 09:29:20.867790: train_loss -0.5757\n",
      "2025-11-25 09:29:20.868077: val_loss -0.6401\n",
      "2025-11-25 09:29:20.868223: Pseudo dice [0.6624, 0.8184, 0.8399]\n",
      "2025-11-25 09:29:20.868372: Epoch time: 348.88 s\n",
      "2025-11-25 09:29:20.868512: Yayy! New best EMA pseudo Dice: 0.6959\n",
      "2025-11-25 09:29:23.132535: \n",
      "2025-11-25 09:29:23.132916: Epoch 8\n",
      "2025-11-25 09:29:23.133066: Current learning rate: 0.00993\n",
      "2025-11-25 09:35:11.921926: train_loss -0.6085\n",
      "2025-11-25 09:35:11.922198: val_loss -0.6591\n",
      "2025-11-25 09:35:11.922309: Pseudo dice [0.7132, 0.8122, 0.862]\n",
      "2025-11-25 09:35:11.922391: Epoch time: 348.79 s\n",
      "2025-11-25 09:35:11.922459: Yayy! New best EMA pseudo Dice: 0.7059\n",
      "2025-11-25 09:35:14.087066: \n",
      "2025-11-25 09:35:14.087355: Epoch 9\n",
      "2025-11-25 09:35:14.087525: Current learning rate: 0.00992\n",
      "2025-11-25 09:41:02.858307: train_loss -0.612\n",
      "2025-11-25 09:41:02.858570: val_loss -0.6588\n",
      "2025-11-25 09:41:02.858731: Pseudo dice [0.7306, 0.8252, 0.8475]\n",
      "2025-11-25 09:41:02.858906: Epoch time: 348.77 s\n",
      "2025-11-25 09:41:02.859004: Yayy! New best EMA pseudo Dice: 0.7154\n",
      "2025-11-25 09:41:05.064085: \n",
      "2025-11-25 09:41:05.064235: Epoch 10\n",
      "2025-11-25 09:41:05.064392: Current learning rate: 0.00991\n",
      "2025-11-25 09:46:53.865852: train_loss -0.6202\n",
      "2025-11-25 09:46:53.866144: val_loss -0.6631\n",
      "2025-11-25 09:46:53.866255: Pseudo dice [0.7009, 0.8224, 0.8596]\n",
      "2025-11-25 09:46:53.866352: Epoch time: 348.8 s\n",
      "2025-11-25 09:46:53.866428: Yayy! New best EMA pseudo Dice: 0.7233\n",
      "2025-11-25 09:46:56.043412: \n",
      "2025-11-25 09:46:56.043594: Epoch 11\n",
      "2025-11-25 09:46:56.043784: Current learning rate: 0.0099\n",
      "2025-11-25 09:52:44.962865: train_loss -0.6113\n",
      "2025-11-25 09:52:44.963150: val_loss -0.6413\n",
      "2025-11-25 09:52:44.963280: Pseudo dice [0.6792, 0.8073, 0.8567]\n",
      "2025-11-25 09:52:44.963453: Epoch time: 348.92 s\n",
      "2025-11-25 09:52:44.963534: Yayy! New best EMA pseudo Dice: 0.7291\n",
      "2025-11-25 09:52:47.453086: \n",
      "2025-11-25 09:52:47.453401: Epoch 12\n",
      "2025-11-25 09:52:47.453569: Current learning rate: 0.00989\n",
      "2025-11-25 09:58:36.276474: train_loss -0.6244\n",
      "2025-11-25 09:58:36.276814: val_loss -0.6543\n",
      "2025-11-25 09:58:36.276968: Pseudo dice [0.7206, 0.8133, 0.8453]\n",
      "2025-11-25 09:58:36.277137: Epoch time: 348.82 s\n",
      "2025-11-25 09:58:36.277235: Yayy! New best EMA pseudo Dice: 0.7355\n",
      "2025-11-25 09:58:38.394160: \n",
      "2025-11-25 09:58:38.394421: Epoch 13\n",
      "2025-11-25 09:58:38.394586: Current learning rate: 0.00988\n",
      "2025-11-25 10:04:27.080643: train_loss -0.6356\n",
      "2025-11-25 10:04:27.080999: val_loss -0.6586\n",
      "2025-11-25 10:04:27.081154: Pseudo dice [0.6994, 0.8334, 0.853]\n",
      "2025-11-25 10:04:27.081302: Epoch time: 348.69 s\n",
      "2025-11-25 10:04:27.081409: Yayy! New best EMA pseudo Dice: 0.7415\n",
      "2025-11-25 10:04:29.279988: \n",
      "2025-11-25 10:04:29.280176: Epoch 14\n",
      "2025-11-25 10:04:29.280326: Current learning rate: 0.00987\n",
      "2025-11-25 10:10:17.966416: train_loss -0.6254\n",
      "2025-11-25 10:10:17.966676: val_loss -0.6854\n",
      "2025-11-25 10:10:17.966828: Pseudo dice [0.7766, 0.8571, 0.8502]\n",
      "2025-11-25 10:10:17.966948: Epoch time: 348.69 s\n",
      "2025-11-25 10:10:17.967046: Yayy! New best EMA pseudo Dice: 0.7501\n",
      "2025-11-25 10:10:20.179856: \n",
      "2025-11-25 10:10:20.180147: Epoch 15\n",
      "2025-11-25 10:10:20.180317: Current learning rate: 0.00986\n",
      "2025-11-25 10:16:09.121315: train_loss -0.6528\n",
      "2025-11-25 10:16:09.121603: val_loss -0.6666\n",
      "2025-11-25 10:16:09.121708: Pseudo dice [0.6524, 0.8344, 0.8812]\n",
      "2025-11-25 10:16:09.121854: Epoch time: 348.94 s\n",
      "2025-11-25 10:16:09.121928: Yayy! New best EMA pseudo Dice: 0.754\n",
      "2025-11-25 10:16:11.355451: \n",
      "2025-11-25 10:16:11.355741: Epoch 16\n",
      "2025-11-25 10:16:11.355922: Current learning rate: 0.00986\n",
      "2025-11-25 10:22:00.156622: train_loss -0.6463\n",
      "2025-11-25 10:22:00.156900: val_loss -0.7006\n",
      "2025-11-25 10:22:00.157059: Pseudo dice [0.7955, 0.8619, 0.8877]\n",
      "2025-11-25 10:22:00.157176: Epoch time: 348.8 s\n",
      "2025-11-25 10:22:00.157316: Yayy! New best EMA pseudo Dice: 0.7635\n",
      "2025-11-25 10:22:02.519730: \n",
      "2025-11-25 10:22:02.520063: Epoch 17\n",
      "2025-11-25 10:22:02.520230: Current learning rate: 0.00985\n",
      "2025-11-25 10:27:51.268784: train_loss -0.6327\n",
      "2025-11-25 10:27:51.269084: val_loss -0.6252\n",
      "2025-11-25 10:27:51.269208: Pseudo dice [0.7292, 0.7943, 0.8339]\n",
      "2025-11-25 10:27:51.269299: Epoch time: 348.75 s\n",
      "2025-11-25 10:27:51.269406: Yayy! New best EMA pseudo Dice: 0.7657\n",
      "2025-11-25 10:27:53.569594: \n",
      "2025-11-25 10:27:53.569814: Epoch 18\n",
      "2025-11-25 10:27:53.570011: Current learning rate: 0.00984\n",
      "2025-11-25 10:33:42.464117: train_loss -0.6388\n",
      "2025-11-25 10:33:42.464374: val_loss -0.6862\n",
      "2025-11-25 10:33:42.464537: Pseudo dice [0.7625, 0.8504, 0.8767]\n",
      "2025-11-25 10:33:42.464689: Epoch time: 348.9 s\n",
      "2025-11-25 10:33:42.464858: Yayy! New best EMA pseudo Dice: 0.7721\n",
      "2025-11-25 10:33:44.754816: \n",
      "2025-11-25 10:33:44.755129: Epoch 19\n",
      "2025-11-25 10:33:44.755298: Current learning rate: 0.00983\n",
      "2025-11-25 10:39:33.526048: train_loss -0.6656\n",
      "2025-11-25 10:39:33.526308: val_loss -0.6753\n",
      "2025-11-25 10:39:33.526440: Pseudo dice [0.7634, 0.8281, 0.8548]\n",
      "2025-11-25 10:39:33.526555: Epoch time: 348.77 s\n",
      "2025-11-25 10:39:33.526655: Yayy! New best EMA pseudo Dice: 0.7765\n",
      "2025-11-25 10:39:36.088622: \n",
      "2025-11-25 10:39:36.088964: Epoch 20\n",
      "2025-11-25 10:39:36.089129: Current learning rate: 0.00982\n",
      "2025-11-25 10:45:24.866669: train_loss -0.6477\n",
      "2025-11-25 10:45:24.867264: val_loss -0.6695\n",
      "2025-11-25 10:45:24.867418: Pseudo dice [0.7257, 0.8361, 0.8678]\n",
      "2025-11-25 10:45:24.867563: Epoch time: 348.78 s\n",
      "2025-11-25 10:45:24.867670: Yayy! New best EMA pseudo Dice: 0.7798\n",
      "2025-11-25 10:45:27.136635: \n",
      "2025-11-25 10:45:27.136921: Epoch 21\n",
      "2025-11-25 10:45:27.137071: Current learning rate: 0.00981\n",
      "2025-11-25 10:51:15.972257: train_loss -0.6446\n",
      "2025-11-25 10:51:15.972519: val_loss -0.6854\n",
      "2025-11-25 10:51:15.972667: Pseudo dice [0.7708, 0.8413, 0.8581]\n",
      "2025-11-25 10:51:15.972879: Epoch time: 348.84 s\n",
      "2025-11-25 10:51:15.972991: Yayy! New best EMA pseudo Dice: 0.7842\n",
      "2025-11-25 10:51:18.127713: \n",
      "2025-11-25 10:51:18.127908: Epoch 22\n",
      "2025-11-25 10:51:18.128177: Current learning rate: 0.0098\n",
      "2025-11-25 10:57:06.910726: train_loss -0.6521\n",
      "2025-11-25 10:57:06.911041: val_loss -0.6803\n",
      "2025-11-25 10:57:06.911260: Pseudo dice [0.767, 0.8424, 0.8545]\n",
      "2025-11-25 10:57:06.911360: Epoch time: 348.78 s\n",
      "2025-11-25 10:57:06.911434: Yayy! New best EMA pseudo Dice: 0.7879\n",
      "2025-11-25 10:57:09.063608: \n",
      "2025-11-25 10:57:09.063869: Epoch 23\n",
      "2025-11-25 10:57:09.064032: Current learning rate: 0.00979\n",
      "2025-11-25 11:02:57.865565: train_loss -0.6649\n",
      "2025-11-25 11:02:57.865952: val_loss -0.7208\n",
      "2025-11-25 11:02:57.866092: Pseudo dice [0.799, 0.8641, 0.8528]\n",
      "2025-11-25 11:02:57.866212: Epoch time: 348.8 s\n",
      "2025-11-25 11:02:57.866306: Yayy! New best EMA pseudo Dice: 0.7929\n",
      "2025-11-25 11:03:00.022915: \n",
      "2025-11-25 11:03:00.023161: Epoch 24\n",
      "2025-11-25 11:03:00.023325: Current learning rate: 0.00978\n",
      "2025-11-25 11:08:48.792432: train_loss -0.6552\n",
      "2025-11-25 11:08:48.792800: val_loss -0.6971\n",
      "2025-11-25 11:08:48.793008: Pseudo dice [0.7737, 0.8508, 0.8728]\n",
      "2025-11-25 11:08:48.793226: Epoch time: 348.77 s\n",
      "2025-11-25 11:08:48.793322: Yayy! New best EMA pseudo Dice: 0.7969\n",
      "2025-11-25 11:08:51.012970: \n",
      "2025-11-25 11:08:51.013324: Epoch 25\n",
      "2025-11-25 11:08:51.013498: Current learning rate: 0.00977\n",
      "2025-11-25 11:14:39.813447: train_loss -0.6617\n",
      "2025-11-25 11:14:39.813848: val_loss -0.6523\n",
      "2025-11-25 11:14:39.813982: Pseudo dice [0.7655, 0.8188, 0.8515]\n",
      "2025-11-25 11:14:39.814088: Epoch time: 348.8 s\n",
      "2025-11-25 11:14:39.814176: Yayy! New best EMA pseudo Dice: 0.7984\n",
      "2025-11-25 11:14:42.055877: \n",
      "2025-11-25 11:14:42.056180: Epoch 26\n",
      "2025-11-25 11:14:42.056343: Current learning rate: 0.00977\n",
      "2025-11-25 11:20:30.846234: train_loss -0.672\n",
      "2025-11-25 11:20:30.846495: val_loss -0.7298\n",
      "2025-11-25 11:20:30.846647: Pseudo dice [0.8033, 0.8572, 0.8814]\n",
      "2025-11-25 11:20:30.846807: Epoch time: 348.79 s\n",
      "2025-11-25 11:20:30.846958: Yayy! New best EMA pseudo Dice: 0.8033\n",
      "2025-11-25 11:20:33.007301: \n",
      "2025-11-25 11:20:33.007598: Epoch 27\n",
      "2025-11-25 11:20:33.007787: Current learning rate: 0.00976\n",
      "2025-11-25 11:26:21.982853: train_loss -0.6716\n",
      "2025-11-25 11:26:21.983221: val_loss -0.6499\n",
      "2025-11-25 11:26:21.983368: Pseudo dice [0.7634, 0.8444, 0.8606]\n",
      "2025-11-25 11:26:21.983489: Epoch time: 348.98 s\n",
      "2025-11-25 11:26:21.983592: Yayy! New best EMA pseudo Dice: 0.8052\n",
      "2025-11-25 11:26:24.732514: \n",
      "2025-11-25 11:26:24.732711: Epoch 28\n",
      "2025-11-25 11:26:24.732875: Current learning rate: 0.00975\n",
      "2025-11-25 11:32:13.827411: train_loss -0.6769\n",
      "2025-11-25 11:32:13.827734: val_loss -0.7154\n",
      "2025-11-25 11:32:13.827960: Pseudo dice [0.8121, 0.8658, 0.8894]\n",
      "2025-11-25 11:32:13.828117: Epoch time: 349.1 s\n",
      "2025-11-25 11:32:13.828228: Yayy! New best EMA pseudo Dice: 0.8103\n",
      "2025-11-25 11:32:16.204599: \n",
      "2025-11-25 11:32:16.204960: Epoch 29\n",
      "2025-11-25 11:32:16.205100: Current learning rate: 0.00974\n",
      "2025-11-25 11:38:05.549189: train_loss -0.6783\n",
      "2025-11-25 11:38:05.549495: val_loss -0.6968\n",
      "2025-11-25 11:38:05.549653: Pseudo dice [0.7882, 0.8607, 0.868]\n",
      "2025-11-25 11:38:05.549803: Epoch time: 349.35 s\n",
      "2025-11-25 11:38:05.549925: Yayy! New best EMA pseudo Dice: 0.8132\n",
      "2025-11-25 11:38:07.924171: \n",
      "2025-11-25 11:38:07.924475: Epoch 30\n",
      "2025-11-25 11:38:07.924666: Current learning rate: 0.00973\n",
      "2025-11-25 11:43:56.994990: train_loss -0.6662\n",
      "2025-11-25 11:43:56.995297: val_loss -0.67\n",
      "2025-11-25 11:43:56.995564: Pseudo dice [0.7401, 0.8547, 0.848]\n",
      "2025-11-25 11:43:56.995781: Epoch time: 349.07 s\n",
      "2025-11-25 11:43:56.995910: Yayy! New best EMA pseudo Dice: 0.8133\n",
      "2025-11-25 11:43:59.365237: \n",
      "2025-11-25 11:43:59.365532: Epoch 31\n",
      "2025-11-25 11:43:59.365731: Current learning rate: 0.00972\n",
      "2025-11-25 11:49:48.703657: train_loss -0.6576\n",
      "2025-11-25 11:49:48.704041: val_loss -0.6474\n",
      "2025-11-25 11:49:48.704159: Pseudo dice [0.6872, 0.8213, 0.8697]\n",
      "2025-11-25 11:49:48.704254: Epoch time: 349.34 s\n",
      "2025-11-25 11:49:50.584568: \n",
      "2025-11-25 11:49:50.584949: Epoch 32\n",
      "2025-11-25 11:49:50.585112: Current learning rate: 0.00971\n",
      "2025-11-25 11:55:39.621071: train_loss -0.6768\n",
      "2025-11-25 11:55:39.621422: val_loss -0.6708\n",
      "2025-11-25 11:55:39.621587: Pseudo dice [0.7044, 0.8273, 0.878]\n",
      "2025-11-25 11:55:39.621724: Epoch time: 349.04 s\n",
      "2025-11-25 11:55:41.471013: \n",
      "2025-11-25 11:55:41.471351: Epoch 33\n",
      "2025-11-25 11:55:41.471494: Current learning rate: 0.0097\n",
      "2025-11-25 12:01:30.725270: train_loss -0.6812\n",
      "2025-11-25 12:01:30.725775: val_loss -0.719\n",
      "2025-11-25 12:01:30.725990: Pseudo dice [0.7657, 0.8561, 0.883]\n",
      "2025-11-25 12:01:30.726155: Epoch time: 349.26 s\n",
      "2025-11-25 12:01:32.531204: \n",
      "2025-11-25 12:01:32.531510: Epoch 34\n",
      "2025-11-25 12:01:32.531657: Current learning rate: 0.00969\n",
      "2025-11-25 12:07:21.608539: train_loss -0.6605\n",
      "2025-11-25 12:07:21.608905: val_loss -0.6654\n",
      "2025-11-25 12:07:21.609025: Pseudo dice [0.8023, 0.7865, 0.8698]\n",
      "2025-11-25 12:07:21.609126: Epoch time: 349.08 s\n",
      "2025-11-25 12:07:21.609209: Yayy! New best EMA pseudo Dice: 0.8135\n",
      "2025-11-25 12:07:23.984432: \n",
      "2025-11-25 12:07:23.984823: Epoch 35\n",
      "2025-11-25 12:07:23.984987: Current learning rate: 0.00968\n",
      "2025-11-25 12:13:12.807181: train_loss -0.6684\n",
      "2025-11-25 12:13:12.807487: val_loss -0.7372\n",
      "2025-11-25 12:13:12.807643: Pseudo dice [0.767, 0.8707, 0.8856]\n",
      "2025-11-25 12:13:12.807796: Epoch time: 348.82 s\n",
      "2025-11-25 12:13:12.807914: Yayy! New best EMA pseudo Dice: 0.8163\n",
      "2025-11-25 12:13:15.082685: \n",
      "2025-11-25 12:13:15.082926: Epoch 36\n",
      "2025-11-25 12:13:15.083076: Current learning rate: 0.00968\n",
      "2025-11-25 12:19:03.899681: train_loss -0.6858\n",
      "2025-11-25 12:19:03.900062: val_loss -0.7201\n",
      "2025-11-25 12:19:03.900217: Pseudo dice [0.7902, 0.8537, 0.8894]\n",
      "2025-11-25 12:19:03.900349: Epoch time: 348.82 s\n",
      "2025-11-25 12:19:03.900432: Yayy! New best EMA pseudo Dice: 0.8191\n",
      "2025-11-25 12:19:06.185001: \n",
      "2025-11-25 12:19:06.185254: Epoch 37\n",
      "2025-11-25 12:19:06.185414: Current learning rate: 0.00967\n",
      "2025-11-25 12:24:55.206361: train_loss -0.6886\n",
      "2025-11-25 12:24:55.206675: val_loss -0.7267\n",
      "2025-11-25 12:24:55.206924: Pseudo dice [0.7682, 0.8601, 0.882]\n",
      "2025-11-25 12:24:55.207052: Epoch time: 349.02 s\n",
      "2025-11-25 12:24:55.207136: Yayy! New best EMA pseudo Dice: 0.8209\n",
      "2025-11-25 12:24:57.521056: \n",
      "2025-11-25 12:24:57.521235: Epoch 38\n",
      "2025-11-25 12:24:57.521397: Current learning rate: 0.00966\n",
      "2025-11-25 12:30:46.273190: train_loss -0.6819\n",
      "2025-11-25 12:30:46.273453: val_loss -0.7022\n",
      "2025-11-25 12:30:46.273609: Pseudo dice [0.6691, 0.839, 0.89]\n",
      "2025-11-25 12:30:46.273760: Epoch time: 348.75 s\n",
      "2025-11-25 12:30:48.013290: \n",
      "2025-11-25 12:30:48.013568: Epoch 39\n",
      "2025-11-25 12:30:48.013727: Current learning rate: 0.00965\n",
      "2025-11-25 12:36:36.752877: train_loss -0.6792\n",
      "2025-11-25 12:36:36.753179: val_loss -0.7077\n",
      "2025-11-25 12:36:36.753295: Pseudo dice [0.7953, 0.8487, 0.8872]\n",
      "2025-11-25 12:36:36.753396: Epoch time: 348.74 s\n",
      "2025-11-25 12:36:36.753510: Yayy! New best EMA pseudo Dice: 0.8212\n",
      "2025-11-25 12:36:39.035339: \n",
      "2025-11-25 12:36:39.035635: Epoch 40\n",
      "2025-11-25 12:36:39.035822: Current learning rate: 0.00964\n",
      "2025-11-25 12:42:27.960983: train_loss -0.6884\n",
      "2025-11-25 12:42:27.961358: val_loss -0.6969\n",
      "2025-11-25 12:42:27.961572: Pseudo dice [0.7176, 0.8418, 0.8736]\n",
      "2025-11-25 12:42:27.961738: Epoch time: 348.93 s\n",
      "2025-11-25 12:42:29.869412: \n",
      "2025-11-25 12:42:29.869725: Epoch 41\n",
      "2025-11-25 12:42:29.869927: Current learning rate: 0.00963\n",
      "2025-11-25 12:48:19.098834: train_loss -0.6871\n",
      "2025-11-25 12:48:19.099160: val_loss -0.6999\n",
      "2025-11-25 12:48:19.099356: Pseudo dice [0.7432, 0.8481, 0.8723]\n",
      "2025-11-25 12:48:19.099639: Epoch time: 349.23 s\n",
      "2025-11-25 12:48:20.998209: \n",
      "2025-11-25 12:48:20.998451: Epoch 42\n",
      "2025-11-25 12:48:20.998584: Current learning rate: 0.00962\n",
      "2025-11-25 12:54:10.275101: train_loss -0.6706\n",
      "2025-11-25 12:54:10.275473: val_loss -0.6784\n",
      "2025-11-25 12:54:10.275634: Pseudo dice [0.7313, 0.8287, 0.8647]\n",
      "2025-11-25 12:54:10.275784: Epoch time: 349.28 s\n",
      "2025-11-25 12:54:12.113038: \n",
      "2025-11-25 12:54:12.113342: Epoch 43\n",
      "2025-11-25 12:54:12.113497: Current learning rate: 0.00961\n",
      "2025-11-25 13:00:01.388170: train_loss -0.6713\n",
      "2025-11-25 13:00:01.388486: val_loss -0.6914\n",
      "2025-11-25 13:00:01.388663: Pseudo dice [0.7456, 0.8458, 0.8636]\n",
      "2025-11-25 13:00:01.389003: Epoch time: 349.28 s\n",
      "2025-11-25 13:00:03.190361: \n",
      "2025-11-25 13:00:03.190526: Epoch 44\n",
      "2025-11-25 13:00:03.190690: Current learning rate: 0.0096\n",
      "2025-11-25 13:05:52.429910: train_loss -0.6638\n",
      "2025-11-25 13:05:52.430228: val_loss -0.7201\n",
      "2025-11-25 13:05:52.430452: Pseudo dice [0.7729, 0.8453, 0.8852]\n",
      "2025-11-25 13:05:52.430735: Epoch time: 349.24 s\n",
      "2025-11-25 13:05:54.686862: \n",
      "2025-11-25 13:05:54.687177: Epoch 45\n",
      "2025-11-25 13:05:54.687337: Current learning rate: 0.00959\n",
      "2025-11-25 13:11:44.198407: train_loss -0.6898\n",
      "2025-11-25 13:11:44.198729: val_loss -0.6834\n",
      "2025-11-25 13:11:44.198947: Pseudo dice [0.7648, 0.8507, 0.8674]\n",
      "2025-11-25 13:11:44.199131: Epoch time: 349.51 s\n",
      "2025-11-25 13:11:44.199250: Yayy! New best EMA pseudo Dice: 0.8213\n",
      "2025-11-25 13:11:46.628606: \n",
      "2025-11-25 13:11:46.628952: Epoch 46\n",
      "2025-11-25 13:11:46.629127: Current learning rate: 0.00959\n",
      "2025-11-25 13:17:36.125564: train_loss -0.6728\n",
      "2025-11-25 13:17:36.126050: val_loss -0.7238\n",
      "2025-11-25 13:17:36.126277: Pseudo dice [0.7983, 0.8495, 0.8885]\n",
      "2025-11-25 13:17:36.126462: Epoch time: 349.5 s\n",
      "2025-11-25 13:17:36.126611: Yayy! New best EMA pseudo Dice: 0.8237\n",
      "2025-11-25 13:17:38.593726: \n",
      "2025-11-25 13:17:38.594061: Epoch 47\n",
      "2025-11-25 13:17:38.594233: Current learning rate: 0.00958\n",
      "2025-11-25 13:23:27.878403: train_loss -0.7075\n",
      "2025-11-25 13:23:27.878740: val_loss -0.7441\n",
      "2025-11-25 13:23:27.878927: Pseudo dice [0.8315, 0.8772, 0.8923]\n",
      "2025-11-25 13:23:27.879063: Epoch time: 349.29 s\n",
      "2025-11-25 13:23:27.879182: Yayy! New best EMA pseudo Dice: 0.828\n",
      "2025-11-25 13:23:30.214315: \n",
      "2025-11-25 13:23:30.214534: Epoch 48\n",
      "2025-11-25 13:23:30.214712: Current learning rate: 0.00957\n",
      "2025-11-25 13:29:19.459355: train_loss -0.6829\n",
      "2025-11-25 13:29:19.459677: val_loss -0.7121\n",
      "2025-11-25 13:29:19.459955: Pseudo dice [0.7983, 0.8647, 0.8835]\n",
      "2025-11-25 13:29:19.460144: Epoch time: 349.25 s\n",
      "2025-11-25 13:29:19.460290: Yayy! New best EMA pseudo Dice: 0.8301\n",
      "2025-11-25 13:29:21.949071: \n",
      "2025-11-25 13:29:21.949522: Epoch 49\n",
      "2025-11-25 13:29:21.949688: Current learning rate: 0.00956\n",
      "2025-11-25 13:35:11.456141: train_loss -0.685\n",
      "2025-11-25 13:35:11.456487: val_loss -0.7082\n",
      "2025-11-25 13:35:11.456645: Pseudo dice [0.8033, 0.8349, 0.8633]\n",
      "2025-11-25 13:35:11.456798: Epoch time: 349.51 s\n",
      "2025-11-25 13:35:11.801347: Yayy! New best EMA pseudo Dice: 0.8305\n",
      "2025-11-25 13:35:14.266264: \n",
      "2025-11-25 13:35:14.266562: Epoch 50\n",
      "2025-11-25 13:35:14.266773: Current learning rate: 0.00955\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 266, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/run/run_training.py\", line 207, in run_training\n",
      "    nnunet_trainer.run_training()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1371, in run_training\n",
      "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 989, in train_step\n",
      "    output = self.network(data)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/dynamic_network_architectures/architectures/unet.py\", line 93, in forward\n",
      "    skips = self.encoder(x)\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/dynamic_network_architectures/building_blocks/plain_conv_encoder.py\", line 86, in forward\n",
      "    x = s(x)\n",
      "        ^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py\", line 137, in forward\n",
      "    return self.convs(x)\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/dynamic_network_architectures/building_blocks/simple_conv_blocks.py\", line 71, in forward\n",
      "    return self.all_modules(x)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/instancenorm.py\", line 124, in forward\n",
      "    return self._apply_instance_norm(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/instancenorm.py\", line 47, in _apply_instance_norm\n",
      "    return F.instance_norm(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 2876, in instance_norm\n",
      "    return torch.instance_norm(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Exception in thread Thread-1 (results_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 125, in results_loop\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 108, in results_loop\n",
      "    item = in_queue.get()\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 519, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# CELL 4: START TRAINING\n",
    "# ------------------------------------------------------------------\n",
    "print(\"ğŸš€ Báº®T Äáº¦U TRAINING (Fold 0 - 30 Epochs)...\")\n",
    "# LÆ°u Ã½: Cá» --npz sáº½ lÆ°u file .npz ráº¥t náº·ng. Náº¿u sá»£ trÃ n á»• cá»©ng Kaggle thÃ¬ xÃ³a cá» nÃ y Ä‘i.\n",
    "!nnUNetv2_train Dataset101_BraTS2020 3d_fullres 0 --npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: ÄÃ³ng gÃ³i & Xuáº¥t káº¿t quáº£ (Export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T13:38:16.206757Z",
     "iopub.status.busy": "2025-11-25T13:38:16.206177Z",
     "iopub.status.idle": "2025-11-25T13:38:43.995331Z",
     "shell.execute_reply": "2025-11-25T13:38:43.994525Z",
     "shell.execute_reply.started": "2025-11-25T13:38:16.206716Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Äang Ä‘Ã³ng gÃ³i káº¿t quáº£...\n",
      "âœ… ÄÃ£ nÃ©n thÃ nh cÃ´ng: /kaggle/working/BraTS2020_EDL_Fold0_Results.zip\n",
      "   (Giáº£i nÃ©n ra sáº½ cÃ³ sáºµn folder nnUNet_results/Dataset101...)\n",
      "âœ… ÄÃ£ lÆ°u riÃªng splits_final.json táº¡i: /kaggle/working/splits_final.json\n",
      "ğŸ‰ HOÃ€N Táº¤T! Báº N CÃ“ THá»‚ Táº¢I FILE Vá»€ Tá»ª TAB OUTPUT.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# CELL 5: EXPORT RESULTS (CODE NÃ‰N GIá»® NGUYÃŠN Cáº¤U TRÃšC FOLDER)\n",
    "# ------------------------------------------------------------------\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“¦ Äang Ä‘Ã³ng gÃ³i káº¿t quáº£...\")\n",
    "\n",
    "# 1. NÃ©n Model (Giá»¯ nguyÃªn cáº¥u trÃºc nnUNet_results/...)\n",
    "# ChÃºng ta sáº½ nÃ©n tá»« thÆ° má»¥c gá»‘c /kaggle/working\n",
    "output_zip_name = \"/kaggle/working/BraTS2020_EDL_Fold0_Results\"\n",
    "root_dir = \"/kaggle/working\"\n",
    "base_dir = \"nnUNet_results\" # Chá»‰ nÃ©n folder nÃ y vÃ  cÃ¡c con cá»§a nÃ³\n",
    "\n",
    "try:\n",
    "    shutil.make_archive(output_zip_name, 'zip', root_dir, base_dir)\n",
    "    print(f\"âœ… ÄÃ£ nÃ©n thÃ nh cÃ´ng: {output_zip_name}.zip\")\n",
    "    print(\"   (Giáº£i nÃ©n ra sáº½ cÃ³ sáºµn folder nnUNet_results/Dataset101...)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Lá»—i khi nÃ©n: {e}\")\n",
    "\n",
    "# 2. Copy file splits_final.json (Váº«n giá»¯ nguyÃªn bÆ°á»›c nÃ y Ä‘á»ƒ backup)\n",
    "src_split = \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\"\n",
    "dst_split = \"/kaggle/working/splits_final.json\"\n",
    "\n",
    "if os.path.exists(src_split):\n",
    "    shutil.copy(src_split, dst_split)\n",
    "    print(f\"âœ… ÄÃ£ lÆ°u riÃªng splits_final.json táº¡i: {dst_split}\")\n",
    "else:\n",
    "    print(\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file splits_final.json.\")\n",
    "\n",
    "print(\"ğŸ‰ HOÃ€N Táº¤T! Báº N CÃ“ THá»‚ Táº¢I FILE Vá»€ Tá»ª TAB OUTPUT.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: HÃ¬nh áº£nh so sÃ¡nh MRI vs AI Prediction vs Uncertainty Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T14:44:37.673838Z",
     "iopub.status.busy": "2025-11-23T14:44:37.673516Z",
     "iopub.status.idle": "2025-11-23T15:02:19.06526Z",
     "shell.execute_reply": "2025-11-23T15:02:19.064562Z",
     "shell.execute_reply.started": "2025-11-23T14:44:37.673807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# --- QUAN TRá»ŒNG: Táº®T COMPILE CHO P100 ---\n",
    "os.environ['nnUNet_compile'] = 'F'\n",
    "\n",
    "# ==============================================================================\n",
    "# âš™ï¸ KAGGLE CONFIGURATION (ÄÃƒ Sá»¬A ÄÆ¯á»œNG DáºªN)\n",
    "# ==============================================================================\n",
    "CONFIG = {\n",
    "    # 1. ÄÆ°á»ng dáº«n Model (Láº¥y tá»« folder working)\n",
    "    \"checkpoint_path\": \"/kaggle/working/nnUNet_results/Dataset101_BraTS2020/EDLTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth\",\n",
    "    \n",
    "    # 2. ÄÆ°á»ng dáº«n Data (Láº¥y tá»« folder temp symlink)\n",
    "    \"image_folder\": \"/kaggle/temp/nnUNet_raw/Dataset101_BraTS2020/imagesTr\",\n",
    "    \"label_folder\": \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/gt_segmentations\", # DÃ¹ng GT Ä‘Ã£ preprocessed cho tiá»‡n\n",
    "    \"split_file\":   \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\",\n",
    "\n",
    "    # 3. ÄÆ°á»ng dáº«n lÆ°u káº¿t quáº£ (LÆ°u vÃ o working Ä‘á»ƒ táº£i vá»)\n",
    "    \"output_folder\": \"/kaggle/working/inference_results_batch\",\n",
    "    \n",
    "    # 4. Cáº¥u hÃ¬nh cháº¡y\n",
    "    \"run_mode\":         \"validation_split\",  # Cháº¡y Ä‘Ãºng táº­p Validation cá»§a Fold 0\n",
    "    \"test_range\":       [0, 10], \n",
    "    \"num_random\":       5,        \n",
    "    \n",
    "    # 5. TÃ¹y chá»n hiá»ƒn thá»‹\n",
    "    \"save_images\":      True,     \n",
    "    \"show_on_screen\":   True,    \n",
    "}\n",
    "# ==============================================================================\n",
    "\n",
    "def get_case_list(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        raise FileNotFoundError(f\"âŒ Folder {folder} khÃ´ng tá»“n táº¡i!\")\n",
    "    files = sorted([f for f in os.listdir(folder) if f.endswith(\"_0000.nii\") or f.endswith(\"_0000.nii.gz\")])\n",
    "    case_ids = []\n",
    "    for f in files:\n",
    "        if f.endswith(\".nii\"): cid = f.replace(\"_0000.nii\", \"\")\n",
    "        else: cid = f.replace(\"_0000.nii.gz\", \"\")\n",
    "        case_ids.append(cid)\n",
    "    return case_ids\n",
    "\n",
    "def calculate_dice(pred_slice, gt_slice):\n",
    "    p = (pred_slice > 0).astype(np.float32)\n",
    "    g = (gt_slice > 0).astype(np.float32)\n",
    "    intersection = np.sum(p * g)\n",
    "    sum_areas = np.sum(p) + np.sum(g)\n",
    "    if sum_areas == 0: return 1.0\n",
    "    return (2.0 * intersection) / sum_areas\n",
    "\n",
    "def visualize_comparison(case_id, mri_data, gt_data, pred_data, uncertainty, slice_idx=None):\n",
    "    # TÃ¬m slice cÃ³ khá»‘i u lá»›n nháº¥t Ä‘á»ƒ váº½ cho Ä‘áº¹p\n",
    "    if slice_idx is None:\n",
    "        sums_gt = np.sum(gt_data, axis=(0, 1, 2))\n",
    "        sums_pred = np.sum(pred_data, axis=(0, 1))\n",
    "        \n",
    "        if sums_gt.max() > 0: slice_idx = np.argmax(sums_gt)\n",
    "        elif sums_pred.max() > 0: slice_idx = np.argmax(sums_pred)\n",
    "        else: slice_idx = gt_data.shape[3] // 2\n",
    "\n",
    "    print(f\"    ğŸ“¸ Drawing Slice: {slice_idx}\")\n",
    "\n",
    "    # Xoay áº£nh cho Ä‘Ãºng chiá»u (.T)\n",
    "    img_slice = mri_data[0, :, :, slice_idx].T\n",
    "    \n",
    "    # GT data tá»« preprocessed folder thÆ°á»ng cÃ³ shape [C, X, Y, Z] hoáº·c [X, Y, Z]\n",
    "    # Náº¿u gt_data lÃ  [1, X, Y, Z]\n",
    "    if gt_data.ndim == 4:\n",
    "        gt_slice = gt_data[0, :, :, slice_idx].T\n",
    "    else:\n",
    "        gt_slice = gt_data[:, :, slice_idx].T\n",
    "        \n",
    "    pred_slice = pred_data[:, :, slice_idx].T\n",
    "    unc_slice = uncertainty[:, :, slice_idx].T\n",
    "\n",
    "    dice = calculate_dice(pred_slice, gt_slice)\n",
    "    ratio = (np.sum(pred_slice>0) / np.sum(gt_slice>0) * 100) if np.sum(gt_slice>0) > 0 else 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(24, 6))\n",
    "    plt.suptitle(f\"Case: {case_id} | Slice: {slice_idx}\", fontsize=16, y=0.98)\n",
    "\n",
    "    # 1. MRI\n",
    "    ax[0].imshow(img_slice, cmap='gray', origin='lower')\n",
    "    ax[0].set_title(\"MRI Input\", fontsize=12)\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # 2. GT\n",
    "    ax[1].imshow(img_slice, cmap='gray', origin='lower', alpha=0.6)\n",
    "    if np.any(gt_slice): ax[1].imshow(gt_slice, cmap='Greens', origin='lower', alpha=0.6, interpolation='nearest')\n",
    "    ax[1].set_title(\"Ground Truth\", fontsize=12, color='green')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    # 3. Pred\n",
    "    ax[2].imshow(img_slice, cmap='gray', origin='lower', alpha=0.6)\n",
    "    if np.any(pred_slice): ax[2].imshow(pred_slice, cmap='jet', origin='lower', alpha=0.5, interpolation='nearest')\n",
    "    ax[2].set_title(f\"AI Prediction\\nDice: {dice:.1%} | Area: {ratio:.0f}%\", fontsize=12, color='blue')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    # 4. Uncertainty\n",
    "    im = ax[3].imshow(unc_slice, cmap='hot', origin='lower', vmin=0, vmax=1.0)\n",
    "    ax[3].set_title(\"Uncertainty Map\", fontsize=12, color='red')\n",
    "    ax[3].axis('off')\n",
    "    plt.colorbar(im, ax=ax[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "    if CONFIG[\"save_images\"]:\n",
    "        os.makedirs(CONFIG[\"output_folder\"], exist_ok=True)\n",
    "        save_path = os.path.join(CONFIG[\"output_folder\"], f\"{case_id}_slice{slice_idx}.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=100)\n",
    "        print(f\"    âœ… Saved: {save_path}\")\n",
    "    \n",
    "    if CONFIG[\"show_on_screen\"]:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def process_case(predictor, case_id):\n",
    "    print(f\"\\nğŸ” Processing: {case_id}...\")\n",
    "    \n",
    "    # TÃ¬m file áº£nh input\n",
    "    base_file = os.path.join(CONFIG[\"image_folder\"], f\"{case_id}_0000.nii\")\n",
    "    ext = \".nii\" if os.path.exists(base_file) else \".nii.gz\"\n",
    "    \n",
    "    image_files = [os.path.join(CONFIG[\"image_folder\"], f\"{case_id}_{i:04d}{ext}\") for i in range(4)]\n",
    "    \n",
    "    # TÃ¬m file nhÃ£n (GT)\n",
    "    gt_file = os.path.join(CONFIG[\"label_folder\"], f\"{case_id}{ext}\")\n",
    "    if not os.path.exists(gt_file):\n",
    "        # Thá»­ tÃ¬m trong preprocessed náº¿u raw khÃ´ng cÃ³\n",
    "        gt_file = os.path.join(CONFIG[\"label_folder\"], f\"{case_id}.nii.gz\")\n",
    "    \n",
    "    if not os.path.exists(gt_file):\n",
    "        print(f\"    âš ï¸ Skipping {case_id}: Label file missing.\")\n",
    "        return\n",
    "\n",
    "    # Preprocessing & Inference\n",
    "    preprocessor = predictor.configuration_manager.preprocessor_class(verbose=False)\n",
    "    # Load vÃ  crop dá»¯ liá»‡u\n",
    "    data, seg, _ = preprocessor.run_case(image_files, gt_file, predictor.plans_manager, predictor.configuration_manager, predictor.dataset_json)\n",
    "    \n",
    "    # Predict\n",
    "    data_tensor = torch.from_numpy(data).to(predictor.device)\n",
    "    pred_logits = predictor.predict_logits_from_preprocessed_data(data_tensor)\n",
    "    \n",
    "    # TÃ­nh EDL Uncertainty\n",
    "    evidence = F.softplus(pred_logits)\n",
    "    alpha = evidence + 1\n",
    "    S = torch.sum(alpha, dim=0)\n",
    "    K = alpha.shape[0]\n",
    "    uncertainty = (K / S).cpu().numpy()\n",
    "    segmentation = torch.argmax(pred_logits, dim=0).cpu().numpy()\n",
    "    \n",
    "    visualize_comparison(case_id, data, seg, segmentation, uncertainty)\n",
    "\n",
    "def get_validation_cases(fold=0):\n",
    "    split_file = CONFIG[\"split_file\"]\n",
    "    if not os.path.exists(split_file):\n",
    "        raise FileNotFoundError(f\"âŒ KhÃ´ng tÃ¬m tháº¥y file split táº¡i: {split_file}\")\n",
    "        \n",
    "    with open(split_file, 'r') as f:\n",
    "        splits = json.load(f)\n",
    "    \n",
    "    if fold >= len(splits):\n",
    "        raise ValueError(f\"âŒ Fold {fold} khÃ´ng tá»“n táº¡i!\")\n",
    "        \n",
    "    val_keys = splits[fold]['val']\n",
    "    print(f\"ğŸ“‚ ÄÃ£ load danh sÃ¡ch Validation Fold {fold}: {len(val_keys)} ca.\")\n",
    "    return val_keys\n",
    "\n",
    "def main():\n",
    "    print(\"ğŸš€ --- BATCH INFERENCE STARTED ---\")\n",
    "    \n",
    "    # Load Model\n",
    "    predictor = nnUNetPredictor(\n",
    "        tile_step_size=0.5, use_gaussian=True, use_mirroring=True,\n",
    "        device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'),\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    checkpoint_folder = os.path.dirname(os.path.dirname(CONFIG[\"checkpoint_path\"]))\n",
    "    # nnUNetPredictor tá»± tÃ¬m fold_X trong folder nÃ y\n",
    "    predictor.initialize_from_trained_model_folder(checkpoint_folder, use_folds=(0,), checkpoint_name=\"checkpoint_best.pth\")\n",
    "    print(f\"ğŸ“‚ Model Loaded.\")\n",
    "\n",
    "    if CONFIG[\"run_mode\"] == \"validation_split\":\n",
    "        cases_to_run = get_validation_cases(fold=0)\n",
    "        # cases_to_run = cases_to_run[:5] # Bá» comment náº¿u muá»‘n test nhanh 5 ca Ä‘áº§u\n",
    "        print(f\"âš™ï¸ Mode: VALIDATION SPLIT (Fold 0) -> Running {len(cases_to_run)} cases.\")\n",
    "    else:\n",
    "        # Code cho mode random/range giá»¯ nguyÃªn\n",
    "        pass\n",
    "\n",
    "    for case_id in cases_to_run:\n",
    "        try:\n",
    "            process_case(predictor, case_id)\n",
    "        except Exception as e:\n",
    "            print(f\"    âŒ Error processing {case_id}: {e}\")\n",
    "\n",
    "    print(\"\\nâœ… --- BATCH INFERENCE FINISHED ---\")\n",
    "    \n",
    "    # NÃ©n áº£nh káº¿t quáº£ Ä‘á»ƒ táº£i vá»\n",
    "    shutil.make_archive(\"/kaggle/working/inference_images\", 'zip', CONFIG[\"output_folder\"])\n",
    "    print(\"ğŸ“¦ ÄÃ£ nÃ©n áº£nh káº¿t quáº£: /kaggle/working/inference_images.zip\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8803257,
     "sourceId": 13844758,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
