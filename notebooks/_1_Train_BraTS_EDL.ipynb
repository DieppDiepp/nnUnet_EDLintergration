{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f2e8918",
   "metadata": {
    "papermill": {
     "duration": 0.003842,
     "end_time": "2025-11-25T14:45:32.020154",
     "exception": false,
     "start_time": "2025-11-25T14:45:32.016312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. CÃ i Ä‘áº·t thÆ° viá»‡n (Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f517397e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:45:32.028154Z",
     "iopub.status.busy": "2025-11-25T14:45:32.027372Z",
     "iopub.status.idle": "2025-11-25T14:47:04.894119Z",
     "shell.execute_reply": "2025-11-25T14:47:04.893125Z"
    },
    "papermill": {
     "duration": 92.871998,
     "end_time": "2025-11-25T14:47:04.895449",
     "exception": false,
     "start_time": "2025-11-25T14:45:32.023451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Äang cÃ i Ä‘áº·t nnU-Net vÃ  cÃ¡c thÆ° viá»‡n phá»¥ trá»£...\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mâœ… CÃ i Ä‘áº·t hoÃ n táº¥t.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# CELL 1: SETUP & INSTALLATION\n",
    "# ------------------------------------------------------------------\n",
    "import os\n",
    "import sys\n",
    "import site\n",
    "import shutil\n",
    "\n",
    "print(\"âš™ï¸ Äang cÃ i Ä‘áº·t nnU-Net vÃ  cÃ¡c thÆ° viá»‡n phá»¥ trá»£...\")\n",
    "!pip install nnunetv2 hiddenlayer graphviz --quiet\n",
    "print(\"âœ… CÃ i Ä‘áº·t hoÃ n táº¥t.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c6d11f",
   "metadata": {
    "papermill": {
     "duration": 0.022697,
     "end_time": "2025-11-25T14:47:04.942224",
     "exception": false,
     "start_time": "2025-11-25T14:47:04.919527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 2: Cáº¥u hÃ¬nh MÃ´i trÆ°á»ng & Symlink Data (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d157e236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:47:04.994770Z",
     "iopub.status.busy": "2025-11-25T14:47:04.994468Z",
     "iopub.status.idle": "2025-11-25T14:47:05.054665Z",
     "shell.execute_reply": "2025-11-25T14:47:05.053927Z"
    },
    "papermill": {
     "duration": 0.0903,
     "end_time": "2025-11-25T14:47:05.055815",
     "exception": false,
     "start_time": "2025-11-25T14:47:04.965515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Äang táº¡o Symlink cho dá»¯ liá»‡u...\n",
      "âœ… Cáº¥u hÃ¬nh Data & MÃ´i trÆ°á»ng hoÃ n táº¥t.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# CELL 2: CONFIGURATION & DATA PREPARATION\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng\n",
    "os.environ['nnUNet_raw'] = \"/kaggle/temp/nnUNet_raw\"\n",
    "os.environ['nnUNet_preprocessed'] = \"/kaggle/temp/nnUNet_preprocessed\"\n",
    "os.environ['nnUNet_results'] = \"/kaggle/working/nnUNet_results\" \n",
    "os.environ['nnUNet_compile'] = 'F' # FIX Lá»–I P100: Táº¯t torch.compile\n",
    "\n",
    "# Táº¡o folder gá»‘c\n",
    "for path in [os.environ['nnUNet_raw'], os.environ['nnUNet_preprocessed'], os.environ['nnUNet_results']]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# 2. Xá»­ lÃ½ Symlink cho Data (Ká»¹ thuáº­t tiáº¿t kiá»‡m bá»™ nhá»› Kaggle)\n",
    "print(\"ğŸ”— Äang táº¡o Symlink cho dá»¯ liá»‡u...\")\n",
    "\n",
    "# --- Preprocessed Data ---\n",
    "input_preprocessed_plans = \"/kaggle/input/ds312-nnunet-edl/nnUNET_preprocessed/nnUNET_preprocessed/Dataset101_BraTS2020/nnUNetPlans_3d_fullres\"\n",
    "input_preprocessed_root = os.path.dirname(input_preprocessed_plans)\n",
    "target_preprocessed_dataset = os.path.join(os.environ['nnUNet_preprocessed'], \"Dataset101_BraTS2020\")\n",
    "os.makedirs(target_preprocessed_dataset, exist_ok=True)\n",
    "\n",
    "# Link folder náº·ng\n",
    "target_plans_dir = os.path.join(target_preprocessed_dataset, \"nnUNetPlans_3d_fullres\")\n",
    "if not os.path.exists(target_plans_dir):\n",
    "    os.symlink(input_preprocessed_plans, target_plans_dir)\n",
    "\n",
    "# --- THÃŠM ÄOáº N NÃ€Y VÃ€O CELL 2 ---\n",
    "# 1.1 Link folder 'gt_segmentations' (Äá»ƒ cháº¡y bÆ°á»›c cháº¥m Ä‘iá»ƒm cuá»‘i cÃ¹ng)\n",
    "input_gt_dir = \"/kaggle/input/ds312-nnunet-edl/nnUNET_preprocessed/nnUNET_preprocessed/Dataset101_BraTS2020/gt_segmentations\"\n",
    "target_gt_dir = os.path.join(target_preprocessed_dataset, \"gt_segmentations\")\n",
    "if not os.path.exists(target_gt_dir):\n",
    "    os.symlink(input_gt_dir, target_gt_dir)\n",
    "    \n",
    "# Copy file nháº¹ (json/pkl)\n",
    "for item in os.listdir(input_preprocessed_root):\n",
    "    s = os.path.join(input_preprocessed_root, item)\n",
    "    d = os.path.join(target_preprocessed_dataset, item)\n",
    "    if os.path.isfile(s) and (item.endswith(\".json\") or item.endswith(\".pkl\")):\n",
    "        shutil.copy(s, d)\n",
    "\n",
    "# --- Raw Data (Optional nhÆ°ng tá»‘t Ä‘á»ƒ verify) ---\n",
    "input_raw_images = \"/kaggle/input/ds312-nnunet-edl/nnUNET_raw/nnUNET_raw/Dataset101_BraTS2020/imagesTr\"\n",
    "input_raw_root = os.path.dirname(input_raw_images)\n",
    "target_raw_dataset = os.path.join(os.environ['nnUNet_raw'], \"Dataset101_BraTS2020\")\n",
    "os.makedirs(target_raw_dataset, exist_ok=True)\n",
    "\n",
    "target_imagesTr = os.path.join(target_raw_dataset, \"imagesTr\")\n",
    "if not os.path.exists(target_imagesTr):\n",
    "    os.symlink(input_raw_images, target_imagesTr)\n",
    "\n",
    "raw_json_path = os.path.join(input_raw_root, \"dataset.json\")\n",
    "if os.path.exists(raw_json_path):\n",
    "    shutil.copy(raw_json_path, os.path.join(target_raw_dataset, \"dataset.json\"))\n",
    "\n",
    "print(\"âœ… Cáº¥u hÃ¬nh Data & MÃ´i trÆ°á»ng hoÃ n táº¥t.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b972cdb",
   "metadata": {
    "papermill": {
     "duration": 0.02362,
     "end_time": "2025-11-25T14:47:05.102592",
     "exception": false,
     "start_time": "2025-11-25T14:47:05.078972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 3: Inject Custom Trainer (Customization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01574041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:47:05.150259Z",
     "iopub.status.busy": "2025-11-25T14:47:05.149935Z",
     "iopub.status.idle": "2025-11-25T14:47:05.157542Z",
     "shell.execute_reply": "2025-11-25T14:47:05.156835Z"
    },
    "papermill": {
     "duration": 0.032815,
     "end_time": "2025-11-25T14:47:05.158686",
     "exception": false,
     "start_time": "2025-11-25T14:47:05.125871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Äang ghi Ä‘Ã¨ file Custom Trainer táº¡i: /usr/local/lib/python3.11/dist-packages/nnunetv2/training/nnUNetTrainer/EDLTrainer.py\n",
      "âœ… ÄÃ£ Inject EDLTrainer thÃ nh cÃ´ng.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# CELL 3: INJECT CUSTOM EDL TRAINER\n",
    "# ------------------------------------------------------------------\n",
    "# TÃ¬m nÆ¡i nnunetv2 Ä‘Æ°á»£c cÃ i Ä‘áº·t\n",
    "package_path = site.getsitepackages()[0]\n",
    "target_file = os.path.join(package_path, \"nnunetv2/training/nnUNetTrainer/EDLTrainer.py\")\n",
    "\n",
    "print(f\"ğŸ“ Äang ghi Ä‘Ã¨ file Custom Trainer táº¡i: {target_file}\")\n",
    "\n",
    "# Ná»™i dung file (ÄÃ£ chá»‰nh epoch = 30)\n",
    "new_content = \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
    "from nnunetv2.training.loss.dice import MemoryEfficientSoftDiceLoss\n",
    "from nnunetv2.training.loss.deep_supervision import DeepSupervisionWrapper\n",
    "\n",
    "# --- PHáº¦N 1: HÃ€M LOSS EDL ---\n",
    "class EDLLoss(nn.Module):\n",
    "    def __init__(self, num_classes, annealing_step=10, lamb=1.0):\n",
    "        super(EDLLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.annealing_step = annealing_step\n",
    "        self.lamb = lamb\n",
    "        self.current_epoch = 0 \n",
    "        self.dice_loss = MemoryEfficientSoftDiceLoss(batch_dice=True, do_bg=False, smooth=1e-5, ddp=False)\n",
    "\n",
    "    def KL(self, alpha):\n",
    "        beta = torch.ones((1, self.num_classes) + alpha.shape[2:]).to(alpha.device)\n",
    "        S_alpha = torch.sum(alpha, dim=1, keepdim=True)\n",
    "        S_beta = torch.sum(beta, dim=1, keepdim=True)\n",
    "        \n",
    "        lnB = torch.lgamma(S_alpha) - torch.sum(torch.lgamma(alpha), dim=1, keepdim=True)\n",
    "        lnB_uni = torch.sum(torch.lgamma(beta), dim=1, keepdim=True) - torch.lgamma(S_beta)\n",
    "        \n",
    "        dg0 = torch.digamma(S_alpha)\n",
    "        dg1 = torch.digamma(alpha)\n",
    "        \n",
    "        kl = torch.sum((alpha - beta) * (dg1 - dg0), dim=1, keepdim=True) + lnB + lnB_uni\n",
    "        return kl\n",
    "\n",
    "    def forward(self, outputs, target):\n",
    "        if target.dim() == outputs.dim():\n",
    "            target = target.squeeze(1)\n",
    "            \n",
    "        target_one_hot = F.one_hot(target.long(), num_classes=self.num_classes)\n",
    "        target_one_hot = target_one_hot.permute(0, 4, 1, 2, 3).contiguous().type_as(outputs)\n",
    "\n",
    "        evidence = F.softplus(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = torch.sum(alpha, dim=1, keepdim=True)\n",
    "        \n",
    "        edl_loss = torch.sum(target_one_hot * (torch.digamma(S) - torch.digamma(alpha)), dim=1, keepdim=True)\n",
    "        edl_loss = torch.mean(edl_loss)\n",
    "        \n",
    "        annealing_coef = min(1.0, self.current_epoch / self.annealing_step)\n",
    "        \n",
    "        kl_alpha = (alpha - 1) * (1 - target_one_hot) + 1\n",
    "        kl_div = self.KL(kl_alpha)\n",
    "        kl_loss = annealing_coef * torch.mean(kl_div)\n",
    "        \n",
    "        p = alpha / S\n",
    "        loss_dice = self.dice_loss(p, target.unsqueeze(1))\n",
    "        \n",
    "        final_loss = edl_loss + kl_loss + self.lamb * loss_dice\n",
    "        return final_loss\n",
    "\n",
    "# --- PHáº¦N 2: TRAINER (EPOCH = 30) ---\n",
    "class EDLTrainer(nnUNetTrainer):\n",
    "    def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict,\n",
    "                 device: torch.device = torch.device('cuda')):\n",
    "        super().__init__(plans, configuration, fold, dataset_json, device=device)\n",
    "        self.num_epochs = 50 \n",
    "\n",
    "    def _build_loss(self):\n",
    "        num_classes = self.label_manager.num_segmentation_heads\n",
    "        loss = EDLLoss(num_classes=num_classes, annealing_step=50, lamb=1.0)\n",
    "        \n",
    "        if self.enable_deep_supervision:\n",
    "            deep_supervision_scales = self._get_deep_supervision_scales()\n",
    "            weights = np.array([1 / (2 ** i) for i in range(len(deep_supervision_scales))])\n",
    "            weights[-1] = 0\n",
    "            weights = weights / weights.sum()\n",
    "            return DeepSupervisionWrapper(loss, weights)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def train_step(self, batch: dict):\n",
    "        data = batch['data']\n",
    "        target = batch['target']\n",
    "        \n",
    "        data = data.to(self.device, non_blocking=True)\n",
    "        if isinstance(target, list):\n",
    "            target = [i.to(self.device, non_blocking=True) for i in target]\n",
    "        else:\n",
    "            target = target.to(self.device, non_blocking=True)\n",
    "            \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Update epoch cho loss\n",
    "        if isinstance(self.loss, DeepSupervisionWrapper):\n",
    "            self.loss.loss.current_epoch = self.current_epoch\n",
    "        else:\n",
    "            self.loss.current_epoch = self.current_epoch\n",
    "            \n",
    "        with torch.autocast(device_type=self.device.type, enabled=True):\n",
    "            output = self.network(data)\n",
    "            l = self.loss(output, target)\n",
    "            \n",
    "        self.grad_scaler.scale(l).backward()\n",
    "        self.grad_scaler.unscale_(self.optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
    "        self.grad_scaler.step(self.optimizer)\n",
    "        self.grad_scaler.update()\n",
    "        \n",
    "        return {'loss': l.detach().cpu().numpy()}\n",
    "\"\"\"\n",
    "\n",
    "with open(target_file, \"w\") as f:\n",
    "    f.write(new_content)\n",
    "\n",
    "print(\"âœ… ÄÃ£ Inject EDLTrainer thÃ nh cÃ´ng.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d42040",
   "metadata": {
    "papermill": {
     "duration": 0.031316,
     "end_time": "2025-11-25T14:47:05.226018",
     "exception": false,
     "start_time": "2025-11-25T14:47:05.194702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 4: Thá»±c thi Training (Execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4873f656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T14:47:05.280731Z",
     "iopub.status.busy": "2025-11-25T14:47:05.279940Z",
     "iopub.status.idle": "2025-11-25T20:06:03.300394Z",
     "shell.execute_reply": "2025-11-25T20:06:03.299422Z"
    },
    "papermill": {
     "duration": 19138.047861,
     "end_time": "2025-11-25T20:06:03.302090",
     "exception": false,
     "start_time": "2025-11-25T14:47:05.254229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Báº®T Äáº¦U TRAINING (Fold 0 - 30 Epochs)...\n",
      "\r\n",
      "############################\r\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\r\n",
      "############################\r\n",
      "\r\n",
      "Using device: cuda:0\r\n",
      "\r\n",
      "#######################################################################\r\n",
      "Please cite the following paper when using nnU-Net:\r\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\r\n",
      "#######################################################################\r\n",
      "\r\n",
      "2025-11-25 14:47:22.810474: do_dummy_2d_data_aug: False\r\n",
      "2025-11-25 14:47:22.812406: Using splits from existing split file: /kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\r\n",
      "2025-11-25 14:47:22.812828: The split file contains 5 splits.\r\n",
      "2025-11-25 14:47:22.812914: Desired fold for training: 0\r\n",
      "2025-11-25 14:47:22.812987: This split has 294 training and 74 validation cases.\r\n",
      "using pin_memory on device 0\r\n",
      "using pin_memory on device 0\r\n",
      "\r\n",
      "This is the configuration used by this training:\r\n",
      "Configuration name: 3d_fullres\r\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [139.0, 170.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \r\n",
      "\r\n",
      "These are the global plan.json settings:\r\n",
      " {'dataset_name': 'Dataset101_BraTS2020', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [139, 170, 138], 'image_reader_writer': 'NibabelIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 29422.0, 'mean': 724.156982421875, 'median': 428.0, 'min': 0.0, 'percentile_00_5': 73.0, 'percentile_99_5': 16634.0, 'std': 1905.18603515625}, '1': {'max': 20094.0, 'mean': 644.5623779296875, 'median': 356.0, 'min': 0.0, 'percentile_00_5': 37.0, 'percentile_99_5': 8509.0, 'std': 1026.4256591796875}, '2': {'max': 18011.0, 'mean': 793.357421875, 'median': 415.0, 'min': 0.0, 'percentile_00_5': 36.0, 'percentile_99_5': 8117.0, 'std': 1158.4361572265625}, '3': {'max': 31404.0, 'mean': 1070.999267578125, 'median': 665.0, 'min': 0.0, 'percentile_00_5': 96.0, 'percentile_99_5': 16393.0, 'std': 1994.0704345703125}}} \r\n",
      "\r\n",
      "2025-11-25 14:47:51.203334: Unable to plot network architecture:\r\n",
      "2025-11-25 14:47:51.204110: module 'torch.onnx' has no attribute '_optimize_trace'\r\n",
      "2025-11-25 14:47:51.297003: \r\n",
      "2025-11-25 14:47:51.297298: Epoch 0\r\n",
      "2025-11-25 14:47:51.297618: Current learning rate: 0.01\r\n",
      "2025-11-25 14:56:02.461864: train_loss 0.2697\r\n",
      "2025-11-25 14:56:02.462204: val_loss -0.0847\r\n",
      "2025-11-25 14:56:02.462410: Pseudo dice [0.0, 0.7201, 0.7711]\r\n",
      "2025-11-25 14:56:02.462565: Epoch time: 491.17 s\r\n",
      "2025-11-25 14:56:02.462694: Yayy! New best EMA pseudo Dice: 0.4971\r\n",
      "2025-11-25 14:56:04.141955: \r\n",
      "2025-11-25 14:56:04.142315: Epoch 1\r\n",
      "2025-11-25 14:56:04.142447: Current learning rate: 0.00982\r\n",
      "2025-11-25 15:02:05.240977: train_loss -0.1229\r\n",
      "2025-11-25 15:02:05.241448: val_loss -0.1844\r\n",
      "2025-11-25 15:02:05.241598: Pseudo dice [0.0069, 0.7397, 0.761]\r\n",
      "2025-11-25 15:02:05.241766: Epoch time: 361.1 s\r\n",
      "2025-11-25 15:02:05.241902: Yayy! New best EMA pseudo Dice: 0.4976\r\n",
      "2025-11-25 15:02:07.604290: \r\n",
      "2025-11-25 15:02:07.604437: Epoch 2\r\n",
      "2025-11-25 15:02:07.604564: Current learning rate: 0.00964\r\n",
      "2025-11-25 15:08:08.186784: train_loss -0.2158\r\n",
      "2025-11-25 15:08:08.187041: val_loss -0.2801\r\n",
      "2025-11-25 15:08:08.187181: Pseudo dice [0.4174, 0.7823, 0.8093]\r\n",
      "2025-11-25 15:08:08.187290: Epoch time: 360.58 s\r\n",
      "2025-11-25 15:08:08.187366: Yayy! New best EMA pseudo Dice: 0.5148\r\n",
      "2025-11-25 15:08:10.282807: \r\n",
      "2025-11-25 15:08:10.282957: Epoch 3\r\n",
      "2025-11-25 15:08:10.283087: Current learning rate: 0.00946\r\n",
      "2025-11-25 15:14:10.843428: train_loss -0.2852\r\n",
      "2025-11-25 15:14:10.843716: val_loss -0.3071\r\n",
      "2025-11-25 15:14:10.843877: Pseudo dice [0.5649, 0.7558, 0.798]\r\n",
      "2025-11-25 15:14:10.843975: Epoch time: 360.56 s\r\n",
      "2025-11-25 15:14:10.844052: Yayy! New best EMA pseudo Dice: 0.534\r\n",
      "2025-11-25 15:14:12.869657: \r\n",
      "2025-11-25 15:14:12.869877: Epoch 4\r\n",
      "2025-11-25 15:14:12.870111: Current learning rate: 0.00928\r\n",
      "2025-11-25 15:20:13.079389: train_loss -0.3234\r\n",
      "2025-11-25 15:20:13.079643: val_loss -0.3297\r\n",
      "2025-11-25 15:20:13.079825: Pseudo dice [0.5132, 0.7317, 0.8014]\r\n",
      "2025-11-25 15:20:13.080073: Epoch time: 360.21 s\r\n",
      "2025-11-25 15:20:13.080237: Yayy! New best EMA pseudo Dice: 0.5488\r\n",
      "2025-11-25 15:20:15.269956: \r\n",
      "2025-11-25 15:20:15.270253: Epoch 5\r\n",
      "2025-11-25 15:20:15.270420: Current learning rate: 0.0091\r\n",
      "2025-11-25 15:26:15.193279: train_loss -0.3519\r\n",
      "2025-11-25 15:26:15.193633: val_loss -0.3777\r\n",
      "2025-11-25 15:26:15.193864: Pseudo dice [0.6254, 0.834, 0.8204]\r\n",
      "2025-11-25 15:26:15.194034: Epoch time: 359.92 s\r\n",
      "2025-11-25 15:26:15.194232: Yayy! New best EMA pseudo Dice: 0.5699\r\n",
      "2025-11-25 15:26:17.308351: \r\n",
      "2025-11-25 15:26:17.308500: Epoch 6\r\n",
      "2025-11-25 15:26:17.308703: Current learning rate: 0.00891\r\n",
      "2025-11-25 15:32:17.609319: train_loss -0.3713\r\n",
      "2025-11-25 15:32:17.609567: val_loss -0.3776\r\n",
      "2025-11-25 15:32:17.609692: Pseudo dice [0.5419, 0.8002, 0.8349]\r\n",
      "2025-11-25 15:32:17.609851: Epoch time: 360.3 s\r\n",
      "2025-11-25 15:32:17.610025: Yayy! New best EMA pseudo Dice: 0.5855\r\n",
      "2025-11-25 15:32:19.687846: \r\n",
      "2025-11-25 15:32:19.688047: Epoch 7\r\n",
      "2025-11-25 15:32:19.688212: Current learning rate: 0.00873\r\n",
      "2025-11-25 15:38:20.089135: train_loss -0.3933\r\n",
      "2025-11-25 15:38:20.089397: val_loss -0.3805\r\n",
      "2025-11-25 15:38:20.089533: Pseudo dice [0.5727, 0.7858, 0.8107]\r\n",
      "2025-11-25 15:38:20.089676: Epoch time: 360.4 s\r\n",
      "2025-11-25 15:38:20.089812: Yayy! New best EMA pseudo Dice: 0.5992\r\n",
      "2025-11-25 15:38:22.252832: \r\n",
      "2025-11-25 15:38:22.253116: Epoch 8\r\n",
      "2025-11-25 15:38:22.253271: Current learning rate: 0.00855\r\n",
      "2025-11-25 15:44:22.524158: train_loss -0.3948\r\n",
      "2025-11-25 15:44:22.524367: val_loss -0.4417\r\n",
      "2025-11-25 15:44:22.524461: Pseudo dice [0.6662, 0.8304, 0.8445]\r\n",
      "2025-11-25 15:44:22.524544: Epoch time: 360.27 s\r\n",
      "2025-11-25 15:44:22.524666: Yayy! New best EMA pseudo Dice: 0.6173\r\n",
      "2025-11-25 15:44:24.703855: \r\n",
      "2025-11-25 15:44:24.704169: Epoch 9\r\n",
      "2025-11-25 15:44:24.704301: Current learning rate: 0.00836\r\n",
      "2025-11-25 15:50:24.745762: train_loss -0.4168\r\n",
      "2025-11-25 15:50:24.746061: val_loss -0.4329\r\n",
      "2025-11-25 15:50:24.746236: Pseudo dice [0.6633, 0.7891, 0.838]\r\n",
      "2025-11-25 15:50:24.746456: Epoch time: 360.04 s\r\n",
      "2025-11-25 15:50:24.746585: Yayy! New best EMA pseudo Dice: 0.632\r\n",
      "2025-11-25 15:50:27.179842: \r\n",
      "2025-11-25 15:50:27.180116: Epoch 10\r\n",
      "2025-11-25 15:50:27.180251: Current learning rate: 0.00818\r\n",
      "2025-11-25 15:56:27.300273: train_loss -0.4066\r\n",
      "2025-11-25 15:56:27.300573: val_loss -0.4231\r\n",
      "2025-11-25 15:56:27.300728: Pseudo dice [0.6608, 0.7892, 0.8341]\r\n",
      "2025-11-25 15:56:27.300999: Epoch time: 360.12 s\r\n",
      "2025-11-25 15:56:27.301128: Yayy! New best EMA pseudo Dice: 0.6449\r\n",
      "2025-11-25 15:56:29.378132: \r\n",
      "2025-11-25 15:56:29.378325: Epoch 11\r\n",
      "2025-11-25 15:56:29.378444: Current learning rate: 0.008\r\n",
      "2025-11-25 16:02:28.676640: train_loss -0.4236\r\n",
      "2025-11-25 16:02:28.676953: val_loss -0.4593\r\n",
      "2025-11-25 16:02:28.677122: Pseudo dice [0.6685, 0.8371, 0.8555]\r\n",
      "2025-11-25 16:02:28.677270: Epoch time: 359.3 s\r\n",
      "2025-11-25 16:02:28.677364: Yayy! New best EMA pseudo Dice: 0.6591\r\n",
      "2025-11-25 16:02:30.765271: \r\n",
      "2025-11-25 16:02:30.765480: Epoch 12\r\n",
      "2025-11-25 16:02:30.765677: Current learning rate: 0.00781\r\n",
      "2025-11-25 16:08:30.274146: train_loss -0.4259\r\n",
      "2025-11-25 16:08:30.274484: val_loss -0.4635\r\n",
      "2025-11-25 16:08:30.274623: Pseudo dice [0.7296, 0.8134, 0.8451]\r\n",
      "2025-11-25 16:08:30.274751: Epoch time: 359.51 s\r\n",
      "2025-11-25 16:08:30.274871: Yayy! New best EMA pseudo Dice: 0.6728\r\n",
      "2025-11-25 16:08:32.431920: \r\n",
      "2025-11-25 16:08:32.432134: Epoch 13\r\n",
      "2025-11-25 16:08:32.432265: Current learning rate: 0.00763\r\n",
      "2025-11-25 16:14:32.754246: train_loss -0.437\r\n",
      "2025-11-25 16:14:32.754699: val_loss -0.4557\r\n",
      "2025-11-25 16:14:32.754870: Pseudo dice [0.6804, 0.8128, 0.8398]\r\n",
      "2025-11-25 16:14:32.755010: Epoch time: 360.32 s\r\n",
      "2025-11-25 16:14:32.755110: Yayy! New best EMA pseudo Dice: 0.6833\r\n",
      "2025-11-25 16:14:35.020545: \r\n",
      "2025-11-25 16:14:35.020920: Epoch 14\r\n",
      "2025-11-25 16:14:35.021114: Current learning rate: 0.00744\r\n",
      "2025-11-25 16:20:34.548841: train_loss -0.4361\r\n",
      "2025-11-25 16:20:34.549089: val_loss -0.4584\r\n",
      "2025-11-25 16:20:34.549193: Pseudo dice [0.5792, 0.8464, 0.8553]\r\n",
      "2025-11-25 16:20:34.549281: Epoch time: 359.53 s\r\n",
      "2025-11-25 16:20:34.549349: Yayy! New best EMA pseudo Dice: 0.691\r\n",
      "2025-11-25 16:20:36.768500: \r\n",
      "2025-11-25 16:20:36.768797: Epoch 15\r\n",
      "2025-11-25 16:20:36.768982: Current learning rate: 0.00725\r\n",
      "2025-11-25 16:26:36.528072: train_loss -0.459\r\n",
      "2025-11-25 16:26:36.528369: val_loss -0.4959\r\n",
      "2025-11-25 16:26:36.528537: Pseudo dice [0.7516, 0.844, 0.8513]\r\n",
      "2025-11-25 16:26:36.528689: Epoch time: 359.76 s\r\n",
      "2025-11-25 16:26:36.528830: Yayy! New best EMA pseudo Dice: 0.7034\r\n",
      "2025-11-25 16:26:38.732582: \r\n",
      "2025-11-25 16:26:38.732789: Epoch 16\r\n",
      "2025-11-25 16:26:38.732959: Current learning rate: 0.00707\r\n",
      "2025-11-25 16:32:39.206976: train_loss -0.4633\r\n",
      "2025-11-25 16:32:39.207231: val_loss -0.4846\r\n",
      "2025-11-25 16:32:39.207371: Pseudo dice [0.6929, 0.8572, 0.8375]\r\n",
      "2025-11-25 16:32:39.207466: Epoch time: 360.48 s\r\n",
      "2025-11-25 16:32:39.207579: Yayy! New best EMA pseudo Dice: 0.7127\r\n",
      "2025-11-25 16:32:41.482566: \r\n",
      "2025-11-25 16:32:41.482804: Epoch 17\r\n",
      "2025-11-25 16:32:41.482968: Current learning rate: 0.00688\r\n",
      "2025-11-25 16:38:41.981863: train_loss -0.4538\r\n",
      "2025-11-25 16:38:41.982157: val_loss -0.4806\r\n",
      "2025-11-25 16:38:41.982362: Pseudo dice [0.7056, 0.8478, 0.8359]\r\n",
      "2025-11-25 16:38:41.982478: Epoch time: 360.5 s\r\n",
      "2025-11-25 16:38:41.982578: Yayy! New best EMA pseudo Dice: 0.7211\r\n",
      "2025-11-25 16:38:44.197936: \r\n",
      "2025-11-25 16:38:44.198233: Epoch 18\r\n",
      "2025-11-25 16:38:44.198369: Current learning rate: 0.00669\r\n",
      "2025-11-25 16:44:44.523058: train_loss -0.4725\r\n",
      "2025-11-25 16:44:44.523317: val_loss -0.5188\r\n",
      "2025-11-25 16:44:44.523425: Pseudo dice [0.7486, 0.8693, 0.8601]\r\n",
      "2025-11-25 16:44:44.523515: Epoch time: 360.33 s\r\n",
      "2025-11-25 16:44:44.523588: Yayy! New best EMA pseudo Dice: 0.7316\r\n",
      "2025-11-25 16:44:47.120725: \r\n",
      "2025-11-25 16:44:47.121041: Epoch 19\r\n",
      "2025-11-25 16:44:47.121204: Current learning rate: 0.0065\r\n",
      "2025-11-25 16:50:46.813131: train_loss -0.483\r\n",
      "2025-11-25 16:50:46.813410: val_loss -0.4245\r\n",
      "2025-11-25 16:50:46.813545: Pseudo dice [0.5827, 0.7863, 0.8555]\r\n",
      "2025-11-25 16:50:46.813661: Epoch time: 359.69 s\r\n",
      "2025-11-25 16:50:46.813787: Yayy! New best EMA pseudo Dice: 0.7326\r\n",
      "2025-11-25 16:50:49.028920: \r\n",
      "2025-11-25 16:50:49.029265: Epoch 20\r\n",
      "2025-11-25 16:50:49.029421: Current learning rate: 0.00631\r\n",
      "2025-11-25 16:56:49.589251: train_loss -0.4917\r\n",
      "2025-11-25 16:56:49.589562: val_loss -0.4905\r\n",
      "2025-11-25 16:56:49.589692: Pseudo dice [0.7462, 0.8463, 0.8356]\r\n",
      "2025-11-25 16:56:49.589861: Epoch time: 360.56 s\r\n",
      "2025-11-25 16:56:49.590015: Yayy! New best EMA pseudo Dice: 0.7402\r\n",
      "2025-11-25 16:56:51.878199: \r\n",
      "2025-11-25 16:56:51.878395: Epoch 21\r\n",
      "2025-11-25 16:56:51.878572: Current learning rate: 0.00612\r\n",
      "2025-11-25 17:02:52.067950: train_loss -0.5065\r\n",
      "2025-11-25 17:02:52.068254: val_loss -0.5227\r\n",
      "2025-11-25 17:02:52.068396: Pseudo dice [0.7916, 0.8413, 0.8543]\r\n",
      "2025-11-25 17:02:52.068511: Epoch time: 360.19 s\r\n",
      "2025-11-25 17:02:52.068613: Yayy! New best EMA pseudo Dice: 0.7491\r\n",
      "2025-11-25 17:02:54.131928: \r\n",
      "2025-11-25 17:02:54.132204: Epoch 22\r\n",
      "2025-11-25 17:02:54.132370: Current learning rate: 0.00593\r\n",
      "2025-11-25 17:08:54.358700: train_loss -0.5019\r\n",
      "2025-11-25 17:08:54.358996: val_loss -0.4974\r\n",
      "2025-11-25 17:08:54.359107: Pseudo dice [0.7113, 0.8191, 0.8595]\r\n",
      "2025-11-25 17:08:54.359198: Epoch time: 360.23 s\r\n",
      "2025-11-25 17:08:54.359280: Yayy! New best EMA pseudo Dice: 0.7539\r\n",
      "2025-11-25 17:08:56.597936: \r\n",
      "2025-11-25 17:08:56.598225: Epoch 23\r\n",
      "2025-11-25 17:08:56.598388: Current learning rate: 0.00574\r\n",
      "2025-11-25 17:14:57.400584: train_loss -0.4805\r\n",
      "2025-11-25 17:14:57.401002: val_loss -0.5184\r\n",
      "2025-11-25 17:14:57.401180: Pseudo dice [0.7542, 0.8687, 0.8544]\r\n",
      "2025-11-25 17:14:57.401320: Epoch time: 360.8 s\r\n",
      "2025-11-25 17:14:57.401429: Yayy! New best EMA pseudo Dice: 0.7611\r\n",
      "2025-11-25 17:14:59.511111: \r\n",
      "2025-11-25 17:14:59.511442: Epoch 24\r\n",
      "2025-11-25 17:14:59.511619: Current learning rate: 0.00555\r\n",
      "2025-11-25 17:20:59.949400: train_loss -0.4726\r\n",
      "2025-11-25 17:20:59.949705: val_loss -0.536\r\n",
      "2025-11-25 17:20:59.949903: Pseudo dice [0.7825, 0.873, 0.8702]\r\n",
      "2025-11-25 17:20:59.950064: Epoch time: 360.44 s\r\n",
      "2025-11-25 17:20:59.950163: Yayy! New best EMA pseudo Dice: 0.7691\r\n",
      "2025-11-25 17:21:02.150768: \r\n",
      "2025-11-25 17:21:02.150983: Epoch 25\r\n",
      "2025-11-25 17:21:02.151160: Current learning rate: 0.00536\r\n",
      "2025-11-25 17:27:02.609202: train_loss -0.4924\r\n",
      "2025-11-25 17:27:02.609486: val_loss -0.5411\r\n",
      "2025-11-25 17:27:02.609642: Pseudo dice [0.801, 0.8732, 0.8692]\r\n",
      "2025-11-25 17:27:02.609852: Epoch time: 360.46 s\r\n",
      "2025-11-25 17:27:02.609977: Yayy! New best EMA pseudo Dice: 0.777\r\n",
      "2025-11-25 17:27:04.736655: \r\n",
      "2025-11-25 17:27:04.736858: Epoch 26\r\n",
      "2025-11-25 17:27:04.737141: Current learning rate: 0.00517\r\n",
      "2025-11-25 17:33:05.519130: train_loss -0.5012\r\n",
      "2025-11-25 17:33:05.519378: val_loss -0.5482\r\n",
      "2025-11-25 17:33:05.519533: Pseudo dice [0.7239, 0.8673, 0.8886]\r\n",
      "2025-11-25 17:33:05.519712: Epoch time: 360.78 s\r\n",
      "2025-11-25 17:33:05.519845: Yayy! New best EMA pseudo Dice: 0.782\r\n",
      "2025-11-25 17:33:08.057367: \r\n",
      "2025-11-25 17:33:08.057585: Epoch 27\r\n",
      "2025-11-25 17:33:08.057785: Current learning rate: 0.00497\r\n",
      "2025-11-25 17:39:08.122324: train_loss -0.497\r\n",
      "2025-11-25 17:39:08.122583: val_loss -0.4818\r\n",
      "2025-11-25 17:39:08.122716: Pseudo dice [0.725, 0.8179, 0.8421]\r\n",
      "2025-11-25 17:39:08.122889: Epoch time: 360.07 s\r\n",
      "2025-11-25 17:39:08.122993: Yayy! New best EMA pseudo Dice: 0.7833\r\n",
      "2025-11-25 17:39:10.188334: \r\n",
      "2025-11-25 17:39:10.188510: Epoch 28\r\n",
      "2025-11-25 17:39:10.188633: Current learning rate: 0.00478\r\n",
      "2025-11-25 17:45:09.480324: train_loss -0.4951\r\n",
      "2025-11-25 17:45:09.480627: val_loss -0.4779\r\n",
      "2025-11-25 17:45:09.480819: Pseudo dice [0.6949, 0.8402, 0.8621]\r\n",
      "2025-11-25 17:45:09.480959: Epoch time: 359.29 s\r\n",
      "2025-11-25 17:45:09.481066: Yayy! New best EMA pseudo Dice: 0.7849\r\n",
      "2025-11-25 17:45:11.583567: \r\n",
      "2025-11-25 17:45:11.583770: Epoch 29\r\n",
      "2025-11-25 17:45:11.583925: Current learning rate: 0.00458\r\n",
      "2025-11-25 17:51:12.123316: train_loss -0.4988\r\n",
      "2025-11-25 17:51:12.123605: val_loss -0.5347\r\n",
      "2025-11-25 17:51:12.123780: Pseudo dice [0.7536, 0.8661, 0.866]\r\n",
      "2025-11-25 17:51:12.123921: Epoch time: 360.54 s\r\n",
      "2025-11-25 17:51:12.124040: Yayy! New best EMA pseudo Dice: 0.7892\r\n",
      "2025-11-25 17:51:14.279133: \r\n",
      "2025-11-25 17:51:14.279418: Epoch 30\r\n",
      "2025-11-25 17:51:14.279585: Current learning rate: 0.00438\r\n",
      "2025-11-25 17:57:14.519103: train_loss -0.5108\r\n",
      "2025-11-25 17:57:14.519380: val_loss -0.5249\r\n",
      "2025-11-25 17:57:14.519524: Pseudo dice [0.7817, 0.8598, 0.8613]\r\n",
      "2025-11-25 17:57:14.519642: Epoch time: 360.24 s\r\n",
      "2025-11-25 17:57:14.519793: Yayy! New best EMA pseudo Dice: 0.7937\r\n",
      "2025-11-25 17:57:16.611577: \r\n",
      "2025-11-25 17:57:16.611964: Epoch 31\r\n",
      "2025-11-25 17:57:16.612150: Current learning rate: 0.00419\r\n",
      "2025-11-25 18:03:15.978977: train_loss -0.508\r\n",
      "2025-11-25 18:03:15.979232: val_loss -0.4884\r\n",
      "2025-11-25 18:03:15.979417: Pseudo dice [0.7071, 0.8277, 0.8562]\r\n",
      "2025-11-25 18:03:15.979527: Epoch time: 359.37 s\r\n",
      "2025-11-25 18:03:15.979621: Yayy! New best EMA pseudo Dice: 0.7941\r\n",
      "2025-11-25 18:03:18.124158: \r\n",
      "2025-11-25 18:03:18.124450: Epoch 32\r\n",
      "2025-11-25 18:03:18.124586: Current learning rate: 0.00399\r\n",
      "2025-11-25 18:09:17.460322: train_loss -0.5008\r\n",
      "2025-11-25 18:09:17.460579: val_loss -0.5082\r\n",
      "2025-11-25 18:09:17.460803: Pseudo dice [0.7443, 0.8307, 0.8784]\r\n",
      "2025-11-25 18:09:17.460970: Epoch time: 359.34 s\r\n",
      "2025-11-25 18:09:17.461093: Yayy! New best EMA pseudo Dice: 0.7964\r\n",
      "2025-11-25 18:09:19.563148: \r\n",
      "2025-11-25 18:09:19.563443: Epoch 33\r\n",
      "2025-11-25 18:09:19.563605: Current learning rate: 0.00379\r\n",
      "2025-11-25 18:15:18.964614: train_loss -0.5059\r\n",
      "2025-11-25 18:15:18.964958: val_loss -0.4939\r\n",
      "2025-11-25 18:15:18.965090: Pseudo dice [0.7726, 0.8225, 0.8674]\r\n",
      "2025-11-25 18:15:18.965210: Epoch time: 359.4 s\r\n",
      "2025-11-25 18:15:18.965387: Yayy! New best EMA pseudo Dice: 0.7989\r\n",
      "2025-11-25 18:15:21.127574: \r\n",
      "2025-11-25 18:15:21.127800: Epoch 34\r\n",
      "2025-11-25 18:15:21.128054: Current learning rate: 0.00359\r\n",
      "2025-11-25 18:21:21.777068: train_loss -0.5112\r\n",
      "2025-11-25 18:21:21.777322: val_loss -0.5237\r\n",
      "2025-11-25 18:21:21.777500: Pseudo dice [0.7914, 0.8646, 0.8512]\r\n",
      "2025-11-25 18:21:21.777628: Epoch time: 360.65 s\r\n",
      "2025-11-25 18:21:21.777767: Yayy! New best EMA pseudo Dice: 0.8026\r\n",
      "2025-11-25 18:21:24.335841: \r\n",
      "2025-11-25 18:21:24.336044: Epoch 35\r\n",
      "2025-11-25 18:21:24.336202: Current learning rate: 0.00338\r\n",
      "2025-11-25 18:27:24.349451: train_loss -0.4959\r\n",
      "2025-11-25 18:27:24.349691: val_loss -0.5426\r\n",
      "2025-11-25 18:27:24.349973: Pseudo dice [0.7773, 0.8757, 0.8723]\r\n",
      "2025-11-25 18:27:24.350138: Epoch time: 360.01 s\r\n",
      "2025-11-25 18:27:24.350251: Yayy! New best EMA pseudo Dice: 0.8065\r\n",
      "2025-11-25 18:27:26.546080: \r\n",
      "2025-11-25 18:27:26.546472: Epoch 36\r\n",
      "2025-11-25 18:27:26.546659: Current learning rate: 0.00318\r\n",
      "2025-11-25 18:33:27.132935: train_loss -0.5174\r\n",
      "2025-11-25 18:33:27.133198: val_loss -0.5304\r\n",
      "2025-11-25 18:33:27.133381: Pseudo dice [0.7759, 0.8629, 0.8676]\r\n",
      "2025-11-25 18:33:27.133611: Epoch time: 360.59 s\r\n",
      "2025-11-25 18:33:27.133707: Yayy! New best EMA pseudo Dice: 0.8094\r\n",
      "2025-11-25 18:33:29.372344: \r\n",
      "2025-11-25 18:33:29.372633: Epoch 37\r\n",
      "2025-11-25 18:33:29.372800: Current learning rate: 0.00297\r\n",
      "2025-11-25 18:39:29.017843: train_loss -0.5204\r\n",
      "2025-11-25 18:39:29.018153: val_loss -0.5474\r\n",
      "2025-11-25 18:39:29.018310: Pseudo dice [0.7922, 0.8732, 0.8764]\r\n",
      "2025-11-25 18:39:29.018408: Epoch time: 359.65 s\r\n",
      "2025-11-25 18:39:29.018482: Yayy! New best EMA pseudo Dice: 0.8132\r\n",
      "2025-11-25 18:39:31.251613: \r\n",
      "2025-11-25 18:39:31.251904: Epoch 38\r\n",
      "2025-11-25 18:39:31.252056: Current learning rate: 0.00277\r\n",
      "2025-11-25 18:45:32.260854: train_loss -0.5128\r\n",
      "2025-11-25 18:45:32.261113: val_loss -0.5324\r\n",
      "2025-11-25 18:45:32.261253: Pseudo dice [0.7788, 0.8569, 0.8714]\r\n",
      "2025-11-25 18:45:32.261432: Epoch time: 361.01 s\r\n",
      "2025-11-25 18:45:32.261540: Yayy! New best EMA pseudo Dice: 0.8154\r\n",
      "2025-11-25 18:45:34.495130: \r\n",
      "2025-11-25 18:45:34.495465: Epoch 39\r\n",
      "2025-11-25 18:45:34.495629: Current learning rate: 0.00256\r\n",
      "2025-11-25 18:51:35.327471: train_loss -0.509\r\n",
      "2025-11-25 18:51:35.327785: val_loss -0.5509\r\n",
      "2025-11-25 18:51:35.327943: Pseudo dice [0.815, 0.8686, 0.8712]\r\n",
      "2025-11-25 18:51:35.328070: Epoch time: 360.83 s\r\n",
      "2025-11-25 18:51:35.328224: Yayy! New best EMA pseudo Dice: 0.819\r\n",
      "2025-11-25 18:51:37.599708: \r\n",
      "2025-11-25 18:51:37.599899: Epoch 40\r\n",
      "2025-11-25 18:51:37.600079: Current learning rate: 0.00235\r\n",
      "2025-11-25 18:57:38.463944: train_loss -0.5019\r\n",
      "2025-11-25 18:57:38.464204: val_loss -0.5009\r\n",
      "2025-11-25 18:57:38.464348: Pseudo dice [0.7336, 0.8341, 0.8693]\r\n",
      "2025-11-25 18:57:38.464450: Epoch time: 360.87 s\r\n",
      "2025-11-25 18:57:40.215706: \r\n",
      "2025-11-25 18:57:40.215930: Epoch 41\r\n",
      "2025-11-25 18:57:40.216099: Current learning rate: 0.00214\r\n",
      "2025-11-25 19:03:41.184073: train_loss -0.515\r\n",
      "2025-11-25 19:03:41.184506: val_loss -0.5236\r\n",
      "2025-11-25 19:03:41.184667: Pseudo dice [0.7498, 0.8429, 0.8841]\r\n",
      "2025-11-25 19:03:41.184848: Epoch time: 360.97 s\r\n",
      "2025-11-25 19:03:41.185001: Yayy! New best EMA pseudo Dice: 0.8191\r\n",
      "2025-11-25 19:03:43.501348: \r\n",
      "2025-11-25 19:03:43.501607: Epoch 42\r\n",
      "2025-11-25 19:03:43.501802: Current learning rate: 0.00192\r\n",
      "2025-11-25 19:09:44.496670: train_loss -0.5284\r\n",
      "2025-11-25 19:09:44.497081: val_loss -0.5439\r\n",
      "2025-11-25 19:09:44.497265: Pseudo dice [0.7819, 0.8681, 0.877]\r\n",
      "2025-11-25 19:09:44.497452: Epoch time: 361.0 s\r\n",
      "2025-11-25 19:09:44.497549: Yayy! New best EMA pseudo Dice: 0.8214\r\n",
      "2025-11-25 19:09:47.005530: \r\n",
      "2025-11-25 19:09:47.005700: Epoch 43\r\n",
      "2025-11-25 19:09:47.005883: Current learning rate: 0.0017\r\n",
      "2025-11-25 19:15:47.073316: train_loss -0.5269\r\n",
      "2025-11-25 19:15:47.073712: val_loss -0.5121\r\n",
      "2025-11-25 19:15:47.073945: Pseudo dice [0.7414, 0.851, 0.8731]\r\n",
      "2025-11-25 19:15:47.074082: Epoch time: 360.07 s\r\n",
      "2025-11-25 19:15:47.074203: Yayy! New best EMA pseudo Dice: 0.8215\r\n",
      "2025-11-25 19:15:49.208032: \r\n",
      "2025-11-25 19:15:49.208209: Epoch 44\r\n",
      "2025-11-25 19:15:49.208454: Current learning rate: 0.00148\r\n",
      "2025-11-25 19:21:49.631876: train_loss -0.5249\r\n",
      "2025-11-25 19:21:49.632199: val_loss -0.4983\r\n",
      "2025-11-25 19:21:49.632343: Pseudo dice [0.772, 0.8452, 0.8639]\r\n",
      "2025-11-25 19:21:49.632479: Epoch time: 360.42 s\r\n",
      "2025-11-25 19:21:49.632597: Yayy! New best EMA pseudo Dice: 0.822\r\n",
      "2025-11-25 19:21:51.806494: \r\n",
      "2025-11-25 19:21:51.806709: Epoch 45\r\n",
      "2025-11-25 19:21:51.806939: Current learning rate: 0.00126\r\n",
      "2025-11-25 19:27:51.741683: train_loss -0.5393\r\n",
      "2025-11-25 19:27:51.741996: val_loss -0.5171\r\n",
      "2025-11-25 19:27:51.742192: Pseudo dice [0.7647, 0.8638, 0.8769]\r\n",
      "2025-11-25 19:27:51.742306: Epoch time: 359.94 s\r\n",
      "2025-11-25 19:27:51.742438: Yayy! New best EMA pseudo Dice: 0.8233\r\n",
      "2025-11-25 19:27:53.774201: \r\n",
      "2025-11-25 19:27:53.774521: Epoch 46\r\n",
      "2025-11-25 19:27:53.774693: Current learning rate: 0.00103\r\n",
      "2025-11-25 19:33:54.519707: train_loss -0.5242\r\n",
      "2025-11-25 19:33:54.520009: val_loss -0.5346\r\n",
      "2025-11-25 19:33:54.520157: Pseudo dice [0.7952, 0.8731, 0.8746]\r\n",
      "2025-11-25 19:33:54.520295: Epoch time: 360.75 s\r\n",
      "2025-11-25 19:33:54.520417: Yayy! New best EMA pseudo Dice: 0.8258\r\n",
      "2025-11-25 19:33:56.616057: \r\n",
      "2025-11-25 19:33:56.616229: Epoch 47\r\n",
      "2025-11-25 19:33:56.616377: Current learning rate: 0.00079\r\n",
      "2025-11-25 19:39:57.053571: train_loss -0.5319\r\n",
      "2025-11-25 19:39:57.053874: val_loss -0.5508\r\n",
      "2025-11-25 19:39:57.054026: Pseudo dice [0.8181, 0.8694, 0.885]\r\n",
      "2025-11-25 19:39:57.054254: Epoch time: 360.44 s\r\n",
      "2025-11-25 19:39:57.054361: Yayy! New best EMA pseudo Dice: 0.8289\r\n",
      "2025-11-25 19:39:59.142238: \r\n",
      "2025-11-25 19:39:59.142537: Epoch 48\r\n",
      "2025-11-25 19:39:59.142698: Current learning rate: 0.00055\r\n",
      "2025-11-25 19:45:58.803609: train_loss -0.5221\r\n",
      "2025-11-25 19:45:58.803919: val_loss -0.5185\r\n",
      "2025-11-25 19:45:58.804079: Pseudo dice [0.7832, 0.8449, 0.8769]\r\n",
      "2025-11-25 19:45:58.804208: Epoch time: 359.66 s\r\n",
      "2025-11-25 19:45:58.804316: Yayy! New best EMA pseudo Dice: 0.8295\r\n",
      "2025-11-25 19:46:00.882202: \r\n",
      "2025-11-25 19:46:00.882437: Epoch 49\r\n",
      "2025-11-25 19:46:00.882616: Current learning rate: 0.0003\r\n",
      "2025-11-25 19:52:00.705367: train_loss -0.5313\r\n",
      "2025-11-25 19:52:00.705618: val_loss -0.5483\r\n",
      "2025-11-25 19:52:00.705719: Pseudo dice [0.7999, 0.8752, 0.8811]\r\n",
      "2025-11-25 19:52:00.705894: Epoch time: 359.82 s\r\n",
      "2025-11-25 19:52:00.706005: Yayy! New best EMA pseudo Dice: 0.8318\r\n",
      "2025-11-25 19:52:03.247633: Training done.\r\n",
      "2025-11-25 19:52:03.272209: Using splits from existing split file: /kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\r\n",
      "2025-11-25 19:52:03.273244: The split file contains 5 splits.\r\n",
      "2025-11-25 19:52:03.273381: Desired fold for training: 0\r\n",
      "2025-11-25 19:52:03.273471: This split has 294 training and 74 validation cases.\r\n",
      "2025-11-25 19:52:03.274488: predicting BRATS_011\r\n",
      "2025-11-25 19:52:03.392064: BRATS_011, shape torch.Size([4, 142, 160, 152]), rank 0\r\n",
      "2025-11-25 19:52:26.591285: predicting BRATS_012\r\n",
      "2025-11-25 19:52:26.690295: BRATS_012, shape torch.Size([4, 143, 178, 138]), rank 0\r\n",
      "2025-11-25 19:52:38.188864: predicting BRATS_019\r\n",
      "2025-11-25 19:52:38.291535: BRATS_019, shape torch.Size([4, 137, 167, 133]), rank 0\r\n",
      "2025-11-25 19:52:49.800544: predicting BRATS_020\r\n",
      "2025-11-25 19:52:49.895671: BRATS_020, shape torch.Size([4, 139, 180, 140]), rank 0\r\n",
      "2025-11-25 19:53:01.392031: predicting BRATS_021\r\n",
      "2025-11-25 19:53:01.485045: BRATS_021, shape torch.Size([4, 136, 157, 133]), rank 0\r\n",
      "2025-11-25 19:53:12.951096: predicting BRATS_023\r\n",
      "2025-11-25 19:53:13.038082: BRATS_023, shape torch.Size([4, 147, 168, 127]), rank 0\r\n",
      "2025-11-25 19:53:18.927729: predicting BRATS_028\r\n",
      "2025-11-25 19:53:19.030114: BRATS_028, shape torch.Size([4, 142, 179, 144]), rank 0\r\n",
      "2025-11-25 19:53:30.515977: predicting BRATS_029\r\n",
      "2025-11-25 19:53:30.600339: BRATS_029, shape torch.Size([4, 138, 161, 132]), rank 0\r\n",
      "2025-11-25 19:53:42.066529: predicting BRATS_032\r\n",
      "2025-11-25 19:53:42.162263: BRATS_032, shape torch.Size([4, 143, 172, 129]), rank 0\r\n",
      "2025-11-25 19:53:53.651362: predicting BRATS_036\r\n",
      "2025-11-25 19:53:53.747681: BRATS_036, shape torch.Size([4, 139, 158, 137]), rank 0\r\n",
      "2025-11-25 19:54:05.232017: predicting BRATS_039\r\n",
      "2025-11-25 19:54:05.322403: BRATS_039, shape torch.Size([4, 147, 167, 125]), rank 0\r\n",
      "2025-11-25 19:54:11.147349: predicting BRATS_041\r\n",
      "2025-11-25 19:54:11.242949: BRATS_041, shape torch.Size([4, 141, 165, 143]), rank 0\r\n",
      "2025-11-25 19:54:22.732819: predicting BRATS_042\r\n",
      "2025-11-25 19:54:22.834957: BRATS_042, shape torch.Size([4, 142, 165, 142]), rank 0\r\n",
      "2025-11-25 19:54:34.326297: predicting BRATS_049\r\n",
      "2025-11-25 19:54:34.427342: BRATS_049, shape torch.Size([4, 141, 178, 140]), rank 0\r\n",
      "2025-11-25 19:54:45.914515: predicting BRATS_051\r\n",
      "2025-11-25 19:54:45.998129: BRATS_051, shape torch.Size([4, 144, 165, 134]), rank 0\r\n",
      "2025-11-25 19:54:57.477351: predicting BRATS_053\r\n",
      "2025-11-25 19:54:57.583081: BRATS_053, shape torch.Size([4, 140, 186, 136]), rank 0\r\n",
      "2025-11-25 19:55:09.091749: predicting BRATS_056\r\n",
      "2025-11-25 19:55:09.182053: BRATS_056, shape torch.Size([4, 136, 162, 122]), rank 0\r\n",
      "2025-11-25 19:55:14.979561: predicting BRATS_069\r\n",
      "2025-11-25 19:55:15.063208: BRATS_069, shape torch.Size([4, 129, 175, 128]), rank 0\r\n",
      "2025-11-25 19:55:20.841695: predicting BRATS_074\r\n",
      "2025-11-25 19:55:20.935773: BRATS_074, shape torch.Size([4, 138, 166, 147]), rank 0\r\n",
      "2025-11-25 19:55:32.430389: predicting BRATS_086\r\n",
      "2025-11-25 19:55:32.524713: BRATS_086, shape torch.Size([4, 139, 180, 138]), rank 0\r\n",
      "2025-11-25 19:55:44.010091: predicting BRATS_088\r\n",
      "2025-11-25 19:55:44.104317: BRATS_088, shape torch.Size([4, 142, 171, 133]), rank 0\r\n",
      "2025-11-25 19:55:55.588759: predicting BRATS_089\r\n",
      "2025-11-25 19:55:55.689061: BRATS_089, shape torch.Size([4, 143, 181, 134]), rank 0\r\n",
      "2025-11-25 19:56:07.168366: predicting BRATS_098\r\n",
      "2025-11-25 19:56:07.257653: BRATS_098, shape torch.Size([4, 141, 169, 135]), rank 0\r\n",
      "2025-11-25 19:56:18.730182: predicting BRATS_100\r\n",
      "2025-11-25 19:56:18.816010: BRATS_100, shape torch.Size([4, 139, 158, 139]), rank 0\r\n",
      "2025-11-25 19:56:30.291420: predicting BRATS_101\r\n",
      "2025-11-25 19:56:30.378598: BRATS_101, shape torch.Size([4, 139, 167, 145]), rank 0\r\n",
      "2025-11-25 19:56:41.853002: predicting BRATS_104\r\n",
      "2025-11-25 19:56:41.937381: BRATS_104, shape torch.Size([4, 140, 172, 140]), rank 0\r\n",
      "2025-11-25 19:56:53.423141: predicting BRATS_107\r\n",
      "2025-11-25 19:56:53.518301: BRATS_107, shape torch.Size([4, 140, 169, 139]), rank 0\r\n",
      "2025-11-25 19:57:04.995545: predicting BRATS_111\r\n",
      "2025-11-25 19:57:05.096620: BRATS_111, shape torch.Size([4, 143, 173, 151]), rank 0\r\n",
      "2025-11-25 19:57:16.614028: predicting BRATS_113\r\n",
      "2025-11-25 19:57:16.707276: BRATS_113, shape torch.Size([4, 141, 173, 134]), rank 0\r\n",
      "2025-11-25 19:57:28.178237: predicting BRATS_114\r\n",
      "2025-11-25 19:57:28.284306: BRATS_114, shape torch.Size([4, 143, 180, 138]), rank 0\r\n",
      "2025-11-25 19:57:39.781352: predicting BRATS_116\r\n",
      "2025-11-25 19:57:39.868534: BRATS_116, shape torch.Size([4, 142, 174, 134]), rank 0\r\n",
      "2025-11-25 19:57:51.350080: predicting BRATS_131\r\n",
      "2025-11-25 19:57:51.450030: BRATS_131, shape torch.Size([4, 146, 176, 142]), rank 0\r\n",
      "2025-11-25 19:58:02.928805: predicting BRATS_137\r\n",
      "2025-11-25 19:58:03.022351: BRATS_137, shape torch.Size([4, 135, 174, 141]), rank 0\r\n",
      "2025-11-25 19:58:14.494240: predicting BRATS_138\r\n",
      "2025-11-25 19:58:14.581505: BRATS_138, shape torch.Size([4, 130, 169, 128]), rank 0\r\n",
      "2025-11-25 19:58:20.347342: predicting BRATS_145\r\n",
      "2025-11-25 19:58:20.462187: BRATS_145, shape torch.Size([4, 142, 166, 149]), rank 0\r\n",
      "2025-11-25 19:58:31.956309: predicting BRATS_149\r\n",
      "2025-11-25 19:58:32.085221: BRATS_149, shape torch.Size([4, 139, 164, 157]), rank 0\r\n",
      "2025-11-25 19:58:43.564324: predicting BRATS_150\r\n",
      "2025-11-25 19:58:43.626040: BRATS_150, shape torch.Size([4, 117, 145, 127]), rank 0\r\n",
      "2025-11-25 19:58:46.575030: predicting BRATS_153\r\n",
      "2025-11-25 19:58:46.654014: BRATS_153, shape torch.Size([4, 143, 168, 137]), rank 0\r\n",
      "2025-11-25 19:58:58.125896: predicting BRATS_155\r\n",
      "2025-11-25 19:58:58.197420: BRATS_155, shape torch.Size([4, 134, 160, 130]), rank 0\r\n",
      "2025-11-25 19:59:09.668432: predicting BRATS_161\r\n",
      "2025-11-25 19:59:09.761034: BRATS_161, shape torch.Size([4, 139, 169, 135]), rank 0\r\n",
      "2025-11-25 19:59:21.248477: predicting BRATS_174\r\n",
      "2025-11-25 19:59:21.348112: BRATS_174, shape torch.Size([4, 135, 161, 134]), rank 0\r\n",
      "2025-11-25 19:59:32.844189: predicting BRATS_175\r\n",
      "2025-11-25 19:59:32.936317: BRATS_175, shape torch.Size([4, 137, 163, 136]), rank 0\r\n",
      "2025-11-25 19:59:44.414334: predicting BRATS_181\r\n",
      "2025-11-25 19:59:44.486523: BRATS_181, shape torch.Size([4, 130, 162, 137]), rank 0\r\n",
      "2025-11-25 19:59:55.977919: predicting BRATS_187\r\n",
      "2025-11-25 19:59:56.063156: BRATS_187, shape torch.Size([4, 139, 163, 128]), rank 0\r\n",
      "2025-11-25 20:00:01.827869: predicting BRATS_191\r\n",
      "2025-11-25 20:00:01.916726: BRATS_191, shape torch.Size([4, 134, 161, 135]), rank 0\r\n",
      "2025-11-25 20:00:13.402303: predicting BRATS_196\r\n",
      "2025-11-25 20:00:13.493363: BRATS_196, shape torch.Size([4, 138, 161, 139]), rank 0\r\n",
      "2025-11-25 20:00:24.979532: predicting BRATS_203\r\n",
      "2025-11-25 20:00:25.073487: BRATS_203, shape torch.Size([4, 139, 170, 136]), rank 0\r\n",
      "2025-11-25 20:00:36.554133: predicting BRATS_205\r\n",
      "2025-11-25 20:00:36.644185: BRATS_205, shape torch.Size([4, 141, 166, 144]), rank 0\r\n",
      "2025-11-25 20:00:48.121018: predicting BRATS_207\r\n",
      "2025-11-25 20:00:48.232922: BRATS_207, shape torch.Size([4, 138, 173, 143]), rank 0\r\n",
      "2025-11-25 20:00:59.727118: predicting BRATS_214\r\n",
      "2025-11-25 20:00:59.824128: BRATS_214, shape torch.Size([4, 134, 159, 133]), rank 0\r\n",
      "2025-11-25 20:01:11.307670: predicting BRATS_223\r\n",
      "2025-11-25 20:01:11.428428: BRATS_223, shape torch.Size([4, 142, 175, 136]), rank 0\r\n",
      "2025-11-25 20:01:22.912497: predicting BRATS_224\r\n",
      "2025-11-25 20:01:23.013644: BRATS_224, shape torch.Size([4, 141, 166, 140]), rank 0\r\n",
      "2025-11-25 20:01:34.501301: predicting BRATS_226\r\n",
      "2025-11-25 20:01:34.588685: BRATS_226, shape torch.Size([4, 143, 168, 133]), rank 0\r\n",
      "2025-11-25 20:01:46.077575: predicting BRATS_229\r\n",
      "2025-11-25 20:01:46.181964: BRATS_229, shape torch.Size([4, 136, 167, 137]), rank 0\r\n",
      "2025-11-25 20:01:57.660703: predicting BRATS_239\r\n",
      "2025-11-25 20:01:57.751025: BRATS_239, shape torch.Size([4, 138, 159, 142]), rank 0\r\n",
      "2025-11-25 20:02:09.239897: predicting BRATS_244\r\n",
      "2025-11-25 20:02:09.336850: BRATS_244, shape torch.Size([4, 146, 172, 131]), rank 0\r\n",
      "2025-11-25 20:02:20.823882: predicting BRATS_251\r\n",
      "2025-11-25 20:02:20.939648: BRATS_251, shape torch.Size([4, 139, 164, 136]), rank 0\r\n",
      "2025-11-25 20:02:32.413026: predicting BRATS_266\r\n",
      "2025-11-25 20:02:32.525176: BRATS_266, shape torch.Size([4, 138, 163, 137]), rank 0\r\n",
      "2025-11-25 20:02:44.007198: predicting BRATS_285\r\n",
      "2025-11-25 20:02:44.101225: BRATS_285, shape torch.Size([4, 139, 164, 132]), rank 0\r\n",
      "2025-11-25 20:02:55.588830: predicting BRATS_299\r\n",
      "2025-11-25 20:02:55.672006: BRATS_299, shape torch.Size([4, 141, 170, 137]), rank 0\r\n",
      "2025-11-25 20:03:07.150396: predicting BRATS_301\r\n",
      "2025-11-25 20:03:07.235785: BRATS_301, shape torch.Size([4, 136, 174, 135]), rank 0\r\n",
      "2025-11-25 20:03:18.722514: predicting BRATS_304\r\n",
      "2025-11-25 20:03:18.790199: BRATS_304, shape torch.Size([4, 132, 159, 126]), rank 0\r\n",
      "2025-11-25 20:03:24.602348: predicting BRATS_308\r\n",
      "2025-11-25 20:03:24.676490: BRATS_308, shape torch.Size([4, 130, 165, 140]), rank 0\r\n",
      "2025-11-25 20:03:36.144630: predicting BRATS_328\r\n",
      "2025-11-25 20:03:36.247544: BRATS_328, shape torch.Size([4, 138, 176, 144]), rank 0\r\n",
      "2025-11-25 20:03:47.720093: predicting BRATS_330\r\n",
      "2025-11-25 20:03:47.810515: BRATS_330, shape torch.Size([4, 135, 162, 135]), rank 0\r\n",
      "2025-11-25 20:03:59.291352: predicting BRATS_341\r\n",
      "2025-11-25 20:03:59.368922: BRATS_341, shape torch.Size([4, 136, 163, 136]), rank 0\r\n",
      "2025-11-25 20:04:10.842562: predicting BRATS_343\r\n",
      "2025-11-25 20:04:10.944411: BRATS_343, shape torch.Size([4, 141, 184, 139]), rank 0\r\n",
      "2025-11-25 20:04:22.426866: predicting BRATS_349\r\n",
      "2025-11-25 20:04:22.499706: BRATS_349, shape torch.Size([4, 105, 183, 133]), rank 0\r\n",
      "2025-11-25 20:04:28.329827: predicting BRATS_352\r\n",
      "2025-11-25 20:04:28.415606: BRATS_352, shape torch.Size([4, 144, 180, 130]), rank 0\r\n",
      "2025-11-25 20:04:39.898370: predicting BRATS_354\r\n",
      "2025-11-25 20:04:39.984300: BRATS_354, shape torch.Size([4, 140, 177, 138]), rank 0\r\n",
      "2025-11-25 20:04:51.475292: predicting BRATS_356\r\n",
      "2025-11-25 20:04:51.565136: BRATS_356, shape torch.Size([4, 141, 172, 133]), rank 0\r\n",
      "2025-11-25 20:05:03.051232: predicting BRATS_360\r\n",
      "2025-11-25 20:05:03.107316: BRATS_360, shape torch.Size([4, 100, 168, 127]), rank 0\r\n",
      "2025-11-25 20:05:06.076492: predicting BRATS_368\r\n",
      "2025-11-25 20:05:06.163625: BRATS_368, shape torch.Size([4, 138, 171, 133]), rank 0\r\n",
      "2025-11-25 20:05:17.639811: predicting BRATS_369\r\n",
      "2025-11-25 20:05:17.736428: BRATS_369, shape torch.Size([4, 146, 183, 154]), rank 0\r\n",
      "2025-11-25 20:06:00.494399: Validation complete\r\n",
      "2025-11-25 20:06:00.494519: Mean Validation Dice:  0.7862747534954554\r\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# CELL 4: START TRAINING\n",
    "# ------------------------------------------------------------------\n",
    "print(\"ğŸš€ Báº®T Äáº¦U TRAINING (Fold 0 - 30 Epochs)...\")\n",
    "# LÆ°u Ã½: Cá» --npz sáº½ lÆ°u file .npz ráº¥t náº·ng. Náº¿u sá»£ trÃ n á»• cá»©ng Kaggle thÃ¬ xÃ³a cá» nÃ y Ä‘i.\n",
    "!nnUNetv2_train Dataset101_BraTS2020 3d_fullres 0 -tr EDLTrainer --npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502fb249",
   "metadata": {
    "papermill": {
     "duration": 0.032578,
     "end_time": "2025-11-25T20:06:03.596902",
     "exception": false,
     "start_time": "2025-11-25T20:06:03.564324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 5: ÄÃ³ng gÃ³i & Xuáº¥t káº¿t quáº£ (Export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12d6ef9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:06:03.734659Z",
     "iopub.status.busy": "2025-11-25T20:06:03.734215Z",
     "iopub.status.idle": "2025-11-25T20:06:37.385460Z",
     "shell.execute_reply": "2025-11-25T20:06:37.384716Z"
    },
    "papermill": {
     "duration": 33.718443,
     "end_time": "2025-11-25T20:06:37.419589",
     "exception": false,
     "start_time": "2025-11-25T20:06:03.701146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Äang Ä‘Ã³ng gÃ³i káº¿t quáº£...\n",
      "âœ… ÄÃ£ nÃ©n thÃ nh cÃ´ng: /kaggle/working/BraTS2020_EDL_Fold0_Results.zip\n",
      "   (Giáº£i nÃ©n ra sáº½ cÃ³ sáºµn folder nnUNet_results/Dataset101...)\n",
      "âœ… ÄÃ£ lÆ°u riÃªng splits_final.json táº¡i: /kaggle/working/splits_final.json\n",
      "ğŸ‰ HOÃ€N Táº¤T! Báº N CÃ“ THá»‚ Táº¢I FILE Vá»€ Tá»ª TAB OUTPUT.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# CELL 5: EXPORT RESULTS (CODE NÃ‰N GIá»® NGUYÃŠN Cáº¤U TRÃšC FOLDER)\n",
    "# ------------------------------------------------------------------\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“¦ Äang Ä‘Ã³ng gÃ³i káº¿t quáº£...\")\n",
    "\n",
    "# 1. NÃ©n Model (Giá»¯ nguyÃªn cáº¥u trÃºc nnUNet_results/...)\n",
    "# ChÃºng ta sáº½ nÃ©n tá»« thÆ° má»¥c gá»‘c /kaggle/working\n",
    "output_zip_name = \"/kaggle/working/BraTS2020_EDL_Fold0_Results\"\n",
    "root_dir = \"/kaggle/working\"\n",
    "base_dir = \"nnUNet_results\" # Chá»‰ nÃ©n folder nÃ y vÃ  cÃ¡c con cá»§a nÃ³\n",
    "\n",
    "try:\n",
    "    shutil.make_archive(output_zip_name, 'zip', root_dir, base_dir)\n",
    "    print(f\"âœ… ÄÃ£ nÃ©n thÃ nh cÃ´ng: {output_zip_name}.zip\")\n",
    "    print(\"   (Giáº£i nÃ©n ra sáº½ cÃ³ sáºµn folder nnUNet_results/Dataset101...)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Lá»—i khi nÃ©n: {e}\")\n",
    "\n",
    "# 2. Copy file splits_final.json (Váº«n giá»¯ nguyÃªn bÆ°á»›c nÃ y Ä‘á»ƒ backup)\n",
    "src_split = \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\"\n",
    "dst_split = \"/kaggle/working/splits_final.json\"\n",
    "\n",
    "if os.path.exists(src_split):\n",
    "    shutil.copy(src_split, dst_split)\n",
    "    print(f\"âœ… ÄÃ£ lÆ°u riÃªng splits_final.json táº¡i: {dst_split}\")\n",
    "else:\n",
    "    print(\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file splits_final.json.\")\n",
    "\n",
    "print(\"ğŸ‰ HOÃ€N Táº¤T! Báº N CÃ“ THá»‚ Táº¢I FILE Vá»€ Tá»ª TAB OUTPUT.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82345d69",
   "metadata": {
    "papermill": {
     "duration": 0.03264,
     "end_time": "2025-11-25T20:06:37.484687",
     "exception": false,
     "start_time": "2025-11-25T20:06:37.452047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cell 6: HÃ¬nh áº£nh so sÃ¡nh MRI vs AI Prediction vs Uncertainty Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc94f5c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T20:06:37.551344Z",
     "iopub.status.busy": "2025-11-25T20:06:37.551082Z",
     "iopub.status.idle": "2025-11-25T20:06:37.558488Z",
     "shell.execute_reply": "2025-11-25T20:06:37.557785Z"
    },
    "papermill": {
     "duration": 0.042464,
     "end_time": "2025-11-25T20:06:37.559744",
     "exception": false,
     "start_time": "2025-11-25T20:06:37.517280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "# import json\n",
    "# import shutil\n",
    "\n",
    "# # --- QUAN TRá»ŒNG: Táº®T COMPILE CHO P100 ---\n",
    "# os.environ['nnUNet_compile'] = 'F'\n",
    "\n",
    "# # ==============================================================================\n",
    "# # âš™ï¸ KAGGLE CONFIGURATION (ÄÃƒ Sá»¬A ÄÆ¯á»œNG DáºªN)\n",
    "# # ==============================================================================\n",
    "# CONFIG = {\n",
    "#     # 1. ÄÆ°á»ng dáº«n Model (Láº¥y tá»« folder working)\n",
    "#     \"checkpoint_path\": \"/kaggle/working/nnUNet_results/Dataset101_BraTS2020/EDLTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth\",\n",
    "    \n",
    "#     # 2. ÄÆ°á»ng dáº«n Data (Láº¥y tá»« folder temp symlink)\n",
    "#     \"image_folder\": \"/kaggle/temp/nnUNet_raw/Dataset101_BraTS2020/imagesTr\",\n",
    "#     \"label_folder\": \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/gt_segmentations\", # DÃ¹ng GT Ä‘Ã£ preprocessed cho tiá»‡n\n",
    "#     \"split_file\":   \"/kaggle/temp/nnUNet_preprocessed/Dataset101_BraTS2020/splits_final.json\",\n",
    "\n",
    "#     # 3. ÄÆ°á»ng dáº«n lÆ°u káº¿t quáº£ (LÆ°u vÃ o working Ä‘á»ƒ táº£i vá»)\n",
    "#     \"output_folder\": \"/kaggle/working/inference_results_batch\",\n",
    "    \n",
    "#     # 4. Cáº¥u hÃ¬nh cháº¡y\n",
    "#     \"run_mode\":         \"validation_split\",  # Cháº¡y Ä‘Ãºng táº­p Validation cá»§a Fold 0\n",
    "#     \"test_range\":       [0, 10], \n",
    "#     \"num_random\":       5,        \n",
    "    \n",
    "#     # 5. TÃ¹y chá»n hiá»ƒn thá»‹\n",
    "#     \"save_images\":      True,     \n",
    "#     \"show_on_screen\":   True,    \n",
    "# }\n",
    "# # ==============================================================================\n",
    "\n",
    "# def get_case_list(folder):\n",
    "#     if not os.path.exists(folder):\n",
    "#         raise FileNotFoundError(f\"âŒ Folder {folder} khÃ´ng tá»“n táº¡i!\")\n",
    "#     files = sorted([f for f in os.listdir(folder) if f.endswith(\"_0000.nii\") or f.endswith(\"_0000.nii.gz\")])\n",
    "#     case_ids = []\n",
    "#     for f in files:\n",
    "#         if f.endswith(\".nii\"): cid = f.replace(\"_0000.nii\", \"\")\n",
    "#         else: cid = f.replace(\"_0000.nii.gz\", \"\")\n",
    "#         case_ids.append(cid)\n",
    "#     return case_ids\n",
    "\n",
    "# def calculate_dice(pred_slice, gt_slice):\n",
    "#     p = (pred_slice > 0).astype(np.float32)\n",
    "#     g = (gt_slice > 0).astype(np.float32)\n",
    "#     intersection = np.sum(p * g)\n",
    "#     sum_areas = np.sum(p) + np.sum(g)\n",
    "#     if sum_areas == 0: return 1.0\n",
    "#     return (2.0 * intersection) / sum_areas\n",
    "\n",
    "# def visualize_comparison(case_id, mri_data, gt_data, pred_data, uncertainty, slice_idx=None):\n",
    "#     # TÃ¬m slice cÃ³ khá»‘i u lá»›n nháº¥t Ä‘á»ƒ váº½ cho Ä‘áº¹p\n",
    "#     if slice_idx is None:\n",
    "#         sums_gt = np.sum(gt_data, axis=(0, 1, 2))\n",
    "#         sums_pred = np.sum(pred_data, axis=(0, 1))\n",
    "        \n",
    "#         if sums_gt.max() > 0: slice_idx = np.argmax(sums_gt)\n",
    "#         elif sums_pred.max() > 0: slice_idx = np.argmax(sums_pred)\n",
    "#         else: slice_idx = gt_data.shape[3] // 2\n",
    "\n",
    "#     print(f\"    ğŸ“¸ Drawing Slice: {slice_idx}\")\n",
    "\n",
    "#     # Xoay áº£nh cho Ä‘Ãºng chiá»u (.T)\n",
    "#     img_slice = mri_data[0, :, :, slice_idx].T\n",
    "    \n",
    "#     # GT data tá»« preprocessed folder thÆ°á»ng cÃ³ shape [C, X, Y, Z] hoáº·c [X, Y, Z]\n",
    "#     # Náº¿u gt_data lÃ  [1, X, Y, Z]\n",
    "#     if gt_data.ndim == 4:\n",
    "#         gt_slice = gt_data[0, :, :, slice_idx].T\n",
    "#     else:\n",
    "#         gt_slice = gt_data[:, :, slice_idx].T\n",
    "        \n",
    "#     pred_slice = pred_data[:, :, slice_idx].T\n",
    "#     unc_slice = uncertainty[:, :, slice_idx].T\n",
    "\n",
    "#     dice = calculate_dice(pred_slice, gt_slice)\n",
    "#     ratio = (np.sum(pred_slice>0) / np.sum(gt_slice>0) * 100) if np.sum(gt_slice>0) > 0 else 0\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 4, figsize=(24, 6))\n",
    "#     plt.suptitle(f\"Case: {case_id} | Slice: {slice_idx}\", fontsize=16, y=0.98)\n",
    "\n",
    "#     # 1. MRI\n",
    "#     ax[0].imshow(img_slice, cmap='gray', origin='lower')\n",
    "#     ax[0].set_title(\"MRI Input\", fontsize=12)\n",
    "#     ax[0].axis('off')\n",
    "\n",
    "#     # 2. GT\n",
    "#     ax[1].imshow(img_slice, cmap='gray', origin='lower', alpha=0.6)\n",
    "#     if np.any(gt_slice): ax[1].imshow(gt_slice, cmap='Greens', origin='lower', alpha=0.6, interpolation='nearest')\n",
    "#     ax[1].set_title(\"Ground Truth\", fontsize=12, color='green')\n",
    "#     ax[1].axis('off')\n",
    "\n",
    "#     # 3. Pred\n",
    "#     ax[2].imshow(img_slice, cmap='gray', origin='lower', alpha=0.6)\n",
    "#     if np.any(pred_slice): ax[2].imshow(pred_slice, cmap='jet', origin='lower', alpha=0.5, interpolation='nearest')\n",
    "#     ax[2].set_title(f\"AI Prediction\\nDice: {dice:.1%} | Area: {ratio:.0f}%\", fontsize=12, color='blue')\n",
    "#     ax[2].axis('off')\n",
    "\n",
    "#     # 4. Uncertainty\n",
    "#     im = ax[3].imshow(unc_slice, cmap='hot', origin='lower', vmin=0, vmax=1.0)\n",
    "#     ax[3].set_title(\"Uncertainty Map\", fontsize=12, color='red')\n",
    "#     ax[3].axis('off')\n",
    "#     plt.colorbar(im, ax=ax[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "#     if CONFIG[\"save_images\"]:\n",
    "#         os.makedirs(CONFIG[\"output_folder\"], exist_ok=True)\n",
    "#         save_path = os.path.join(CONFIG[\"output_folder\"], f\"{case_id}_slice{slice_idx}.png\")\n",
    "#         plt.savefig(save_path, bbox_inches='tight', dpi=100)\n",
    "#         print(f\"    âœ… Saved: {save_path}\")\n",
    "    \n",
    "#     if CONFIG[\"show_on_screen\"]:\n",
    "#         plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "# def process_case(predictor, case_id):\n",
    "#     print(f\"\\nğŸ” Processing: {case_id}...\")\n",
    "    \n",
    "#     # TÃ¬m file áº£nh input\n",
    "#     base_file = os.path.join(CONFIG[\"image_folder\"], f\"{case_id}_0000.nii\")\n",
    "#     ext = \".nii\" if os.path.exists(base_file) else \".nii.gz\"\n",
    "    \n",
    "#     image_files = [os.path.join(CONFIG[\"image_folder\"], f\"{case_id}_{i:04d}{ext}\") for i in range(4)]\n",
    "    \n",
    "#     # TÃ¬m file nhÃ£n (GT)\n",
    "#     gt_file = os.path.join(CONFIG[\"label_folder\"], f\"{case_id}{ext}\")\n",
    "#     if not os.path.exists(gt_file):\n",
    "#         # Thá»­ tÃ¬m trong preprocessed náº¿u raw khÃ´ng cÃ³\n",
    "#         gt_file = os.path.join(CONFIG[\"label_folder\"], f\"{case_id}.nii.gz\")\n",
    "    \n",
    "#     if not os.path.exists(gt_file):\n",
    "#         print(f\"    âš ï¸ Skipping {case_id}: Label file missing.\")\n",
    "#         return\n",
    "\n",
    "#     # Preprocessing & Inference\n",
    "#     preprocessor = predictor.configuration_manager.preprocessor_class(verbose=False)\n",
    "#     # Load vÃ  crop dá»¯ liá»‡u\n",
    "#     data, seg, _ = preprocessor.run_case(image_files, gt_file, predictor.plans_manager, predictor.configuration_manager, predictor.dataset_json)\n",
    "    \n",
    "#     # Predict\n",
    "#     data_tensor = torch.from_numpy(data).to(predictor.device)\n",
    "#     pred_logits = predictor.predict_logits_from_preprocessed_data(data_tensor)\n",
    "    \n",
    "#     # TÃ­nh EDL Uncertainty\n",
    "#     evidence = F.softplus(pred_logits)\n",
    "#     alpha = evidence + 1\n",
    "#     S = torch.sum(alpha, dim=0)\n",
    "#     K = alpha.shape[0]\n",
    "#     uncertainty = (K / S).cpu().numpy()\n",
    "#     segmentation = torch.argmax(pred_logits, dim=0).cpu().numpy()\n",
    "    \n",
    "#     visualize_comparison(case_id, data, seg, segmentation, uncertainty)\n",
    "\n",
    "# def get_validation_cases(fold=0):\n",
    "#     split_file = CONFIG[\"split_file\"]\n",
    "#     if not os.path.exists(split_file):\n",
    "#         raise FileNotFoundError(f\"âŒ KhÃ´ng tÃ¬m tháº¥y file split táº¡i: {split_file}\")\n",
    "        \n",
    "#     with open(split_file, 'r') as f:\n",
    "#         splits = json.load(f)\n",
    "    \n",
    "#     if fold >= len(splits):\n",
    "#         raise ValueError(f\"âŒ Fold {fold} khÃ´ng tá»“n táº¡i!\")\n",
    "        \n",
    "#     val_keys = splits[fold]['val']\n",
    "#     print(f\"ğŸ“‚ ÄÃ£ load danh sÃ¡ch Validation Fold {fold}: {len(val_keys)} ca.\")\n",
    "#     return val_keys\n",
    "\n",
    "# def main():\n",
    "#     print(\"ğŸš€ --- BATCH INFERENCE STARTED ---\")\n",
    "    \n",
    "#     # Load Model\n",
    "#     predictor = nnUNetPredictor(\n",
    "#         tile_step_size=0.5, use_gaussian=True, use_mirroring=True,\n",
    "#         device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'),\n",
    "#         verbose=False\n",
    "#     )\n",
    "    \n",
    "#     checkpoint_folder = os.path.dirname(os.path.dirname(CONFIG[\"checkpoint_path\"]))\n",
    "#     # nnUNetPredictor tá»± tÃ¬m fold_X trong folder nÃ y\n",
    "#     predictor.initialize_from_trained_model_folder(checkpoint_folder, use_folds=(0,), checkpoint_name=\"checkpoint_best.pth\")\n",
    "#     print(f\"ğŸ“‚ Model Loaded.\")\n",
    "\n",
    "#     if CONFIG[\"run_mode\"] == \"validation_split\":\n",
    "#         cases_to_run = get_validation_cases(fold=0)\n",
    "#         # cases_to_run = cases_to_run[:5] # Bá» comment náº¿u muá»‘n test nhanh 5 ca Ä‘áº§u\n",
    "#         print(f\"âš™ï¸ Mode: VALIDATION SPLIT (Fold 0) -> Running {len(cases_to_run)} cases.\")\n",
    "#     else:\n",
    "#         # Code cho mode random/range giá»¯ nguyÃªn\n",
    "#         pass\n",
    "\n",
    "#     for case_id in cases_to_run:\n",
    "#         try:\n",
    "#             process_case(predictor, case_id)\n",
    "#         except Exception as e:\n",
    "#             print(f\"    âŒ Error processing {case_id}: {e}\")\n",
    "\n",
    "#     print(\"\\nâœ… --- BATCH INFERENCE FINISHED ---\")\n",
    "    \n",
    "#     # NÃ©n áº£nh káº¿t quáº£ Ä‘á»ƒ táº£i vá»\n",
    "#     shutil.make_archive(\"/kaggle/working/inference_images\", 'zip', CONFIG[\"output_folder\"])\n",
    "#     print(\"ğŸ“¦ ÄÃ£ nÃ©n áº£nh káº¿t quáº£: /kaggle/working/inference_images.zip\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc149e",
   "metadata": {
    "papermill": {
     "duration": 0.032953,
     "end_time": "2025-11-25T20:06:37.625597",
     "exception": false,
     "start_time": "2025-11-25T20:06:37.592644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8803257,
     "sourceId": 13844758,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19269.486501,
   "end_time": "2025-11-25T20:06:37.974946",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-25T14:45:28.488445",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
