"""
üß† EDL ENGINE (FINAL ROBUST V7)
H·ªó tr·ª£ ch·∫°y Inference cho c·∫£ 2 ch·∫ø ƒë·ªô:
1. EDL Model: T√≠nh to√°n Uncertainty Decomposition (Aleatoric/Epistemic).
2. Baseline Model: Ch·ªâ ch·∫°y Segmentation chu·∫©n (nhanh h∆°n).

ƒê·∫∑c ƒëi·ªÉm:
- T·ª± ƒë·ªông inject EDLTrainer ƒë·ªÉ tr√°nh l·ªói class.
- X·ª≠ l√Ω l·ªói (Error Handling) ch·∫∑t ch·∫Ω, kh√¥ng crash khi thi·∫øu file.
- Comment chi ti·∫øt ƒë·ªÉ d·ªÖ hi·ªÉu logic to√°n h·ªçc.
"""
import os
import shutil
import torch
import torch.nn.functional as F
import numpy as np
import nibabel as nib
from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor
import nnunetv2

class EDLInferenceEngine:
    def __init__(self, config):
        self.config = config
        mode = config.get('model_mode', 'edl').upper()
        print(f"üîß Initializing Engine | Mode: {mode}...")
        
        self._inject_custom_trainer() # <--- B∆∞·ªõc quan tr·ªçng: Ti√™m Trainer
        self.predictor = self._initialize_predictor()
        
        # Preprocessor d√πng ƒë·ªÉ crop v√† chu·∫©n h√≥a d·ªØ li·ªáu ƒë·∫ßu v√†o
        self.preprocessor = self.predictor.configuration_manager.preprocessor_class(verbose=False)

    def _inject_custom_trainer(self):
        """
        Copy file EDLTrainer.py t·ª´ src/trainers v√†o th∆∞ m·ª•c c√†i ƒë·∫∑t c·ªßa nnunetv2
        ƒë·ªÉ h√†m recursive_find_python_class c√≥ th·ªÉ t√¨m th·∫•y n√≥.
        C√≥ b·∫Øt l·ªói try-except ƒë·ªÉ kh√¥ng l√†m d·ª´ng ch∆∞∆°ng tr√¨nh n·∫øu copy th·∫•t b·∫°i.
        """
        try:
            # 1. T√¨m v·ªã tr√≠ c√†i ƒë·∫∑t nnunetv2 trong m√¥i tr∆∞·ªùng Python hi·ªán t·∫°i
            nnunet_path = os.path.dirname(nnunetv2.__file__)
            target_folder = os.path.join(nnunet_path, "training", "nnUNetTrainer")
            
            # 2. T√¨m file source trong th∆∞ m·ª•c d·ª± √°n (src/trainers)
            current_dir = os.path.dirname(os.path.abspath(__file__))
            source_file = os.path.join(current_dir, "trainers", "EDLTrainer.py")
            
            if not os.path.exists(source_file):
                # print(f"‚ö†Ô∏è Warning: Kh√¥ng t√¨m th·∫•y file trainer t·∫°i {source_file}. B·ªè qua b∆∞·ªõc inject.")
                return

            # 3. Copy file (Overwrite n·∫øu ƒë√£ t·ªìn t·∫°i)
            target_file = os.path.join(target_folder, "EDLTrainer.py")
            shutil.copy(source_file, target_file)
            # print("‚úÖ Inject th√†nh c√¥ng! nnU-Net s·∫Ω nh·∫≠n di·ªán ƒë∆∞·ª£c EDLTrainer.")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: L·ªói khi inject trainer (C√≥ th·ªÉ b·ªè qua n·∫øu ƒëang d√πng Standard Trainer): {e}")

    def _initialize_predictor(self):
        """Kh·ªüi t·∫°o v√† load tr·ªçng s·ªë Model"""
        print("üöÄ Initializing nnU-Net Predictor...")
        try:
            predictor = nnUNetPredictor(
                tile_step_size=0.5, use_gaussian=True, use_mirroring=True,
                device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'),
                verbose=False
            )
            
            ckpt_path = self.config["checkpoint_path"]
            if not os.path.exists(ckpt_path):
                raise FileNotFoundError(f"‚ùå Checkpoint not found: {ckpt_path}")
                
            # nnU-Net y√™u c·∫ßu ƒë∆∞·ªùng d·∫´n folder cha ch·ª©a file checkpoint
            checkpoint_folder = os.path.dirname(os.path.dirname(ckpt_path))
            
            predictor.initialize_from_trained_model_folder(
                checkpoint_folder, use_folds=(0,), checkpoint_name="checkpoint_best.pth"
            )
            print(f"üìÇ Model loaded from: {checkpoint_folder}")
            return predictor
            
        except Exception as e:
            print(f"‚ùå Critical Error initializing predictor: {e}")
            raise e # L·ªói n√†y nghi√™m tr·ªçng, c·∫ßn raise ƒë·ªÉ d·ª´ng ch∆∞∆°ng tr√¨nh

    def save_nifti(self, data, affine, output_path):
        """H√†m ph·ª• tr·ª£ l∆∞u m·∫£ng numpy th√†nh file .nii.gz"""
        try:
            # data shape: [X, Y, Z] -> Ph·∫£i √©p ki·ªÉu v·ªÅ float32 ƒë·ªÉ tr√°nh l·ªói format header
            img = nib.Nifti1Image(data.astype(np.float32), affine)
            nib.save(img, output_path)
        except Exception as e:
            print(f"‚ö†Ô∏è Error saving NIfTI {output_path}: {e}")

    def process_case(self, case_id):
        """
        X·ª≠ l√Ω tr·ªçn v·∫πn m·ªôt ca b·ªánh:
        1. Load ·∫£nh & Preprocess
        2. Inference (D·ª± ƒëo√°n)
        3. T√≠nh Uncertainty (N·∫øu mode=EDL)
        4. L∆∞u file k·∫øt qu·∫£
        """
        # print(f"\nüîç Processing: {case_id}...")
        
        # --- 1. SETUP PATHS & CHECK FILES (C∆° ch·∫ø b·∫£o v·ªá) ---
        img_folder = self.config["image_folder"]
        lbl_folder = self.config["label_folder"]
        
        base_file = os.path.join(img_folder, f"{case_id}_0000.nii")
        ext = ".nii" if os.path.exists(base_file) else ".nii.gz"
        
        # T·∫°o danh s√°ch 4 k√™nh (FLAIR, T1w, T1gd, T2w)
        image_files = [os.path.join(img_folder, f"{case_id}_{i:04d}{ext}") for i in range(4)]
        
        # [QUAN TR·ªåNG] Ki·ªÉm tra file input c√≥ t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(image_files[0]):
            print(f"‚ùå Error: Input files for {case_id} not found.")
            return None, None, None, None, None

        # [FIX] T√¨m file GT th√¥ng minh
        gt_file = None
        gt_path_gz = os.path.join(lbl_folder, f"{case_id}.nii.gz")
        gt_path_nii = os.path.join(lbl_folder, f"{case_id}.nii")
        
        # --- TH√äM ƒêO·∫†N DEBUG N√ÄY ---
        print(f"üîç DEBUG: ƒêang t√¨m GT cho {case_id}...")
        print(f"   - Th·ª≠: {gt_path_gz} -> {'C√ì' if os.path.exists(gt_path_gz) else 'KH√îNG'}")
        print(f"   - Th·ª≠: {gt_path_nii} -> {'C√ì' if os.path.exists(gt_path_nii) else 'KH√îNG'}")
        # ---------------------------

        if os.path.exists(gt_path_gz):
            gt_file = gt_path_gz
        elif os.path.exists(gt_path_nii):
            gt_file = gt_path_nii
        else:
            print(f"‚ö†Ô∏è WARNING: Kh√¥ng t√¨m th·∫•y GT! Code s·∫Ω ch·∫°y v·ªõi GT ƒëen s√¨.")
            gt_file = None

        # --- L·∫§Y AFFINE MATRIX G·ªêC ---
        # ƒê·ªÉ ƒë·∫£m b·∫£o file output ch·ªìng kh√≠t l√™n ·∫£nh g·ªëc trong ITK-SNAP
        try:
            tmp_img = nib.load(image_files[0])
            original_affine = tmp_img.affine
        except Exception as e:
            print(f"‚ùå Error loading affine from input image: {e}")
            return None, None, None, None, None

        # --- 2. PREPROCESSING ---
        try:
            data, seg, properties = self.preprocessor.run_case(
                image_files, gt_file, 
                self.predictor.plans_manager, 
                self.predictor.configuration_manager, 
                self.predictor.dataset_json
            )
        except Exception as e:
            print(f"‚ùå Error during preprocessing: {e}")
            return None, None, None, None, None
        
        # --- 3. INFERENCE ---
        # D√πng torch.no_grad() ƒë·ªÉ ti·∫øt ki·ªám VRAM, kh√¥ng l∆∞u gradient
        data_tensor = torch.from_numpy(data).to(self.predictor.device)
        with torch.no_grad():
            pred_logits = self.predictor.predict_logits_from_preprocessed_data(data_tensor)
        
        # --- 4. LOGIC PH√ÇN NH√ÅNH (EDL vs BASELINE) ---
        segmentation = torch.argmax(pred_logits, dim=0).cpu().numpy()
        
        # Kh·ªüi t·∫°o dict r·ªóng (ƒëen s√¨) ƒë·ªÉ code Visualizer kh√¥ng b·ªã l·ªói
        unc_dict = {
            "total": np.zeros(segmentation.shape),
            "aleatoric": np.zeros(segmentation.shape),
            "epistemic": np.zeros(segmentation.shape)
        }

        # L·∫•y mode t·ª´ config, m·∫∑c ƒë·ªãnh l√† 'edl' n·∫øu kh√¥ng khai b√°o
        model_mode = self.config.get("model_mode", "edl")

        if model_mode == "edl":
            # --- T√çNH TO√ÅN UNCERTAINTY DECOMPOSITION ---
            # C√¥ng th·ª©c d·ª±a tr√™n Information Theory (Entropy c·ªßa ph√¢n ph·ªëi Dirichlet)
            
            # a. T√≠nh tham s·ªë Dirichlet (alpha)
            evidence = F.softplus(pred_logits)
            alpha = evidence + 1
            S = torch.sum(alpha, dim=0, keepdim=True) # T·ªïng s·ª©c m·∫°nh b·∫±ng ch·ª©ng
            probs = alpha / S                         # X√°c su·∫•t k·ª≥ v·ªçng
            
            # b. Total Uncertainty (Entropy)
            # H(p) = - sum(p * log(p))
            # C·ªông th√™m 1e-7 ƒë·ªÉ tr√°nh l·ªói log(0) -> NaN
            total_unc = -torch.sum(probs * torch.log(probs + 1e-7), dim=0)
            
            # c. Aleatoric Uncertainty (Expected Entropy)
            # E[H(p)] approx sum(p * (digamma(S+1) - digamma(alpha+1)))
            digamma_S = torch.digamma(S + 1)
            digamma_alpha = torch.digamma(alpha + 1)
            aleatoric_unc = torch.sum(probs * (digamma_S - digamma_alpha), dim=0)
            
            # d. Epistemic Uncertainty (Mutual Information)
            # I = Total - Aleatoric
            epistemic_unc = total_unc - aleatoric_unc
            
            # e. Chu·∫©n h√≥a v·ªÅ Numpy & Clamp gi√° tr·ªã
            # Clamp min=0 ƒë·ªÉ tr√°nh sai s·ªë d·∫•u ch·∫•m ƒë·ªông l√†m ra s·ªë √¢m c·ª±c nh·ªè
            unc_dict = {
                "total": torch.clamp(total_unc, min=0).cpu().numpy(),
                "aleatoric": torch.clamp(aleatoric_unc, min=0).cpu().numpy(),
                "epistemic": torch.clamp(epistemic_unc, min=0).cpu().numpy()
            }
        
        # X·ª≠ l√Ω seg n·∫øu kh√¥ng c√≥ GT (t·∫°o ·∫£nh ƒëen ƒë·ªÉ visualize kh√¥ng l·ªói)
        if seg is None: seg = np.zeros((1, *segmentation.shape))
        
        # --- 5. SAVE NIFTI FILES ---
        if self.config.get("save_3d_nifti", False):
            try:
                nifti_folder_name = self.config.get("dir_nifti", "3d_nifti")
                out_dir = os.path.join(self.config["output_folder"], nifti_folder_name, case_id)
                os.makedirs(out_dir, exist_ok=True)
                
                # Ch·ªâ l∆∞u Uncertainty Maps n·∫øu ƒëang ch·∫°y mode EDL
                # (Baseline m√† l∆∞u c√°i n√†y th√¨ to√†n ·∫£nh ƒëen, t·ªën dung l∆∞·ª£ng v√¥ √≠ch)
                if model_mode == "edl":
                    self.save_nifti(unc_dict["total"], original_affine, os.path.join(out_dir, "unc_total.nii.gz"))
                    self.save_nifti(unc_dict["aleatoric"], original_affine, os.path.join(out_dir, "unc_aleatoric.nii.gz"))
                    self.save_nifti(unc_dict["epistemic"], original_affine, os.path.join(out_dir, "unc_epistemic.nii.gz"))
                
                # C√°c file c∆° b·∫£n (Lu√¥n l∆∞u)
                self.save_nifti(segmentation, original_affine, os.path.join(out_dir, "prediction.nii.gz"))
                self.save_nifti(seg[0], original_affine, os.path.join(out_dir, "ground_truth.nii.gz"))
                self.save_nifti(data[0], original_affine, os.path.join(out_dir, "mri_crop.nii.gz"))
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error saving NIfTI files for {case_id}: {e}")

        # Return dict uncertainty ƒë·∫ßy ƒë·ªß ƒë·ªÉ Visualizer v·∫Ω
        return data, seg, segmentation, unc_dict, properties