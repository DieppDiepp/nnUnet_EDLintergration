"""
üß† EDL ENGINE (UPDATED V5 - ROBUST MERGE)
K·∫øt h·ª£p logic ph√¢n r√£ Uncertainty (Aleatoric/Epistemic) v·ªõi khung code x·ª≠ l√Ω l·ªói an to√†n.
T·ª± ƒë·ªông inject EDLTrainer v√†o h·ªá th·ªëng nnU-Net ƒë·ªÉ tr√°nh l·ªói "Class not found".
"""
import os
import shutil
import torch
import torch.nn.functional as F
import numpy as np
import nibabel as nib
from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor
import nnunetv2

class EDLInferenceEngine:
    def __init__(self, config):
        self.config = config
        print(f"üîß Initializing EDL Engine with config...")
        self._inject_custom_trainer() # <--- B∆∞·ªõc quan tr·ªçng: Ti√™m Trainer
        self.predictor = self._initialize_predictor()
        self.preprocessor = self.predictor.configuration_manager.preprocessor_class(verbose=False)

    def _inject_custom_trainer(self):
        """
        Copy file EDLTrainer.py t·ª´ src/trainers v√†o th∆∞ m·ª•c c√†i ƒë·∫∑t c·ªßa nnunetv2
        ƒë·ªÉ h√†m recursive_find_python_class c√≥ th·ªÉ t√¨m th·∫•y n√≥.
        """
        try:
            # 1. T√¨m v·ªã tr√≠ c√†i ƒë·∫∑t nnunetv2
            nnunet_path = os.path.dirname(nnunetv2.__file__)
            target_folder = os.path.join(nnunet_path, "training", "nnUNetTrainer")
            
            # 2. T√¨m file source trong src/trainers
            current_dir = os.path.dirname(os.path.abspath(__file__))
            source_file = os.path.join(current_dir, "trainers", "EDLTrainer.py")
            
            if not os.path.exists(source_file):
                print(f"‚ö†Ô∏è Warning: Kh√¥ng t√¨m th·∫•y file trainer t·∫°i {source_file}. B·ªè qua b∆∞·ªõc inject.")
                return

            # 3. Copy file
            target_file = os.path.join(target_folder, "EDLTrainer.py")
            # print(f"üíâ Injecting EDLTrainer...\\n   From: {source_file}\\n   To:   {target_file}")
            shutil.copy(source_file, target_file)
            print("‚úÖ Inject th√†nh c√¥ng! nnU-Net s·∫Ω nh·∫≠n di·ªán ƒë∆∞·ª£c EDLTrainer.")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi inject trainer: {e}")

    def _initialize_predictor(self):
        print("üöÄ Initializing nnU-Net Predictor...")
        try:
            predictor = nnUNetPredictor(
                tile_step_size=0.5, use_gaussian=True, use_mirroring=True,
                device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'),
                verbose=False
            )
            
            ckpt_path = self.config["checkpoint_path"]
            if not os.path.exists(ckpt_path):
                raise FileNotFoundError(f"‚ùå Checkpoint not found: {ckpt_path}")
                
            checkpoint_folder = os.path.dirname(os.path.dirname(ckpt_path))
            predictor.initialize_from_trained_model_folder(
                checkpoint_folder, use_folds=(0,), checkpoint_name="checkpoint_best.pth"
            )
            print(f"üìÇ Model loaded from: {checkpoint_folder}")
            return predictor
        except Exception as e:
            print(f"‚ùå Critical Error initializing predictor: {e}")
            raise e

    def save_nifti(self, data, affine, output_path):
        """L∆∞u m·∫£ng numpy th√†nh file .nii.gz"""
        try:
            # data shape: [X, Y, Z] -> Ph·∫£i √©p ki·ªÉu v·ªÅ float32 ƒë·ªÉ tr√°nh l·ªói format
            img = nib.Nifti1Image(data.astype(np.float32), affine)
            nib.save(img, output_path)
        except Exception as e:
            print(f"‚ö†Ô∏è Error saving NIfTI {output_path}: {e}")

    def process_case(self, case_id):
        """
        X·ª≠ l√Ω m·ªôt ca b·ªánh: Preprocess -> Inference -> EDL Decomposition -> Save
        """
        print(f"\nüîç Processing: {case_id}...")
        
        # --- 1. SETUP PATHS (Code c≈© - Robust) ---
        img_folder = self.config["image_folder"]
        lbl_folder = self.config["label_folder"]
        
        base_file = os.path.join(img_folder, f"{case_id}_0000.nii")
        ext = ".nii" if os.path.exists(base_file) else ".nii.gz"
        
        image_files = [os.path.join(img_folder, f"{case_id}_{i:04d}{ext}") for i in range(4)]
        
        # Ki·ªÉm tra file input t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(image_files[0]):
            print(f"‚ùå Error: Input files for {case_id} not found.")
            return None, None, None, None, None

        gt_file = os.path.join(lbl_folder, f"{case_id}{ext}")
        if not os.path.exists(gt_file): 
            # print(f"‚ö†Ô∏è Ground truth for {case_id} not found (Inference only mode).")
            gt_file = None

        # --- L·∫§Y AFFINE MATRIX G·ªêC ƒê·ªÇ L∆ØU NIFTI ---
        try:
            tmp_img = nib.load(image_files[0])
            original_affine = tmp_img.affine
        except Exception as e:
            print(f"‚ùå Error loading affine from input image: {e}")
            return None, None, None, None, None

        # --- 2. PREPROCESSING ---
        try:
            data, seg, properties = self.preprocessor.run_case(
                image_files, gt_file, 
                self.predictor.plans_manager, 
                self.predictor.configuration_manager, 
                self.predictor.dataset_json
            )
        except Exception as e:
            print(f"‚ùå Error during preprocessing: {e}")
            return None, None, None, None, None
        
        # --- 3. INFERENCE ---
        # Th√™m torch.no_grad() ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ (t·ª´ code m·ªõi)
        data_tensor = torch.from_numpy(data).to(self.predictor.device)
        with torch.no_grad():
            pred_logits = self.predictor.predict_logits_from_preprocessed_data(data_tensor)
        
        # ======================================================================
        # 4. EDL UNCERTAINTY DECOMPOSITION (LOGIC M·ªöI)
        # ======================================================================
        # a. T√≠nh tham s·ªë Dirichlet
        evidence = F.softplus(pred_logits)
        alpha = evidence + 1
        S = torch.sum(alpha, dim=0, keepdim=True) # Sum strength
        probs = alpha / S                         # Expected Probability
        
        # b. Total Uncertainty (Entropy of Expected Probabilities)
        # H(p) = - sum(p * log(p))
        # C·ªông th√™m 1e-7 ƒë·ªÉ tr√°nh log(0)
        total_unc = -torch.sum(probs * torch.log(probs + 1e-7), dim=0)
        
        # c. Aleatoric Uncertainty (Expected Entropy of Dirichlet)
        # E[H(p)] approx sum(p * (digamma(S+1) - digamma(alpha+1)))
        digamma_S = torch.digamma(S + 1)
        digamma_alpha = torch.digamma(alpha + 1)
        aleatoric_unc = torch.sum(probs * (digamma_S - digamma_alpha), dim=0)
        
        # d. Epistemic Uncertainty (Mutual Information)
        # I = H(p) - E[H(p)]
        epistemic_unc = total_unc - aleatoric_unc
        
        # e. Chu·∫©n h√≥a v·ªÅ Numpy & Dictionary
        # Clamp ƒë·ªÉ tr√°nh s·ªë √¢m nh·ªè do sai s·ªë t√≠nh to√°n float
        unc_dict = {
            "total": torch.clamp(total_unc, min=0).cpu().numpy(),
            "aleatoric": torch.clamp(aleatoric_unc, min=0).cpu().numpy(),
            "epistemic": torch.clamp(epistemic_unc, min=0).cpu().numpy()
        }
        
        segmentation = torch.argmax(pred_logits, dim=0).cpu().numpy()
        
        # X·ª≠ l√Ω seg n·∫øu kh√¥ng c√≥ GT
        if seg is None: seg = np.zeros((1, *segmentation.shape))
        
        # ======================================================================
        
        # --- 5. L∆ØU FILE 3D (LOGIC C≈® + FILE M·ªöI) ---
        if self.config.get("save_3d_nifti", False):
            try:
                nifti_folder_name = self.config.get("dir_nifti", "3d_nifti")
                out_dir = os.path.join(self.config["output_folder"], nifti_folder_name, case_id)
                os.makedirs(out_dir, exist_ok=True)
                
                # L∆∞u b·ªô 3 file Uncertainty (M·ªõi)
                self.save_nifti(unc_dict["total"], original_affine, os.path.join(out_dir, "unc_total.nii.gz"))
                self.save_nifti(unc_dict["aleatoric"], original_affine, os.path.join(out_dir, "unc_aleatoric.nii.gz"))
                self.save_nifti(unc_dict["epistemic"], original_affine, os.path.join(out_dir, "unc_epistemic.nii.gz"))
                
                # L∆∞u Prediction (C≈©)
                self.save_nifti(segmentation, original_affine, os.path.join(out_dir, "prediction.nii.gz"))
                
                # L∆∞u Ground Truth (C≈©)
                self.save_nifti(seg[0], original_affine, os.path.join(out_dir, "ground_truth.nii.gz"))
                
                # L∆∞u MRI n·ªÅn (C≈©)
                self.save_nifti(data[0], original_affine, os.path.join(out_dir, "mri_crop.nii.gz"))
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error saving NIfTI files for {case_id}: {e}")

        # Return dict uncertainty thay v√¨ 1 bi·∫øn ƒë∆°n l·∫ª ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi logic m·ªõi
        return data, seg, segmentation, unc_dict, properties